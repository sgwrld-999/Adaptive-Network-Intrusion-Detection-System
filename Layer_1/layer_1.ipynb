{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:10:24,689 - INFO - Loading dataset...\n",
      "2025-03-22 12:10:24,793 - INFO - Loaded dataset with 150000 samples and 13 features\n",
      "2025-03-22 12:10:24,795 - INFO - Preprocessing data...\n",
      "2025-03-22 12:10:24,849 - INFO - Analyzing features...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers, backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import PowerTransformer, MaxAbsScaler\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_curve, roc_auc_score\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "import time\n",
    "import logging\n",
    "import warnings\n",
    "import json\n",
    "\n",
    "# Setup logging and suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger('Layer1_VAE')\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('plots', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('reports', exist_ok=True)\n",
    "\n",
    "class Layer1AutoencoderVAE:\n",
    "    def __init__(self, input_dim, latent_dim=6, learning_rate=1e-4, layer_sizes=None):\n",
    "        \"\"\"Initialize the VAE model with configurable architecture\"\"\"\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.layer_sizes = layer_sizes or [64, 32]  # Default larger network\n",
    "        self.encoder = None\n",
    "        self.decoder = None\n",
    "        self.vae = None\n",
    "        self.kde = None\n",
    "        self.threshold = None\n",
    "        self.fallback_threshold = None  # Added for robustness\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.build_model()\n",
    "        \n",
    "    def sampling(self, args):\n",
    "        \"\"\"Reparameterization trick for VAE\"\"\"\n",
    "        z_mean, z_log_var = args\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.random.normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "        \n",
    "    def build_model(self):\n",
    "        \"\"\"Build the VAE with customizable architecture\"\"\"\n",
    "        # Encoder\n",
    "        encoder_inputs = layers.Input(shape=(self.input_dim,))\n",
    "        x = encoder_inputs\n",
    "        \n",
    "        for size in self.layer_sizes:\n",
    "            x = layers.Dense(size, activation=\"relu\", \n",
    "                             kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = layers.Dropout(0.2)(x)\n",
    "        \n",
    "        # VAE latent space\n",
    "        z_mean = layers.Dense(self.latent_dim, name=\"z_mean\")(x)\n",
    "        z_log_var = layers.Dense(self.latent_dim, name=\"z_log_var\")(x)\n",
    "        z = layers.Lambda(self.sampling, output_shape=(self.latent_dim,), name=\"z\")([z_mean, z_log_var])\n",
    "        \n",
    "        # Instantiate encoder\n",
    "        self.encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "        \n",
    "        # Decoder\n",
    "        latent_inputs = layers.Input(shape=(self.latent_dim,))\n",
    "        x = latent_inputs\n",
    "        \n",
    "        for size in reversed(self.layer_sizes):\n",
    "            x = layers.Dense(size, activation=\"relu\", \n",
    "                             kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = layers.Dropout(0.2)(x)\n",
    "        \n",
    "        decoder_outputs = layers.Dense(self.input_dim, activation=\"sigmoid\")(x)\n",
    "        \n",
    "        # Instantiate decoder\n",
    "        self.decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "        \n",
    "        # Instantiate VAE model\n",
    "        outputs = self.decoder(self.encoder(encoder_inputs)[2])\n",
    "        self.vae = keras.Model(encoder_inputs, outputs, name=\"vae\")\n",
    "        \n",
    "        # Define VAE loss with beta parameter for KL term weighting\n",
    "        beta = 1.0  # Can be adjusted to control KL weight\n",
    "        reconstruction_loss = keras.losses.MeanSquaredError()(encoder_inputs, outputs)\n",
    "        reconstruction_loss *= self.input_dim\n",
    "        kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        vae_loss = K.mean(reconstruction_loss + beta * kl_loss)\n",
    "        \n",
    "        self.vae.add_loss(vae_loss)\n",
    "        self.vae.compile(optimizer=keras.optimizers.Adam(learning_rate=self.learning_rate))\n",
    "        \n",
    "        # Custom metrics\n",
    "        self.vae.metrics_names.append(\"reconstruction_loss\")\n",
    "        self.vae.metrics_names.append(\"kl_loss\")\n",
    "        self.vae.metrics.append(self.reconstruction_loss_tracker)\n",
    "        self.vae.metrics.append(self.kl_loss_tracker)\n",
    "        \n",
    "    def train(self, X_train, X_val, epochs=100, batch_size=32):\n",
    "        \"\"\"Train the VAE model with early stopping and LR reduction\"\"\"\n",
    "        early_stopping = keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', patience=15, restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss', factor=0.5, patience=7, min_lr=1e-7\n",
    "        )\n",
    "        \n",
    "        tensorboard_callback = keras.callbacks.TensorBoard(\n",
    "            log_dir=f'./logs/vae_{time.strftime(\"%Y%m%d-%H%M%S\")}',\n",
    "            histogram_freq=1\n",
    "        )\n",
    "        \n",
    "        class VAECallback(keras.callbacks.Callback):\n",
    "            def __init__(self, parent):\n",
    "                super(VAECallback, self).__init__()\n",
    "                self.parent = parent\n",
    "                \n",
    "            def on_epoch_end(self, epoch, logs=None):\n",
    "                # Track separate loss components\n",
    "                x_val_reconstructed = self.model.predict(X_val)\n",
    "                reconstruction_loss = np.mean(np.square(X_val - x_val_reconstructed))\n",
    "                z_mean, z_log_var, _ = self.parent.encoder.predict(X_val)\n",
    "                kl_loss = -0.5 * np.mean(np.sum(1 + z_log_var - np.square(z_mean) - np.exp(z_log_var), axis=1))\n",
    "                \n",
    "                # Update metrics\n",
    "                self.parent.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "                self.parent.kl_loss_tracker.update_state(kl_loss)\n",
    "                \n",
    "                logs['reconstruction_loss'] = reconstruction_loss\n",
    "                logs['kl_loss'] = kl_loss\n",
    "        \n",
    "        vae_callback = VAECallback(self)\n",
    "        \n",
    "        logger.info(\"Starting VAE training...\")\n",
    "        history = self.vae.fit(\n",
    "            X_train, X_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_val, X_val),\n",
    "            callbacks=[early_stopping, reduce_lr, tensorboard_callback, vae_callback],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        logger.info(\"VAE training completed.\")\n",
    "        self._set_dynamic_threshold(X_train)\n",
    "        return history\n",
    "    \n",
    "    def _set_dynamic_threshold(self, X_data):\n",
    "        \"\"\"Set robust thresholds using multiple methods\"\"\"\n",
    "        # Compute reconstruction errors\n",
    "        _, _, z = self.encoder.predict(X_data)\n",
    "        reconstructed = self.decoder.predict(z)\n",
    "        mse = np.mean(np.square(X_data - reconstructed), axis=1)\n",
    "        \n",
    "        # Set percentile-based fallback threshold (90th-99th percentile)\n",
    "        self.fallback_threshold = np.percentile(mse, 97.5)\n",
    "        \n",
    "        # Optimize KDE bandwidth using grid search\n",
    "        param_grid = {'bandwidth': np.logspace(-2, 1, 10)}\n",
    "        grid_search = GridSearchCV(KernelDensity(kernel='gaussian'), param_grid, cv=5)\n",
    "        grid_search.fit(mse.reshape(-1, 1))\n",
    "        \n",
    "        # Use the optimized bandwidth\n",
    "        best_bandwidth = grid_search.best_params_['bandwidth']\n",
    "        self.kde = KernelDensity(kernel='gaussian', bandwidth=best_bandwidth).fit(mse.reshape(-1, 1))\n",
    "        \n",
    "        log_dens = self.kde.score_samples(mse.reshape(-1, 1))\n",
    "        scores = -log_dens\n",
    "        \n",
    "        # Robust elbow finding\n",
    "        try:\n",
    "            sorted_scores = np.sort(scores)\n",
    "            n_samples = len(sorted_scores)\n",
    "            \n",
    "            if n_samples < 10:  # Not enough samples for reliable elbow detection\n",
    "                self.threshold = self.fallback_threshold\n",
    "            else:\n",
    "                indices = np.arange(n_samples)\n",
    "                \n",
    "                # Use window averaging for more stable angle calculation\n",
    "                window_size = max(3, int(n_samples * 0.02))\n",
    "                angles = []\n",
    "                \n",
    "                for i in range(window_size, n_samples - window_size):\n",
    "                    # Use windowed points for more stability\n",
    "                    p1 = np.array([indices[i-window_size]/n_samples, sorted_scores[i-window_size]])\n",
    "                    p2 = np.array([indices[i]/n_samples, sorted_scores[i]])\n",
    "                    p3 = np.array([indices[i+window_size]/n_samples, sorted_scores[i+window_size]])\n",
    "                    \n",
    "                    # Compute vectors\n",
    "                    v1 = p2 - p1\n",
    "                    v2 = p3 - p2\n",
    "                    \n",
    "                    # Normalize vectors\n",
    "                    v1_norm = np.linalg.norm(v1)\n",
    "                    v2_norm = np.linalg.norm(v2)\n",
    "                    \n",
    "                    if v1_norm > 0 and v2_norm > 0:\n",
    "                        v1 = v1 / v1_norm\n",
    "                        v2 = v2 / v2_norm\n",
    "                        \n",
    "                        # Compute angle using dot product\n",
    "                        dot_product = np.dot(v1, v2)\n",
    "                        angle = np.arccos(np.clip(dot_product, -1.0, 1.0))\n",
    "                        angles.append(angle)\n",
    "                    else:\n",
    "                        angles.append(0)\n",
    "                \n",
    "                if len(angles) > 0 and max(angles) > 0.1:  # Check if we have meaningful angles\n",
    "                    elbow_idx = np.argmax(angles) + window_size\n",
    "                    adaptive_threshold = sorted_scores[elbow_idx]\n",
    "                    \n",
    "                    # Blend with percentile-based threshold for robustness\n",
    "                    self.threshold = 0.7 * adaptive_threshold + 0.3 * self.fallback_threshold\n",
    "                else:\n",
    "                    self.threshold = self.fallback_threshold\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error in threshold calculation: {e}. Using fallback threshold.\")\n",
    "            self.threshold = self.fallback_threshold\n",
    "        \n",
    "        logger.info(f\"Dynamic threshold: {self.threshold:.6f} (fallback: {self.fallback_threshold:.6f})\")\n",
    "        \n",
    "        # Visualize the threshold\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(scores, bins=50, alpha=0.6, color='blue')\n",
    "        plt.axvline(x=self.threshold, color='red', linestyle='--', label=f'Threshold: {self.threshold:.6f}')\n",
    "        plt.axvline(x=self.fallback_threshold, color='green', linestyle=':', label=f'Fallback: {self.fallback_threshold:.6f}')\n",
    "        plt.title('Anomaly Score Distribution and Thresholds')\n",
    "        plt.xlabel('Anomaly Score (-log density)')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "        plt.savefig('plots/anomaly_threshold.png')\n",
    "        plt.close()\n",
    "    \n",
    "    def detect_anomalies(self, X_data):\n",
    "        \"\"\"Detect anomalies in the data\"\"\"\n",
    "        if self.kde is None or self.threshold is None:\n",
    "            raise ValueError(\"Model hasn't been trained yet. Call train() first.\")\n",
    "        \n",
    "        # Get latent representations and reconstructions\n",
    "        _, _, z = self.encoder.predict(X_data)\n",
    "        reconstructed = self.decoder.predict(z)\n",
    "        \n",
    "        # Compute reconstruction error (MSE)\n",
    "        mse = np.mean(np.square(X_data - reconstructed), axis=1)\n",
    "        \n",
    "        # Compute log density and anomaly scores\n",
    "        log_dens = self.kde.score_samples(mse.reshape(-1, 1))\n",
    "        anomaly_scores = -log_dens\n",
    "        \n",
    "        # Identify anomalies\n",
    "        anomaly_indices = np.where(anomaly_scores > self.threshold)[0]\n",
    "        anomalies = X_data[anomaly_indices]\n",
    "        \n",
    "        # Compute confidence\n",
    "        max_score = np.max(anomaly_scores)\n",
    "        min_score = np.min(anomaly_scores)\n",
    "        confidence = (anomaly_scores - min_score) / (max_score - min_score) if max_score > min_score else np.zeros_like(anomaly_scores)\n",
    "        \n",
    "        return anomalies, anomaly_indices, anomaly_scores, confidence\n",
    "    \n",
    "    def get_encoded_features(self, X_data):\n",
    "        \"\"\"Extract features from the encoder's latent space\"\"\"\n",
    "        _, _, z = self.encoder.predict(X_data)\n",
    "        return z\n",
    "    \n",
    "    def save_model(self, base_path='models'):\n",
    "        \"\"\"Save the model and artifacts\"\"\"\n",
    "        timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        \n",
    "        # Save full VAE model\n",
    "        self.vae.save(f'{base_path}/layer1_model_{timestamp}.h5')\n",
    "        self.encoder.save(f'{base_path}/layer1_encoder_{timestamp}.h5')\n",
    "        self.decoder.save(f'{base_path}/layer1_decoder_{timestamp}.h5')\n",
    "        \n",
    "        # Create symlinks to latest models\n",
    "        for model_type in ['model', 'encoder', 'decoder']:\n",
    "            latest_link = f'{base_path}/layer1_{model_type}.h5'\n",
    "            if os.path.exists(latest_link):\n",
    "                os.remove(latest_link)\n",
    "            os.symlink(f'layer1_{model_type}_{timestamp}.h5', latest_link)\n",
    "        \n",
    "        # Save threshold and metadata\n",
    "        model_config = {\n",
    "            'input_dim': self.input_dim,\n",
    "            'latent_dim': self.latent_dim,\n",
    "            'layer_sizes': self.layer_sizes,\n",
    "            'threshold': float(self.threshold),\n",
    "            'fallback_threshold': float(self.fallback_threshold),\n",
    "            'timestamp': timestamp\n",
    "        }\n",
    "        \n",
    "        with open(f'{base_path}/layer1_config_{timestamp}.json', 'w') as f:\n",
    "            json.dump(model_config, f, indent=4)\n",
    "        \n",
    "        # Save the KDE model\n",
    "        joblib.dump(self.kde, f'{base_path}/layer1_kde_{timestamp}.pkl')\n",
    "        joblib.dump(self.kde, f'{base_path}/layer1_kde.pkl')\n",
    "        \n",
    "        return timestamp\n",
    "\n",
    "def analyze_features(data, save_dir='plots'):\n",
    "    \"\"\"Analyze feature distributions and create visualizations\"\"\"\n",
    "    # Create feature distribution plots\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    features = data.columns\n",
    "    num_features = len(features)\n",
    "    rows = int(np.ceil(num_features / 3))\n",
    "    \n",
    "    for i, feature in enumerate(features):\n",
    "        plt.subplot(rows, 3, i+1)\n",
    "        sns.histplot(data[feature], kde=True)\n",
    "        plt.title(f'{feature} Distribution')\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(f'{save_dir}/feature_distributions.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Feature correlation heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    corr_matrix = data.corr()\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "    sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "    plt.title('Feature Correlation Heatmap')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_dir}/feature_correlations.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Calculate feature variances\n",
    "    variances = data.var().sort_values(ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=variances.index, y=variances.values)\n",
    "    plt.title('Feature Variance')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_dir}/feature_variances.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Identify low variance features\n",
    "    low_var_threshold = 0.01\n",
    "    low_var_features = variances[variances < low_var_threshold].index.tolist()\n",
    "    \n",
    "    return {\n",
    "        'variances': variances,\n",
    "        'low_var_features': low_var_features,\n",
    "        'correlation_matrix': corr_matrix\n",
    "    }\n",
    "\n",
    "def find_optimal_latent_dim(X_train, X_val, input_dim, min_dim=3, max_dim=15):\n",
    "    \"\"\"Use k-fold cross-validation to find optimal latent dimension\"\"\"\n",
    "    logger.info(\"Finding optimal latent dimension...\")\n",
    "    \n",
    "    # Define candidate dimensions to test\n",
    "    if input_dim <= 10:\n",
    "        candidate_dims = list(range(min_dim, min(max_dim, input_dim) + 1))\n",
    "    else:\n",
    "        # Test a range with more focus on smaller dimensions\n",
    "        candidate_dims = list(range(min_dim, min(8, input_dim // 2) + 1))\n",
    "        candidate_dims += [min(d, input_dim // 2) for d in [10, 12, 15]]\n",
    "    \n",
    "    # Remove duplicates and sort\n",
    "    candidate_dims = sorted(list(set(candidate_dims)))\n",
    "    \n",
    "    # Combine train and validation for k-fold\n",
    "    X_combined = np.vstack([X_train, X_val])\n",
    "    \n",
    "    results = []\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    for latent_dim in candidate_dims:\n",
    "        fold_losses = []\n",
    "        \n",
    "        for train_idx, val_idx in kf.split(X_combined):\n",
    "            X_fold_train, X_fold_val = X_combined[train_idx], X_combined[val_idx]\n",
    "            \n",
    "            # Train a smaller model for quick evaluation\n",
    "            model = Layer1AutoencoderVAE(\n",
    "                input_dim=input_dim, \n",
    "                latent_dim=latent_dim,\n",
    "                layer_sizes=[32, 16],  # Smaller network for quick evaluation\n",
    "                learning_rate=1e-3\n",
    "            )\n",
    "            \n",
    "            # Train with fewer epochs for efficiency\n",
    "            history = model.train(\n",
    "                X_fold_train, X_fold_val, \n",
    "                epochs=30, \n",
    "                batch_size=64\n",
    "            )\n",
    "            \n",
    "            # Get the best validation loss\n",
    "            best_val_loss = min(history.history['val_loss'])\n",
    "            fold_losses.append(best_val_loss)\n",
    "        \n",
    "        # Average loss across folds\n",
    "        avg_loss = np.mean(fold_losses)\n",
    "        logger.info(f\"Latent dim {latent_dim}: avg validation loss = {avg_loss:.6f}\")\n",
    "        results.append((latent_dim, avg_loss))\n",
    "    \n",
    "    # Find dimension with lowest loss\n",
    "    results.sort(key=lambda x: x[1])\n",
    "    best_dim = results[0][0]\n",
    "    \n",
    "    # Visualize dimension search\n",
    "    dims, losses = zip(*results)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(dims, losses, 'o-')\n",
    "    plt.axvline(x=best_dim, color='red', linestyle='--')\n",
    "    plt.title(f'Latent Dimension Optimization (Best: {best_dim})')\n",
    "    plt.xlabel('Latent Dimension')\n",
    "    plt.ylabel('Validation Loss')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('plots/latent_dim_optimization.png')\n",
    "    plt.close()\n",
    "    \n",
    "    logger.info(f\"Optimal latent dimension: {best_dim}\")\n",
    "    return best_dim\n",
    "\n",
    "def generate_evaluation_plots(model, X_normal, X_test=None, y_test=None, save_dir='plots'):\n",
    "    \"\"\"Generate evaluation plots for the model\"\"\"\n",
    "    # Reconstruction error distribution for normal data\n",
    "    _, _, z_normal = model.encoder.predict(X_normal)\n",
    "    X_normal_reconstructed = model.decoder.predict(z_normal)\n",
    "    normal_mse = np.mean(np.square(X_normal - X_normal_reconstructed), axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(normal_mse, kde=True, color='blue', label='Normal')\n",
    "    \n",
    "    # If test data with labels is available\n",
    "    if X_test is not None and y_test is not None:\n",
    "        _, _, z_test = model.encoder.predict(X_test)\n",
    "        X_test_reconstructed = model.decoder.predict(z_test)\n",
    "        test_mse = np.mean(np.square(X_test - X_test_reconstructed), axis=1)\n",
    "        \n",
    "        # Separate normal and anomaly in test set\n",
    "        if np.sum(y_test) > 0:  # If we have anomalies\n",
    "            anomaly_mse = test_mse[y_test == 1]\n",
    "            sns.histplot(anomaly_mse, kde=True, color='red', alpha=0.6, label='Anomaly')\n",
    "    \n",
    "    plt.axvline(x=model.threshold, color='green', linestyle='--', \n",
    "                label=f'Threshold: {model.threshold:.6f}')\n",
    "    plt.title('Reconstruction Error Distribution')\n",
    "    plt.xlabel('Mean Squared Error')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{save_dir}/reconstruction_error_dist.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # If test data with labels is available, generate ROC and PR curves\n",
    "    if X_test is not None and y_test is not None and np.sum(y_test) > 0:\n",
    "        # Get anomaly scores for test data\n",
    "        _, _, anomaly_scores, _ = model.detect_anomalies(X_test)\n",
    "        \n",
    "        # ROC curve\n",
    "        fpr, tpr, _ = roc_curve(y_test, anomaly_scores)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig(f'{save_dir}/roc_curve.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Precision-Recall curve\n",
    "        precision, recall, _ = precision_recall_curve(y_test, anomaly_scores)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(recall, precision, color='blue', lw=2, label=f'PR curve (area = {pr_auc:.2f})')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curve')\n",
    "        plt.legend(loc=\"lower left\")\n",
    "        plt.savefig(f'{save_dir}/pr_curve.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Latent space visualization (2D projection if latent_dim > 2)\n",
    "        _, _, z = model.encoder.predict(X_test)\n",
    "        \n",
    "        if model.latent_dim >= 2:\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            if np.sum(y_test == 0) > 0:\n",
    "                plt.scatter(z[y_test == 0, 0], z[y_test == 0, 1], c='blue', alpha=0.5, label='Normal')\n",
    "            if np.sum(y_test == 1) > 0:\n",
    "                plt.scatter(z[y_test == 1, 0], z[y_test == 1, 1], c='red', alpha=0.5, label='Anomaly')\n",
    "            plt.title('Latent Space Visualization (First 2 Dimensions)')\n",
    "            plt.xlabel('Latent Dim 1')\n",
    "            plt.ylabel('Latent Dim 2')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'{save_dir}/latent_space_2d.png')\n",
    "            plt.close()\n",
    "\n",
    "def generate_report(model, history, feature_analysis, data_info, timestamp, save_dir='reports'):\n",
    "    \"\"\"Generate a summary report of the model training and evaluation\"\"\"\n",
    "    report = []\n",
    "    report.append(\"=\" * 80)\n",
    "    report.append(\"LAYER 1 AUTOENCODER-VAE MODEL SUMMARY REPORT\")\n",
    "    report.append(\"=\" * 80)\n",
    "    report.append(f\"Generated: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    report.append(f\"Model timestamp: {timestamp}\")\n",
    "    report.append(\"\\n\")\n",
    "    \n",
    "    # Data information\n",
    "    report.append(\"DATA INFORMATION\")\n",
    "    report.append(\"-\" * 80)\n",
    "    report.append(f\"Total samples: {data_info['total_samples']}\")\n",
    "    report.append(f\"Training samples: {data_info['train_samples']}\")\n",
    "    report.append(f\"Validation samples: {data_info['val_samples']}\")\n",
    "    report.append(f\"Input features: {data_info['n_features']}\")\n",
    "    report.append(f\"Feature names: {', '.join(data_info['feature_names'])}\")\n",
    "    report.append(\"\\n\")\n",
    "    \n",
    "    # Feature analysis\n",
    "    report.append(\"FEATURE ANALYSIS\")\n",
    "    report.append(\"-\" * 80)\n",
    "    report.append(\"Top 5 features by variance:\")\n",
    "    top_var_features = feature_analysis['variances'].head(5)\n",
    "    for feature, var in top_var_features.items():\n",
    "        report.append(f\"  - {feature}: {var:.6f}\")\n",
    "    \n",
    "    report.append(\"\\nLow variance features:\")\n",
    "    for feature in feature_analysis['low_var_features']:\n",
    "        report.append(f\"  - {feature}: {feature_analysis['variances'][feature]:.6f}\")\n",
    "    report.append(\"\\n\")\n",
    "    \n",
    "    # Model architecture\n",
    "    report.append(\"MODEL ARCHITECTURE\")\n",
    "    report.append(\"-\" * 80)\n",
    "    report.append(f\"Input dimension: {model.input_dim}\")\n",
    "    report.append(f\"Latent dimension: {model.latent_dim}\")\n",
    "    report.append(f\"Hidden layer sizes: {model.layer_sizes}\")\n",
    "    report.append(f\"Learning rate: {model.learning_rate}\")\n",
    "    report.append(\"\\n\")\n",
    "    \n",
    "    # Training performance\n",
    "    report.append(\"TRAINING PERFORMANCE\")\n",
    "    report.append(\"-\" * 80)\n",
    "    report.append(f\"Final training loss: {history.history['loss'][-1]:.6f}\")\n",
    "    report.append(f\"Final validation loss: {history.history['val_loss'][-1]:.6f}\")\n",
    "    report.append(f\"Final reconstruction loss: {history.history['reconstruction_loss'][-1]:.6f}\")\n",
    "    report.append(f\"Final KL loss: {history.history['kl_loss'][-1]:.6f}\")\n",
    "    report.append(f\"Training epochs: {len(history.history['loss'])}\")\n",
    "    report.append(\"\\n\")\n",
    "    \n",
    "    # Anomaly detection\n",
    "    report.append(\"ANOMALY DETECTION\")\n",
    "    report.append(\"-\" * 80)\n",
    "    report.append(f\"Dynamic threshold: {model.threshold:.6f}\")\n",
    "    report.append(f\"Fallback threshold: {model.fallback_threshold:.6f}\")\n",
    "    report.append(f\"Threshold method: Kernel Density Estimation with robust elbow finding\")\n",
    "    report.append(\"\\n\")\n",
    "    \n",
    "    # Saved artifacts\n",
    "    report.append(\"SAVED ARTIFACTS\")\n",
    "    report.append(\"-\" * 80)\n",
    "    report.append(f\"Full model: models/layer1_model_{timestamp}.h5\")\n",
    "    report.append(f\"Encoder model: models/layer1_encoder_{timestamp}.h5\")\n",
    "    report.append(f\"Decoder model: models/layer1_decoder_{timestamp}.h5\")\n",
    "    report.append(f\"KDE model: models/layer1_kde_{timestamp}.pkl\")\n",
    "    report.append(f\"Configuration: models/layer1_config_{timestamp}.json\")\n",
    "    report.append(\"\\n\")\n",
    "    \n",
    "    # Write report to file\n",
    "    with open(f\"{save_dir}/layer1_report_{timestamp}.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(report))\n",
    "    \n",
    "    # Create symlink to latest report\n",
    "    latest_report = f\"{save_dir}/layer1_report_latest.txt\"\n",
    "    if os.path.exists(latest_report):\n",
    "        os.remove(latest_report)\n",
    "    os.symlink(f\"layer1_report_{timestamp}.txt\", latest_report)\n",
    "    \n",
    "    return report\n",
    "\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    logger.info(\"Loading dataset...\")\n",
    "    dataset_path = \"layer1_training_data.csv\"\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(dataset_path)\n",
    "        logger.info(f\"Loaded dataset with {len(df)} samples and {len(df.columns)} features\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading dataset: {e}\")\n",
    "        logger.info(\"Using sample data instead...\")\n",
    "        sample_data = \"\"\"tcp.dstport_category,mbtcp.trans_id,tcp.ack,mqtt.ver,tcp.connection.synack,mbtcp.len,mqtt.conflags,mqtt.conack.flags,tcp.connection.rst,http.tls_port,tcp.srcport,tcp.connection.fin,mqtt.hdrflags\n",
    "0.5,0.0,1.2316824563829088e-09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7660298471022675,0.0,0.8\n",
    "0.5,0.0,1.4780189476594907e-09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9434339426862391,0.0,0.0\n",
    "1.0,0.0,3.1824211308021596e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7660298471022675,0.0,0.8\n",
    "0.5,0.0,1.2316824563829088e-09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7660298471022675,0.0,0.8\"\"\"\n",
    "        df = pd.read_csv(pd.StringIO(sample_data))\n",
    "        \n",
    "    # Preprocess data\n",
    "    logger.info(\"Preprocessing data...\")\n",
    "    \n",
    "    # Drop columns with zero variance\n",
    "    var = df.var()\n",
    "    zero_var_cols = var[var == 0].index.tolist()\n",
    "    if zero_var_cols:\n",
    "        logger.info(f\"Dropping {len(zero_var_cols)} zero-variance columns: {zero_var_cols}\")\n",
    "        df = df.drop(columns=zero_var_cols)\n",
    "    \n",
    "    # Handle NaN values\n",
    "    if df.isna().any().any():\n",
    "        logger.info(\"Filling NaN values with 0\")\n",
    "        df = df.fillna(0)\n",
    "    \n",
    "    # Scale features to [0, 1] range for VAE\n",
    "    scaler = MaxAbsScaler()\n",
    "    X_scaled = scaler.fit_transform(df)\n",
    "    \n",
    "    # Save scaler for future use\n",
    "    joblib.dump(scaler, 'models/layer1_scaler.pkl')\n",
    "    \n",
    "    # Split data for training\n",
    "    X_train, X_val = train_test_split(X_scaled, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Analyze features\n",
    "    logger.info(\"Analyzing features...\")\n",
    "    feature_analysis = analyze_features(df)\n",
    "    \n",
    "    # Find optimal latent dimension\n",
    "    input_dim = X_train.shape[1]\n",
    "    best_latent_dim = find_optimal_latent_dim(X_train, X_val, input_dim)\n",
    "    \n",
    "    # Define model architecture based on input size\n",
    "    if input_dim <= 10:\n",
    "        layer_sizes = [32, 16]\n",
    "    elif input_dim <= 20:\n",
    "        layer_sizes = [64, 32, 16]\n",
    "    else:\n",
    "        layer_sizes = [128, 64, 32]\n",
    "    \n",
    "    # Create and train the model\n",
    "    logger.info(f\"Building VAE model with latent dim {best_latent_dim}...\")\n",
    "    model = Layer1AutoencoderVAE(\n",
    "        input_dim=input_dim,\n",
    "        latent_dim=best_latent_dim,\n",
    "        layer_sizes=layer_sizes\n",
    "    )\n",
    "    \n",
    "    logger.info(\"Training VAE model...\")\n",
    "    history = model.train(X_train, X_val, epochs=200, batch_size=64)\n",
    "    \n",
    "    # Generate evaluation plots\n",
    "    logger.info(\"Generating evaluation plots...\")\n",
    "    generate_evaluation_plots(model, X_train)\n",
    "    \n",
    "    # Save the model\n",
    "    logger.info(\"Saving model...\")\n",
    "    timestamp = model.save_model()\n",
    "    \n",
    "    # Prepare data info for report\n",
    "    data_info = {\n",
    "        'total_samples': len(df),\n",
    "        'train_samples': len(X_train),\n",
    "        'val_samples': len(X_val),\n",
    "        'n_features': input_dim,\n",
    "        'feature_names': df.columns.tolist()\n",
    "    }\n",
    "    \n",
    "    # Generate and save report\n",
    "    logger.info(\"Generating report...\")\n",
    "    report = generate_report(model, history, feature_analysis, data_info, timestamp)\n",
    "    \n",
    "    # Extract encoded features for Layer 2\n",
    "    logger.info(\"Extracting encoded features for Layer 2...\")\n",
    "    encoded_features = model.get_encoded_features(X_scaled)\n",
    "    \n",
    "    # Save encoded features for Layer 2\n",
    "    encoded_df = pd.DataFrame(\n",
    "        encoded_features,\n",
    "        columns=[f'vae_feature_{i}' for i in range(best_latent_dim)]\n",
    "    )\n",
    "    encoded_df.to_csv('layer1_encoded_features.csv', index=False)\n",
    "    \n",
    "    # Perform anomaly detection on training data (to demonstrate)\n",
    "    logger.info(\"Running anomaly detection on training data...\")\n",
    "    anomalies, anomaly_indices, anomaly_scores, confidence = model.detect_anomalies(X_scaled)\n",
    "    \n",
    "    # Save anomaly detection results\n",
    "    anomaly_results = pd.DataFrame({\n",
    "        'anomaly_score': anomaly_scores,\n",
    "        'confidence': confidence,\n",
    "        'is_anomaly': anomaly_scores > model.threshold\n",
    "    })\n",
    "    anomaly_results.to_csv('layer1_anomaly_results.csv', index=False)\n",
    "    \n",
    "    # Print summary of anomalies found\n",
    "    anomaly_count = len(anomaly_indices)\n",
    "    logger.info(f\"Found {anomaly_count} potential anomalies ({(anomaly_count/len(X_scaled))*100:.2f}%)\")\n",
    "    \n",
    "    # Print execution time\n",
    "    execution_time = time.time() - start_time\n",
    "    logger.info(f\"Total execution time: {execution_time:.2f} seconds\")\n",
    "    \n",
    "    logger.info(\"Layer 1 VAE processing completed successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:51:00,647 - INFO - Loading and preparing data...\n",
      "2025-03-22 12:51:00,649 - ERROR - Error loading data: [Errno 2] No such file or directory: 'your_dataset.csv'\n",
      "2025-03-22 12:51:00,649 - INFO - Using synthetic data for demonstration...\n",
      "2025-03-22 12:51:00,663 - INFO - Finding optimal latent dimension...\n",
      "2025-03-22 12:51:00,783 - INFO - Starting hybrid Autoencoder-VAE training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - ae_loss: 6.3908 - kl_loss: 0.2055 - loss: 13.5509 - reconstruction_loss: 6.9956 - val_ae_loss: 5.6228 - val_kl_loss: 0.0681 - val_loss: 12.1632 - val_reconstruction_loss: 6.4859 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 5.4064 - kl_loss: 0.0575 - loss: 11.9462 - reconstruction_loss: 6.4938 - val_ae_loss: 4.2152 - val_kl_loss: 0.0286 - val_loss: 10.2248 - val_reconstruction_loss: 5.9867 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 3.9000 - kl_loss: 0.0272 - loss: 9.9422 - reconstruction_loss: 6.0204 - val_ae_loss: 2.7146 - val_kl_loss: 0.0205 - val_loss: 8.2030 - val_reconstruction_loss: 5.4720 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 2.5532 - kl_loss: 0.0212 - loss: 7.9403 - reconstruction_loss: 5.3701 - val_ae_loss: 1.9335 - val_kl_loss: 0.0334 - val_loss: 6.6301 - val_reconstruction_loss: 4.6698 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.9307 - kl_loss: 0.0445 - loss: 6.4466 - reconstruction_loss: 4.4803 - val_ae_loss: 1.7515 - val_kl_loss: 0.0783 - val_loss: 5.3362 - val_reconstruction_loss: 3.5220 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.8215 - kl_loss: 0.0999 - loss: 5.3482 - reconstruction_loss: 3.4468 - val_ae_loss: 1.7229 - val_kl_loss: 0.1434 - val_loss: 4.7086 - val_reconstruction_loss: 2.8709 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7762 - kl_loss: 0.1579 - loss: 4.6934 - reconstruction_loss: 2.7908 - val_ae_loss: 1.7167 - val_kl_loss: 0.1376 - val_loss: 4.1198 - val_reconstruction_loss: 2.2930 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7851 - kl_loss: 0.1309 - loss: 4.1996 - reconstruction_loss: 2.3098 - val_ae_loss: 1.7144 - val_kl_loss: 0.0815 - val_loss: 3.8041 - val_reconstruction_loss: 2.0245 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7746 - kl_loss: 0.0726 - loss: 3.9221 - reconstruction_loss: 2.0894 - val_ae_loss: 1.7132 - val_kl_loss: 0.0433 - val_loss: 3.6442 - val_reconstruction_loss: 1.8964 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7693 - kl_loss: 0.0407 - loss: 3.7764 - reconstruction_loss: 1.9746 - val_ae_loss: 1.7122 - val_kl_loss: 0.0263 - val_loss: 3.5677 - val_reconstruction_loss: 1.8345 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7689 - kl_loss: 0.0252 - loss: 3.6908 - reconstruction_loss: 1.9017 - val_ae_loss: 1.7113 - val_kl_loss: 0.0179 - val_loss: 3.5159 - val_reconstruction_loss: 1.7904 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7774 - kl_loss: 0.0181 - loss: 3.6654 - reconstruction_loss: 1.8736 - val_ae_loss: 1.7104 - val_kl_loss: 0.0125 - val_loss: 3.4899 - val_reconstruction_loss: 1.7695 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7832 - kl_loss: 0.0122 - loss: 3.6439 - reconstruction_loss: 1.8509 - val_ae_loss: 1.7096 - val_kl_loss: 0.0087 - val_loss: 3.4852 - val_reconstruction_loss: 1.7686 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7599 - kl_loss: 0.0083 - loss: 3.5865 - reconstruction_loss: 1.8199 - val_ae_loss: 1.7087 - val_kl_loss: 0.0068 - val_loss: 3.4728 - val_reconstruction_loss: 1.7586 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7366 - kl_loss: 0.0068 - loss: 3.5226 - reconstruction_loss: 1.7806 - val_ae_loss: 1.7078 - val_kl_loss: 0.0055 - val_loss: 3.4672 - val_reconstruction_loss: 1.7550 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7687 - kl_loss: 0.0056 - loss: 3.5786 - reconstruction_loss: 1.8054 - val_ae_loss: 1.7068 - val_kl_loss: 0.0046 - val_loss: 3.4577 - val_reconstruction_loss: 1.7472 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7802 - kl_loss: 0.0046 - loss: 3.5927 - reconstruction_loss: 1.8088 - val_ae_loss: 1.7058 - val_kl_loss: 0.0040 - val_loss: 3.4479 - val_reconstruction_loss: 1.7389 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7831 - kl_loss: 0.0043 - loss: 3.6020 - reconstruction_loss: 1.8155 - val_ae_loss: 1.7048 - val_kl_loss: 0.0034 - val_loss: 3.4403 - val_reconstruction_loss: 1.7327 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7615 - kl_loss: 0.0036 - loss: 3.5548 - reconstruction_loss: 1.7904 - val_ae_loss: 1.7035 - val_kl_loss: 0.0030 - val_loss: 3.4425 - val_reconstruction_loss: 1.7366 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7497 - kl_loss: 0.0031 - loss: 3.5318 - reconstruction_loss: 1.7797 - val_ae_loss: 1.7023 - val_kl_loss: 0.0027 - val_loss: 3.4306 - val_reconstruction_loss: 1.7262 - learning_rate: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7546 - kl_loss: 0.0027 - loss: 3.5381 - reconstruction_loss: 1.7813 - val_ae_loss: 1.7009 - val_kl_loss: 0.0024 - val_loss: 3.4284 - val_reconstruction_loss: 1.7255 - learning_rate: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7655 - kl_loss: 0.0025 - loss: 3.5624 - reconstruction_loss: 1.7949 - val_ae_loss: 1.6995 - val_kl_loss: 0.0022 - val_loss: 3.4252 - val_reconstruction_loss: 1.7240 - learning_rate: 0.0010\n",
      "Epoch 23/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7372 - kl_loss: 0.0022 - loss: 3.5036 - reconstruction_loss: 1.7646 - val_ae_loss: 1.6980 - val_kl_loss: 0.0020 - val_loss: 3.4220 - val_reconstruction_loss: 1.7225 - learning_rate: 0.0010\n",
      "Epoch 24/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7536 - kl_loss: 0.0021 - loss: 3.5345 - reconstruction_loss: 1.7793 - val_ae_loss: 1.6963 - val_kl_loss: 0.0018 - val_loss: 3.4237 - val_reconstruction_loss: 1.7259 - learning_rate: 0.0010\n",
      "Epoch 25/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7736 - kl_loss: 0.0020 - loss: 3.5779 - reconstruction_loss: 1.8027 - val_ae_loss: 1.6946 - val_kl_loss: 0.0016 - val_loss: 3.4270 - val_reconstruction_loss: 1.7312 - learning_rate: 0.0010\n",
      "Epoch 26/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7518 - kl_loss: 0.0016 - loss: 3.5336 - reconstruction_loss: 1.7805 - val_ae_loss: 1.6925 - val_kl_loss: 0.0015 - val_loss: 3.4172 - val_reconstruction_loss: 1.7235 - learning_rate: 0.0010\n",
      "Epoch 27/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - ae_loss: 1.7606 - kl_loss: 0.0015 - loss: 3.5491 - reconstruction_loss: 1.7873 - val_ae_loss: 1.6904 - val_kl_loss: 0.0014 - val_loss: 3.4161 - val_reconstruction_loss: 1.7246 - learning_rate: 0.0010\n",
      "Epoch 28/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7514 - kl_loss: 0.0014 - loss: 3.5314 - reconstruction_loss: 1.7789 - val_ae_loss: 1.6881 - val_kl_loss: 0.0013 - val_loss: 3.4127 - val_reconstruction_loss: 1.7236 - learning_rate: 0.0010\n",
      "Epoch 29/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7533 - kl_loss: 0.0012 - loss: 3.5375 - reconstruction_loss: 1.7832 - val_ae_loss: 1.6855 - val_kl_loss: 0.0012 - val_loss: 3.4121 - val_reconstruction_loss: 1.7257 - learning_rate: 0.0010\n",
      "Epoch 30/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7661 - kl_loss: 0.0011 - loss: 3.5694 - reconstruction_loss: 1.8025 - val_ae_loss: 1.6826 - val_kl_loss: 0.0011 - val_loss: 3.4077 - val_reconstruction_loss: 1.7242 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:51:09,192 - INFO - Hybrid Autoencoder-VAE training completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:51:09,825 - INFO - Dynamic threshold: 0.604404 (fallback: 0.170850)\n",
      "2025-03-22 12:51:10,039 - INFO - Latent dim 3: validation loss = 3.407724\n",
      "2025-03-22 12:51:10,112 - INFO - Starting hybrid Autoencoder-VAE training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - ae_loss: 6.5959 - kl_loss: 0.1359 - loss: 13.1339 - reconstruction_loss: 6.4293 - val_ae_loss: 6.2265 - val_kl_loss: 0.0783 - val_loss: 12.1332 - val_reconstruction_loss: 5.8440 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 6.1934 - kl_loss: 0.0882 - loss: 12.0794 - reconstruction_loss: 5.8155 - val_ae_loss: 5.4515 - val_kl_loss: 0.0882 - val_loss: 10.6189 - val_reconstruction_loss: 5.0969 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 5.2763 - kl_loss: 0.1099 - loss: 10.3423 - reconstruction_loss: 4.9780 - val_ae_loss: 4.2356 - val_kl_loss: 0.1601 - val_loss: 8.5677 - val_reconstruction_loss: 4.2040 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 3.9736 - kl_loss: 0.2033 - loss: 8.0363 - reconstruction_loss: 3.9000 - val_ae_loss: 2.9216 - val_kl_loss: 0.2766 - val_loss: 6.2075 - val_reconstruction_loss: 3.0647 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 2.6970 - kl_loss: 0.3151 - loss: 5.9847 - reconstruction_loss: 3.0357 - val_ae_loss: 1.9777 - val_kl_loss: 0.2756 - val_loss: 4.6783 - val_reconstruction_loss: 2.4801 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.9241 - kl_loss: 0.2535 - loss: 4.5604 - reconstruction_loss: 2.4334 - val_ae_loss: 1.7474 - val_kl_loss: 0.1522 - val_loss: 3.9751 - val_reconstruction_loss: 2.1059 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.8090 - kl_loss: 0.1345 - loss: 4.1062 - reconstruction_loss: 2.1896 - val_ae_loss: 1.7215 - val_kl_loss: 0.0833 - val_loss: 3.7559 - val_reconstruction_loss: 1.9677 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7539 - kl_loss: 0.0752 - loss: 3.8017 - reconstruction_loss: 1.9875 - val_ae_loss: 1.7167 - val_kl_loss: 0.0473 - val_loss: 3.6200 - val_reconstruction_loss: 1.8654 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - ae_loss: 1.7825 - kl_loss: 0.0450 - loss: 3.7842 - reconstruction_loss: 1.9657 - val_ae_loss: 1.7147 - val_kl_loss: 0.0282 - val_loss: 3.5634 - val_reconstruction_loss: 1.8261 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7934 - kl_loss: 0.0263 - loss: 3.7276 - reconstruction_loss: 1.9131 - val_ae_loss: 1.7132 - val_kl_loss: 0.0176 - val_loss: 3.5224 - val_reconstruction_loss: 1.7951 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7663 - kl_loss: 0.0169 - loss: 3.6251 - reconstruction_loss: 1.8453 - val_ae_loss: 1.7117 - val_kl_loss: 0.0123 - val_loss: 3.4942 - val_reconstruction_loss: 1.7726 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7585 - kl_loss: 0.0128 - loss: 3.5814 - reconstruction_loss: 1.8127 - val_ae_loss: 1.7101 - val_kl_loss: 0.0091 - val_loss: 3.4752 - val_reconstruction_loss: 1.7579 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7458 - kl_loss: 0.0094 - loss: 3.5367 - reconstruction_loss: 1.7833 - val_ae_loss: 1.7083 - val_kl_loss: 0.0071 - val_loss: 3.4728 - val_reconstruction_loss: 1.7588 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7606 - kl_loss: 0.0073 - loss: 3.5690 - reconstruction_loss: 1.8025 - val_ae_loss: 1.7064 - val_kl_loss: 0.0057 - val_loss: 3.4415 - val_reconstruction_loss: 1.7306 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7779 - kl_loss: 0.0059 - loss: 3.5953 - reconstruction_loss: 1.8127 - val_ae_loss: 1.7043 - val_kl_loss: 0.0046 - val_loss: 3.4466 - val_reconstruction_loss: 1.7386 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7359 - kl_loss: 0.0051 - loss: 3.5082 - reconstruction_loss: 1.7682 - val_ae_loss: 1.7019 - val_kl_loss: 0.0038 - val_loss: 3.4373 - val_reconstruction_loss: 1.7324 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7406 - kl_loss: 0.0042 - loss: 3.5159 - reconstruction_loss: 1.7720 - val_ae_loss: 1.6988 - val_kl_loss: 0.0032 - val_loss: 3.4359 - val_reconstruction_loss: 1.7346 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7418 - kl_loss: 0.0033 - loss: 3.5269 - reconstruction_loss: 1.7825 - val_ae_loss: 1.6952 - val_kl_loss: 0.0027 - val_loss: 3.4292 - val_reconstruction_loss: 1.7319 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7663 - kl_loss: 0.0028 - loss: 3.5671 - reconstruction_loss: 1.7986 - val_ae_loss: 1.6907 - val_kl_loss: 0.0023 - val_loss: 3.4207 - val_reconstruction_loss: 1.7282 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7279 - kl_loss: 0.0024 - loss: 3.4907 - reconstruction_loss: 1.7609 - val_ae_loss: 1.6850 - val_kl_loss: 0.0020 - val_loss: 3.4137 - val_reconstruction_loss: 1.7271 - learning_rate: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7464 - kl_loss: 0.0021 - loss: 3.5386 - reconstruction_loss: 1.7906 - val_ae_loss: 1.6782 - val_kl_loss: 0.0017 - val_loss: 3.4129 - val_reconstruction_loss: 1.7333 - learning_rate: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - ae_loss: 1.7474 - kl_loss: 0.0020 - loss: 3.5463 - reconstruction_loss: 1.7973 - val_ae_loss: 1.6744 - val_kl_loss: 0.0015 - val_loss: 3.4030 - val_reconstruction_loss: 1.7274 - learning_rate: 0.0010\n",
      "Epoch 23/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7118 - kl_loss: 0.0016 - loss: 3.4744 - reconstruction_loss: 1.7614 - val_ae_loss: 1.6712 - val_kl_loss: 0.0014 - val_loss: 3.3986 - val_reconstruction_loss: 1.7263 - learning_rate: 0.0010\n",
      "Epoch 24/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7148 - kl_loss: 0.0014 - loss: 3.4926 - reconstruction_loss: 1.7767 - val_ae_loss: 1.6682 - val_kl_loss: 0.0012 - val_loss: 3.3951 - val_reconstruction_loss: 1.7259 - learning_rate: 0.0010\n",
      "Epoch 25/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7346 - kl_loss: 0.0014 - loss: 3.5315 - reconstruction_loss: 1.7958 - val_ae_loss: 1.6655 - val_kl_loss: 0.0011 - val_loss: 3.3892 - val_reconstruction_loss: 1.7228 - learning_rate: 0.0010\n",
      "Epoch 26/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7112 - kl_loss: 0.0012 - loss: 3.4910 - reconstruction_loss: 1.7788 - val_ae_loss: 1.6630 - val_kl_loss: 9.7240e-04 - val_loss: 3.3864 - val_reconstruction_loss: 1.7226 - learning_rate: 0.0010\n",
      "Epoch 27/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7057 - kl_loss: 0.0010 - loss: 3.4781 - reconstruction_loss: 1.7716 - val_ae_loss: 1.6602 - val_kl_loss: 8.8135e-04 - val_loss: 3.3854 - val_reconstruction_loss: 1.7245 - learning_rate: 0.0010\n",
      "Epoch 28/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7080 - kl_loss: 9.4674e-04 - loss: 3.4842 - reconstruction_loss: 1.7755 - val_ae_loss: 1.6580 - val_kl_loss: 7.9736e-04 - val_loss: 3.3880 - val_reconstruction_loss: 1.7293 - learning_rate: 0.0010\n",
      "Epoch 29/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.6905 - kl_loss: 8.0280e-04 - loss: 3.4533 - reconstruction_loss: 1.7621 - val_ae_loss: 1.6549 - val_kl_loss: 7.3734e-04 - val_loss: 3.3752 - val_reconstruction_loss: 1.7197 - learning_rate: 0.0010\n",
      "Epoch 30/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.6861 - kl_loss: 7.3460e-04 - loss: 3.4449 - reconstruction_loss: 1.7583 - val_ae_loss: 1.6522 - val_kl_loss: 6.7493e-04 - val_loss: 3.3742 - val_reconstruction_loss: 1.7215 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:51:17,474 - INFO - Hybrid Autoencoder-VAE training completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:51:18,110 - INFO - Dynamic threshold: 1.692072 (fallback: 0.168434)\n",
      "2025-03-22 12:51:18,249 - INFO - Latent dim 4: validation loss = 3.374154\n",
      "2025-03-22 12:51:18,308 - INFO - Starting hybrid Autoencoder-VAE training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - ae_loss: 6.6879 - kl_loss: 0.0958 - loss: 13.1605 - reconstruction_loss: 6.3959 - val_ae_loss: 6.1958 - val_kl_loss: 0.0450 - val_loss: 12.0233 - val_reconstruction_loss: 5.7916 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 6.1058 - kl_loss: 0.0491 - loss: 11.8287 - reconstruction_loss: 5.6837 - val_ae_loss: 5.3781 - val_kl_loss: 0.0471 - val_loss: 10.5784 - val_reconstruction_loss: 5.1626 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 5.1560 - kl_loss: 0.0602 - loss: 10.1362 - reconstruction_loss: 4.9321 - val_ae_loss: 4.1366 - val_kl_loss: 0.0826 - val_loss: 8.3917 - val_reconstruction_loss: 4.1890 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 3.8281 - kl_loss: 0.1078 - loss: 7.8878 - reconstruction_loss: 3.9735 - val_ae_loss: 2.9376 - val_kl_loss: 0.1407 - val_loss: 6.3746 - val_reconstruction_loss: 3.3245 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 2.7508 - kl_loss: 0.1619 - loss: 6.1364 - reconstruction_loss: 3.2561 - val_ae_loss: 2.1689 - val_kl_loss: 0.1396 - val_loss: 4.8933 - val_reconstruction_loss: 2.6127 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 2.0869 - kl_loss: 0.1414 - loss: 4.7483 - reconstruction_loss: 2.5482 - val_ae_loss: 1.8401 - val_kl_loss: 0.0967 - val_loss: 4.1310 - val_reconstruction_loss: 2.2136 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.8730 - kl_loss: 0.0961 - loss: 4.1980 - reconstruction_loss: 2.2481 - val_ae_loss: 1.7551 - val_kl_loss: 0.0598 - val_loss: 3.8630 - val_reconstruction_loss: 2.0601 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7884 - kl_loss: 0.0576 - loss: 3.8936 - reconstruction_loss: 2.0591 - val_ae_loss: 1.7338 - val_kl_loss: 0.0355 - val_loss: 3.7133 - val_reconstruction_loss: 1.9511 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7746 - kl_loss: 0.0347 - loss: 3.7273 - reconstruction_loss: 1.9249 - val_ae_loss: 1.7269 - val_kl_loss: 0.0219 - val_loss: 3.5897 - val_reconstruction_loss: 1.8454 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7797 - kl_loss: 0.0210 - loss: 3.6753 - reconstruction_loss: 1.8788 - val_ae_loss: 1.7235 - val_kl_loss: 0.0144 - val_loss: 3.5210 - val_reconstruction_loss: 1.7860 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7967 - kl_loss: 0.0139 - loss: 3.6710 - reconstruction_loss: 1.8632 - val_ae_loss: 1.7214 - val_kl_loss: 0.0098 - val_loss: 3.5212 - val_reconstruction_loss: 1.7919 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7647 - kl_loss: 0.0096 - loss: 3.5857 - reconstruction_loss: 1.8133 - val_ae_loss: 1.7200 - val_kl_loss: 0.0067 - val_loss: 3.4891 - val_reconstruction_loss: 1.7638 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7815 - kl_loss: 0.0063 - loss: 3.6158 - reconstruction_loss: 1.8292 - val_ae_loss: 1.7188 - val_kl_loss: 0.0048 - val_loss: 3.4849 - val_reconstruction_loss: 1.7623 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7634 - kl_loss: 0.0045 - loss: 3.5632 - reconstruction_loss: 1.7962 - val_ae_loss: 1.7177 - val_kl_loss: 0.0036 - val_loss: 3.4646 - val_reconstruction_loss: 1.7440 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7619 - kl_loss: 0.0034 - loss: 3.5583 - reconstruction_loss: 1.7937 - val_ae_loss: 1.7167 - val_kl_loss: 0.0029 - val_loss: 3.4644 - val_reconstruction_loss: 1.7453 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7576 - kl_loss: 0.0027 - loss: 3.5414 - reconstruction_loss: 1.7817 - val_ae_loss: 1.7158 - val_kl_loss: 0.0023 - val_loss: 3.4475 - val_reconstruction_loss: 1.7298 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7490 - kl_loss: 0.0021 - loss: 3.5226 - reconstruction_loss: 1.7720 - val_ae_loss: 1.7149 - val_kl_loss: 0.0020 - val_loss: 3.4505 - val_reconstruction_loss: 1.7340 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7501 - kl_loss: 0.0016 - loss: 3.5239 - reconstruction_loss: 1.7724 - val_ae_loss: 1.7139 - val_kl_loss: 0.0017 - val_loss: 3.4511 - val_reconstruction_loss: 1.7359 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7715 - kl_loss: 0.0013 - loss: 3.5661 - reconstruction_loss: 1.7936 - val_ae_loss: 1.7129 - val_kl_loss: 0.0014 - val_loss: 3.4564 - val_reconstruction_loss: 1.7424 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7581 - kl_loss: 0.0013 - loss: 3.5399 - reconstruction_loss: 1.7808 - val_ae_loss: 1.7119 - val_kl_loss: 0.0012 - val_loss: 3.4424 - val_reconstruction_loss: 1.7295 - learning_rate: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7766 - kl_loss: 0.0010 - loss: 3.5780 - reconstruction_loss: 1.8006 - val_ae_loss: 1.7106 - val_kl_loss: 0.0011 - val_loss: 3.4436 - val_reconstruction_loss: 1.7322 - learning_rate: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7441 - kl_loss: 7.6737e-04 - loss: 3.5118 - reconstruction_loss: 1.7671 - val_ae_loss: 1.7092 - val_kl_loss: 9.4198e-04 - val_loss: 3.4437 - val_reconstruction_loss: 1.7338 - learning_rate: 0.0010\n",
      "Epoch 23/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7513 - kl_loss: 7.3910e-04 - loss: 3.5247 - reconstruction_loss: 1.7728 - val_ae_loss: 1.7078 - val_kl_loss: 8.4028e-04 - val_loss: 3.4411 - val_reconstruction_loss: 1.7326 - learning_rate: 0.0010\n",
      "Epoch 24/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7358 - kl_loss: 6.0006e-04 - loss: 3.4963 - reconstruction_loss: 1.7601 - val_ae_loss: 1.7063 - val_kl_loss: 7.6382e-04 - val_loss: 3.4358 - val_reconstruction_loss: 1.7289 - learning_rate: 0.0010\n",
      "Epoch 25/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7382 - kl_loss: 5.2076e-04 - loss: 3.5008 - reconstruction_loss: 1.7622 - val_ae_loss: 1.7044 - val_kl_loss: 6.9038e-04 - val_loss: 3.4324 - val_reconstruction_loss: 1.7274 - learning_rate: 0.0010\n",
      "Epoch 26/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7670 - kl_loss: 5.2022e-04 - loss: 3.5642 - reconstruction_loss: 1.7968 - val_ae_loss: 1.7025 - val_kl_loss: 6.2619e-04 - val_loss: 3.4250 - val_reconstruction_loss: 1.7219 - learning_rate: 0.0010\n",
      "Epoch 27/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7443 - kl_loss: 3.8146e-04 - loss: 3.5190 - reconstruction_loss: 1.7744 - val_ae_loss: 1.7004 - val_kl_loss: 5.7315e-04 - val_loss: 3.4256 - val_reconstruction_loss: 1.7248 - learning_rate: 0.0010\n",
      "Epoch 28/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - ae_loss: 1.7685 - kl_loss: 4.3963e-04 - loss: 3.5677 - reconstruction_loss: 1.7988 - val_ae_loss: 1.6983 - val_kl_loss: 5.2763e-04 - val_loss: 3.4223 - val_reconstruction_loss: 1.7236 - learning_rate: 0.0010\n",
      "Epoch 29/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7585 - kl_loss: 3.5370e-04 - loss: 3.5500 - reconstruction_loss: 1.7913 - val_ae_loss: 1.6958 - val_kl_loss: 4.8343e-04 - val_loss: 3.4194 - val_reconstruction_loss: 1.7232 - learning_rate: 0.0010\n",
      "Epoch 30/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7306 - kl_loss: 2.9822e-04 - loss: 3.4929 - reconstruction_loss: 1.7621 - val_ae_loss: 1.6933 - val_kl_loss: 4.4366e-04 - val_loss: 3.4185 - val_reconstruction_loss: 1.7248 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:51:26,049 - INFO - Hybrid Autoencoder-VAE training completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:51:26,546 - INFO - Dynamic threshold: 0.637989 (fallback: 0.170936)\n",
      "2025-03-22 12:51:26,666 - INFO - Latent dim 5: validation loss = 3.418460\n",
      "2025-03-22 12:51:26,712 - INFO - Starting hybrid Autoencoder-VAE training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - ae_loss: 6.6942 - kl_loss: 0.1117 - loss: 13.7246 - reconstruction_loss: 6.9410 - val_ae_loss: 6.2935 - val_kl_loss: 0.0706 - val_loss: 12.6008 - val_reconstruction_loss: 6.2508 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 6.3048 - kl_loss: 0.0672 - loss: 12.6404 - reconstruction_loss: 6.2818 - val_ae_loss: 5.6420 - val_kl_loss: 0.0538 - val_loss: 11.3207 - val_reconstruction_loss: 5.6356 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 5.5060 - kl_loss: 0.0523 - loss: 11.1333 - reconstruction_loss: 5.5855 - val_ae_loss: 4.4203 - val_kl_loss: 0.0454 - val_loss: 9.3908 - val_reconstruction_loss: 4.9342 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 4.1994 - kl_loss: 0.0446 - loss: 9.0959 - reconstruction_loss: 4.8608 - val_ae_loss: 2.9103 - val_kl_loss: 0.0508 - val_loss: 7.0167 - val_reconstruction_loss: 4.0657 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 2.7885 - kl_loss: 0.0556 - loss: 6.7837 - reconstruction_loss: 3.9508 - val_ae_loss: 2.0022 - val_kl_loss: 0.0676 - val_loss: 5.3547 - val_reconstruction_loss: 3.2985 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 2.0023 - kl_loss: 0.0762 - loss: 5.2023 - reconstruction_loss: 3.1390 - val_ae_loss: 1.7568 - val_kl_loss: 0.0889 - val_loss: 4.3640 - val_reconstruction_loss: 2.5361 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.8066 - kl_loss: 0.0935 - loss: 4.3846 - reconstruction_loss: 2.5032 - val_ae_loss: 1.7224 - val_kl_loss: 0.0878 - val_loss: 3.9172 - val_reconstruction_loss: 2.1245 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7826 - kl_loss: 0.0864 - loss: 4.0141 - reconstruction_loss: 2.1624 - val_ae_loss: 1.7165 - val_kl_loss: 0.0667 - val_loss: 3.8007 - val_reconstruction_loss: 2.0308 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7792 - kl_loss: 0.0639 - loss: 3.8474 - reconstruction_loss: 2.0171 - val_ae_loss: 1.7145 - val_kl_loss: 0.0459 - val_loss: 3.6223 - val_reconstruction_loss: 1.8712 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7741 - kl_loss: 0.0438 - loss: 3.7284 - reconstruction_loss: 1.9193 - val_ae_loss: 1.7133 - val_kl_loss: 0.0312 - val_loss: 3.5680 - val_reconstruction_loss: 1.8298 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7832 - kl_loss: 0.0294 - loss: 3.6910 - reconstruction_loss: 1.8842 - val_ae_loss: 1.7123 - val_kl_loss: 0.0211 - val_loss: 3.5360 - val_reconstruction_loss: 1.8068 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7576 - kl_loss: 0.0195 - loss: 3.6047 - reconstruction_loss: 1.8316 - val_ae_loss: 1.7114 - val_kl_loss: 0.0144 - val_loss: 3.4988 - val_reconstruction_loss: 1.7758 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7667 - kl_loss: 0.0132 - loss: 3.6053 - reconstruction_loss: 1.8280 - val_ae_loss: 1.7105 - val_kl_loss: 0.0103 - val_loss: 3.4757 - val_reconstruction_loss: 1.7569 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7642 - kl_loss: 0.0095 - loss: 3.5932 - reconstruction_loss: 1.8214 - val_ae_loss: 1.7097 - val_kl_loss: 0.0073 - val_loss: 3.4715 - val_reconstruction_loss: 1.7560 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7857 - kl_loss: 0.0066 - loss: 3.6163 - reconstruction_loss: 1.8252 - val_ae_loss: 1.7087 - val_kl_loss: 0.0052 - val_loss: 3.4669 - val_reconstruction_loss: 1.7540 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7719 - kl_loss: 0.0047 - loss: 3.5787 - reconstruction_loss: 1.8030 - val_ae_loss: 1.7077 - val_kl_loss: 0.0038 - val_loss: 3.4541 - val_reconstruction_loss: 1.7433 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7494 - kl_loss: 0.0033 - loss: 3.5313 - reconstruction_loss: 1.7793 - val_ae_loss: 1.7066 - val_kl_loss: 0.0029 - val_loss: 3.4409 - val_reconstruction_loss: 1.7319 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7823 - kl_loss: 0.0026 - loss: 3.5915 - reconstruction_loss: 1.8072 - val_ae_loss: 1.7055 - val_kl_loss: 0.0022 - val_loss: 3.4440 - val_reconstruction_loss: 1.7367 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7506 - kl_loss: 0.0019 - loss: 3.5314 - reconstruction_loss: 1.7793 - val_ae_loss: 1.7042 - val_kl_loss: 0.0017 - val_loss: 3.4358 - val_reconstruction_loss: 1.7302 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7498 - kl_loss: 0.0013 - loss: 3.5261 - reconstruction_loss: 1.7752 - val_ae_loss: 1.7029 - val_kl_loss: 0.0014 - val_loss: 3.4327 - val_reconstruction_loss: 1.7287 - learning_rate: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7476 - kl_loss: 0.0011 - loss: 3.5186 - reconstruction_loss: 1.7700 - val_ae_loss: 1.7013 - val_kl_loss: 0.0012 - val_loss: 3.4280 - val_reconstruction_loss: 1.7257 - learning_rate: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7539 - kl_loss: 0.0011 - loss: 3.5361 - reconstruction_loss: 1.7813 - val_ae_loss: 1.6997 - val_kl_loss: 9.7912e-04 - val_loss: 3.4304 - val_reconstruction_loss: 1.7300 - learning_rate: 0.0010\n",
      "Epoch 23/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7597 - kl_loss: 7.2710e-04 - loss: 3.5444 - reconstruction_loss: 1.7842 - val_ae_loss: 1.6979 - val_kl_loss: 8.4934e-04 - val_loss: 3.4258 - val_reconstruction_loss: 1.7273 - learning_rate: 0.0010\n",
      "Epoch 24/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7342 - kl_loss: 6.0595e-04 - loss: 3.4972 - reconstruction_loss: 1.7625 - val_ae_loss: 1.6958 - val_kl_loss: 7.5948e-04 - val_loss: 3.4236 - val_reconstruction_loss: 1.7271 - learning_rate: 0.0010\n",
      "Epoch 25/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7748 - kl_loss: 5.5456e-04 - loss: 3.5790 - reconstruction_loss: 1.8037 - val_ae_loss: 1.6938 - val_kl_loss: 6.7588e-04 - val_loss: 3.4221 - val_reconstruction_loss: 1.7277 - learning_rate: 0.0010\n",
      "Epoch 26/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7526 - kl_loss: 4.2506e-04 - loss: 3.5361 - reconstruction_loss: 1.7832 - val_ae_loss: 1.6918 - val_kl_loss: 6.0863e-04 - val_loss: 3.4198 - val_reconstruction_loss: 1.7275 - learning_rate: 0.0010\n",
      "Epoch 27/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7629 - kl_loss: 4.5350e-04 - loss: 3.5586 - reconstruction_loss: 1.7953 - val_ae_loss: 1.6895 - val_kl_loss: 5.5190e-04 - val_loss: 3.4136 - val_reconstruction_loss: 1.7237 - learning_rate: 0.0010\n",
      "Epoch 28/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7426 - kl_loss: 3.3819e-04 - loss: 3.5148 - reconstruction_loss: 1.7719 - val_ae_loss: 1.6869 - val_kl_loss: 5.0334e-04 - val_loss: 3.4156 - val_reconstruction_loss: 1.7283 - learning_rate: 0.0010\n",
      "Epoch 29/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7293 - kl_loss: 2.7558e-04 - loss: 3.4905 - reconstruction_loss: 1.7610 - val_ae_loss: 1.6840 - val_kl_loss: 4.6564e-04 - val_loss: 3.4106 - val_reconstruction_loss: 1.7262 - learning_rate: 0.0010\n",
      "Epoch 30/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7381 - kl_loss: 2.5920e-04 - loss: 3.5132 - reconstruction_loss: 1.7749 - val_ae_loss: 1.6806 - val_kl_loss: 4.3495e-04 - val_loss: 3.4042 - val_reconstruction_loss: 1.7232 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:51:34,411 - INFO - Hybrid Autoencoder-VAE training completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:51:34,911 - INFO - Dynamic threshold: 0.711018 (fallback: 0.168702)\n",
      "2025-03-22 12:51:35,032 - INFO - Latent dim 6: validation loss = 3.404155\n",
      "2025-03-22 12:51:35,080 - INFO - Starting hybrid Autoencoder-VAE training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - ae_loss: 6.7202 - kl_loss: 0.0489 - loss: 13.5652 - reconstruction_loss: 6.8058 - val_ae_loss: 6.3266 - val_kl_loss: 0.0277 - val_loss: 12.6093 - val_reconstruction_loss: 6.2605 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 6.3647 - kl_loss: 0.0208 - loss: 12.6922 - reconstruction_loss: 6.3109 - val_ae_loss: 5.7763 - val_kl_loss: 0.0190 - val_loss: 11.5375 - val_reconstruction_loss: 5.7460 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 5.6744 - kl_loss: 0.0168 - loss: 11.3765 - reconstruction_loss: 5.6887 - val_ae_loss: 4.7927 - val_kl_loss: 0.0238 - val_loss: 9.8019 - val_reconstruction_loss: 4.9902 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 4.5460 - kl_loss: 0.0244 - loss: 9.4438 - reconstruction_loss: 4.8783 - val_ae_loss: 3.4213 - val_kl_loss: 0.0413 - val_loss: 7.5063 - val_reconstruction_loss: 4.0520 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - ae_loss: 3.1843 - kl_loss: 0.0448 - loss: 7.0735 - reconstruction_loss: 3.8534 - val_ae_loss: 2.2845 - val_kl_loss: 0.0722 - val_loss: 5.3939 - val_reconstruction_loss: 3.0516 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - ae_loss: 2.2385 - kl_loss: 0.0740 - loss: 5.2549 - reconstruction_loss: 2.9572 - val_ae_loss: 1.8365 - val_kl_loss: 0.0898 - val_loss: 4.2411 - val_reconstruction_loss: 2.3328 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - ae_loss: 1.8750 - kl_loss: 0.0839 - loss: 4.3172 - reconstruction_loss: 2.3751 - val_ae_loss: 1.7414 - val_kl_loss: 0.0747 - val_loss: 3.8660 - val_reconstruction_loss: 2.0648 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7877 - kl_loss: 0.0657 - loss: 3.8633 - reconstruction_loss: 2.0229 - val_ae_loss: 1.7237 - val_kl_loss: 0.0485 - val_loss: 3.6833 - val_reconstruction_loss: 1.9208 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7882 - kl_loss: 0.0419 - loss: 3.7722 - reconstruction_loss: 1.9505 - val_ae_loss: 1.7190 - val_kl_loss: 0.0291 - val_loss: 3.5946 - val_reconstruction_loss: 1.8524 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7541 - kl_loss: 0.0249 - loss: 3.6386 - reconstruction_loss: 1.8646 - val_ae_loss: 1.7169 - val_kl_loss: 0.0174 - val_loss: 3.5309 - val_reconstruction_loss: 1.8001 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7690 - kl_loss: 0.0148 - loss: 3.6402 - reconstruction_loss: 1.8594 - val_ae_loss: 1.7156 - val_kl_loss: 0.0107 - val_loss: 3.5125 - val_reconstruction_loss: 1.7883 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7767 - kl_loss: 0.0092 - loss: 3.6212 - reconstruction_loss: 1.8372 - val_ae_loss: 1.7146 - val_kl_loss: 0.0069 - val_loss: 3.4800 - val_reconstruction_loss: 1.7599 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7906 - kl_loss: 0.0058 - loss: 3.6422 - reconstruction_loss: 1.8470 - val_ae_loss: 1.7138 - val_kl_loss: 0.0045 - val_loss: 3.4696 - val_reconstruction_loss: 1.7523 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7971 - kl_loss: 0.0037 - loss: 3.6467 - reconstruction_loss: 1.8466 - val_ae_loss: 1.7130 - val_kl_loss: 0.0030 - val_loss: 3.4718 - val_reconstruction_loss: 1.7565 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7608 - kl_loss: 0.0024 - loss: 3.5568 - reconstruction_loss: 1.7941 - val_ae_loss: 1.7122 - val_kl_loss: 0.0020 - val_loss: 3.4471 - val_reconstruction_loss: 1.7332 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7589 - kl_loss: 0.0016 - loss: 3.5460 - reconstruction_loss: 1.7858 - val_ae_loss: 1.7115 - val_kl_loss: 0.0014 - val_loss: 3.4524 - val_reconstruction_loss: 1.7398 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7693 - kl_loss: 0.0010 - loss: 3.5598 - reconstruction_loss: 1.7896 - val_ae_loss: 1.7107 - val_kl_loss: 0.0010 - val_loss: 3.4509 - val_reconstruction_loss: 1.7394 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7537 - kl_loss: 7.3321e-04 - loss: 3.5332 - reconstruction_loss: 1.7790 - val_ae_loss: 1.7098 - val_kl_loss: 7.8430e-04 - val_loss: 3.4420 - val_reconstruction_loss: 1.7316 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7620 - kl_loss: 5.2883e-04 - loss: 3.5402 - reconstruction_loss: 1.7778 - val_ae_loss: 1.7090 - val_kl_loss: 6.1462e-04 - val_loss: 3.4452 - val_reconstruction_loss: 1.7357 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7526 - kl_loss: 3.3609e-04 - loss: 3.5233 - reconstruction_loss: 1.7705 - val_ae_loss: 1.7080 - val_kl_loss: 5.1098e-04 - val_loss: 3.4432 - val_reconstruction_loss: 1.7347 - learning_rate: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7520 - kl_loss: 2.8810e-04 - loss: 3.5221 - reconstruction_loss: 1.7698 - val_ae_loss: 1.7071 - val_kl_loss: 4.3940e-04 - val_loss: 3.4425 - val_reconstruction_loss: 1.7350 - learning_rate: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7506 - kl_loss: 2.0949e-04 - loss: 3.5173 - reconstruction_loss: 1.7665 - val_ae_loss: 1.7061 - val_kl_loss: 3.8144e-04 - val_loss: 3.4407 - val_reconstruction_loss: 1.7344 - learning_rate: 0.0010\n",
      "Epoch 23/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7584 - kl_loss: 1.8234e-04 - loss: 3.5354 - reconstruction_loss: 1.7769 - val_ae_loss: 1.7050 - val_kl_loss: 3.5298e-04 - val_loss: 3.4355 - val_reconstruction_loss: 1.7303 - learning_rate: 0.0010\n",
      "Epoch 24/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7642 - kl_loss: 1.3930e-04 - loss: 3.5481 - reconstruction_loss: 1.7839 - val_ae_loss: 1.7038 - val_kl_loss: 3.2750e-04 - val_loss: 3.4280 - val_reconstruction_loss: 1.7239 - learning_rate: 0.0010\n",
      "Epoch 25/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7574 - kl_loss: 1.2666e-04 - loss: 3.5353 - reconstruction_loss: 1.7777 - val_ae_loss: 1.7025 - val_kl_loss: 2.9929e-04 - val_loss: 3.4368 - val_reconstruction_loss: 1.7340 - learning_rate: 0.0010\n",
      "Epoch 26/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7870 - kl_loss: 1.1536e-04 - loss: 3.5940 - reconstruction_loss: 1.8070 - val_ae_loss: 1.7012 - val_kl_loss: 2.6658e-04 - val_loss: 3.4251 - val_reconstruction_loss: 1.7237 - learning_rate: 0.0010\n",
      "Epoch 27/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - ae_loss: 1.7581 - kl_loss: 8.3899e-05 - loss: 3.5372 - reconstruction_loss: 1.7791 - val_ae_loss: 1.6998 - val_kl_loss: 2.3346e-04 - val_loss: 3.4247 - val_reconstruction_loss: 1.7247 - learning_rate: 0.0010\n",
      "Epoch 28/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - ae_loss: 1.7387 - kl_loss: 6.2609e-05 - loss: 3.4979 - reconstruction_loss: 1.7591 - val_ae_loss: 1.6983 - val_kl_loss: 2.1646e-04 - val_loss: 3.4237 - val_reconstruction_loss: 1.7253 - learning_rate: 0.0010\n",
      "Epoch 29/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7488 - kl_loss: 5.8667e-05 - loss: 3.5217 - reconstruction_loss: 1.7729 - val_ae_loss: 1.6967 - val_kl_loss: 2.0207e-04 - val_loss: 3.4210 - val_reconstruction_loss: 1.7241 - learning_rate: 0.0010\n",
      "Epoch 30/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7507 - kl_loss: 4.1806e-05 - loss: 3.5250 - reconstruction_loss: 1.7743 - val_ae_loss: 1.6950 - val_kl_loss: 1.9007e-04 - val_loss: 3.4176 - val_reconstruction_loss: 1.7225 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:51:42,871 - INFO - Hybrid Autoencoder-VAE training completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:51:43,376 - INFO - Dynamic threshold: 0.585683 (fallback: 0.171040)\n",
      "2025-03-22 12:51:43,769 - INFO - Latent dim 7: validation loss = 3.417625\n",
      "2025-03-22 12:51:43,830 - INFO - Starting hybrid Autoencoder-VAE training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - ae_loss: 6.6698 - kl_loss: 0.2162 - loss: 13.6694 - reconstruction_loss: 6.8266 - val_ae_loss: 6.3010 - val_kl_loss: 0.0712 - val_loss: 12.5160 - val_reconstruction_loss: 6.1580 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - ae_loss: 6.3045 - kl_loss: 0.0696 - loss: 12.5034 - reconstruction_loss: 6.1431 - val_ae_loss: 5.7325 - val_kl_loss: 0.0390 - val_loss: 11.2736 - val_reconstruction_loss: 5.5099 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 5.6959 - kl_loss: 0.0458 - loss: 11.1870 - reconstruction_loss: 5.4544 - val_ae_loss: 4.7304 - val_kl_loss: 0.0434 - val_loss: 9.5539 - val_reconstruction_loss: 4.7888 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 4.5410 - kl_loss: 0.0560 - loss: 9.1956 - reconstruction_loss: 4.6097 - val_ae_loss: 3.3200 - val_kl_loss: 0.0664 - val_loss: 7.1033 - val_reconstruction_loss: 3.7303 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 3.1762 - kl_loss: 0.0837 - loss: 6.9250 - reconstruction_loss: 3.6818 - val_ae_loss: 2.1833 - val_kl_loss: 0.1112 - val_loss: 5.1787 - val_reconstruction_loss: 2.9065 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 2.1719 - kl_loss: 0.1235 - loss: 5.1796 - reconstruction_loss: 2.9089 - val_ae_loss: 1.7828 - val_kl_loss: 0.1205 - val_loss: 4.1359 - val_reconstruction_loss: 2.2568 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.8367 - kl_loss: 0.1216 - loss: 4.2777 - reconstruction_loss: 2.3437 - val_ae_loss: 1.7219 - val_kl_loss: 0.0842 - val_loss: 3.8224 - val_reconstruction_loss: 2.0331 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7970 - kl_loss: 0.0806 - loss: 3.9902 - reconstruction_loss: 2.1287 - val_ae_loss: 1.7146 - val_kl_loss: 0.0541 - val_loss: 3.6598 - val_reconstruction_loss: 1.9019 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7751 - kl_loss: 0.0501 - loss: 3.7763 - reconstruction_loss: 1.9611 - val_ae_loss: 1.7130 - val_kl_loss: 0.0324 - val_loss: 3.5787 - val_reconstruction_loss: 1.8397 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7770 - kl_loss: 0.0296 - loss: 3.6924 - reconstruction_loss: 1.8918 - val_ae_loss: 1.7121 - val_kl_loss: 0.0205 - val_loss: 3.5236 - val_reconstruction_loss: 1.7952 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7487 - kl_loss: 0.0189 - loss: 3.5911 - reconstruction_loss: 1.8273 - val_ae_loss: 1.7113 - val_kl_loss: 0.0134 - val_loss: 3.4997 - val_reconstruction_loss: 1.7777 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7641 - kl_loss: 0.0120 - loss: 3.5953 - reconstruction_loss: 1.8216 - val_ae_loss: 1.7104 - val_kl_loss: 0.0089 - val_loss: 3.4800 - val_reconstruction_loss: 1.7625 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7895 - kl_loss: 0.0084 - loss: 3.6322 - reconstruction_loss: 1.8360 - val_ae_loss: 1.7094 - val_kl_loss: 0.0061 - val_loss: 3.4748 - val_reconstruction_loss: 1.7605 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7608 - kl_loss: 0.0057 - loss: 3.5649 - reconstruction_loss: 1.7996 - val_ae_loss: 1.7085 - val_kl_loss: 0.0043 - val_loss: 3.4753 - val_reconstruction_loss: 1.7634 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7649 - kl_loss: 0.0039 - loss: 3.5649 - reconstruction_loss: 1.7969 - val_ae_loss: 1.7072 - val_kl_loss: 0.0031 - val_loss: 3.4666 - val_reconstruction_loss: 1.7569 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7633 - kl_loss: 0.0029 - loss: 3.5648 - reconstruction_loss: 1.7993 - val_ae_loss: 1.7059 - val_kl_loss: 0.0023 - val_loss: 3.4390 - val_reconstruction_loss: 1.7313 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7721 - kl_loss: 0.0020 - loss: 3.5797 - reconstruction_loss: 1.8060 - val_ae_loss: 1.7043 - val_kl_loss: 0.0018 - val_loss: 3.4342 - val_reconstruction_loss: 1.7285 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7493 - kl_loss: 0.0015 - loss: 3.5287 - reconstruction_loss: 1.7782 - val_ae_loss: 1.7026 - val_kl_loss: 0.0014 - val_loss: 3.4322 - val_reconstruction_loss: 1.7285 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - ae_loss: 1.7573 - kl_loss: 0.0013 - loss: 3.5471 - reconstruction_loss: 1.7888 - val_ae_loss: 1.7006 - val_kl_loss: 0.0011 - val_loss: 3.4293 - val_reconstruction_loss: 1.7278 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7313 - kl_loss: 0.0011 - loss: 3.4910 - reconstruction_loss: 1.7588 - val_ae_loss: 1.6984 - val_kl_loss: 9.6112e-04 - val_loss: 3.4265 - val_reconstruction_loss: 1.7274 - learning_rate: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7608 - kl_loss: 6.6929e-04 - loss: 3.5475 - reconstruction_loss: 1.7862 - val_ae_loss: 1.6957 - val_kl_loss: 8.1828e-04 - val_loss: 3.4193 - val_reconstruction_loss: 1.7229 - learning_rate: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7607 - kl_loss: 5.7322e-04 - loss: 3.5514 - reconstruction_loss: 1.7902 - val_ae_loss: 1.6925 - val_kl_loss: 7.1025e-04 - val_loss: 3.4173 - val_reconstruction_loss: 1.7242 - learning_rate: 0.0010\n",
      "Epoch 23/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7338 - kl_loss: 4.5346e-04 - loss: 3.4939 - reconstruction_loss: 1.7598 - val_ae_loss: 1.6893 - val_kl_loss: 6.3057e-04 - val_loss: 3.4165 - val_reconstruction_loss: 1.7267 - learning_rate: 0.0010\n",
      "Epoch 24/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7705 - kl_loss: 4.9019e-04 - loss: 3.5733 - reconstruction_loss: 1.8025 - val_ae_loss: 1.6849 - val_kl_loss: 5.6175e-04 - val_loss: 3.4110 - val_reconstruction_loss: 1.7257 - learning_rate: 0.0010\n",
      "Epoch 25/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7340 - kl_loss: 3.4094e-04 - loss: 3.5010 - reconstruction_loss: 1.7668 - val_ae_loss: 1.6806 - val_kl_loss: 5.0777e-04 - val_loss: 3.4024 - val_reconstruction_loss: 1.7214 - learning_rate: 0.0010\n",
      "Epoch 26/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - ae_loss: 1.7452 - kl_loss: 3.3856e-04 - loss: 3.5265 - reconstruction_loss: 1.7810 - val_ae_loss: 1.6749 - val_kl_loss: 4.6155e-04 - val_loss: 3.3980 - val_reconstruction_loss: 1.7227 - learning_rate: 0.0010\n",
      "Epoch 27/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7398 - kl_loss: 2.7647e-04 - loss: 3.5206 - reconstruction_loss: 1.7805 - val_ae_loss: 1.6674 - val_kl_loss: 4.2322e-04 - val_loss: 3.3891 - val_reconstruction_loss: 1.7213 - learning_rate: 0.0010\n",
      "Epoch 28/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7379 - kl_loss: 2.1275e-04 - loss: 3.5225 - reconstruction_loss: 1.7844 - val_ae_loss: 1.6599 - val_kl_loss: 3.8905e-04 - val_loss: 3.3837 - val_reconstruction_loss: 1.7235 - learning_rate: 0.0010\n",
      "Epoch 29/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7254 - kl_loss: 2.1649e-04 - loss: 3.5114 - reconstruction_loss: 1.7859 - val_ae_loss: 1.6479 - val_kl_loss: 3.6093e-04 - val_loss: 3.3743 - val_reconstruction_loss: 1.7262 - learning_rate: 0.0010\n",
      "Epoch 30/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7134 - kl_loss: 2.1750e-04 - loss: 3.4957 - reconstruction_loss: 1.7821 - val_ae_loss: 1.6382 - val_kl_loss: 3.3890e-04 - val_loss: 3.3613 - val_reconstruction_loss: 1.7228 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:51:51,441 - INFO - Hybrid Autoencoder-VAE training completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:51:51,967 - INFO - Dynamic threshold: 0.704048 (fallback: 0.169800)\n",
      "2025-03-22 12:51:52,898 - INFO - Latent dim 8: validation loss = 3.361253\n",
      "2025-03-22 12:51:52,951 - INFO - Starting hybrid Autoencoder-VAE training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - ae_loss: 6.7201 - kl_loss: 0.1123 - loss: 13.9768 - reconstruction_loss: 7.1669 - val_ae_loss: 6.3902 - val_kl_loss: 0.0729 - val_loss: 12.9524 - val_reconstruction_loss: 6.5038 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 6.4572 - kl_loss: 0.0592 - loss: 12.9775 - reconstruction_loss: 6.4728 - val_ae_loss: 5.9768 - val_kl_loss: 0.0450 - val_loss: 11.8850 - val_reconstruction_loss: 5.8721 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 5.9567 - kl_loss: 0.0382 - loss: 11.8200 - reconstruction_loss: 5.8328 - val_ae_loss: 5.2171 - val_kl_loss: 0.0289 - val_loss: 10.4678 - val_reconstruction_loss: 5.2275 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 5.0524 - kl_loss: 0.0263 - loss: 10.1618 - reconstruction_loss: 5.0883 - val_ae_loss: 4.0216 - val_kl_loss: 0.0293 - val_loss: 8.4390 - val_reconstruction_loss: 4.3939 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 3.8983 - kl_loss: 0.0321 - loss: 8.2615 - reconstruction_loss: 4.3374 - val_ae_loss: 2.7697 - val_kl_loss: 0.0440 - val_loss: 6.2161 - val_reconstruction_loss: 3.4112 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 2.6481 - kl_loss: 0.0492 - loss: 6.1369 - reconstruction_loss: 3.4494 - val_ae_loss: 2.0247 - val_kl_loss: 0.0626 - val_loss: 4.8022 - val_reconstruction_loss: 2.7274 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 2.0227 - kl_loss: 0.0651 - loss: 4.7329 - reconstruction_loss: 2.6582 - val_ae_loss: 1.7775 - val_kl_loss: 0.0636 - val_loss: 3.9756 - val_reconstruction_loss: 2.1473 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.8391 - kl_loss: 0.0591 - loss: 4.1075 - reconstruction_loss: 2.2212 - val_ae_loss: 1.7320 - val_kl_loss: 0.0475 - val_loss: 3.7138 - val_reconstruction_loss: 1.9439 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7781 - kl_loss: 0.0425 - loss: 3.7886 - reconstruction_loss: 1.9765 - val_ae_loss: 1.7233 - val_kl_loss: 0.0303 - val_loss: 3.6374 - val_reconstruction_loss: 1.8898 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7707 - kl_loss: 0.0263 - loss: 3.6804 - reconstruction_loss: 1.8887 - val_ae_loss: 1.7207 - val_kl_loss: 0.0184 - val_loss: 3.5253 - val_reconstruction_loss: 1.7898 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7892 - kl_loss: 0.0160 - loss: 3.6789 - reconstruction_loss: 1.8769 - val_ae_loss: 1.7195 - val_kl_loss: 0.0113 - val_loss: 3.5107 - val_reconstruction_loss: 1.7822 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7692 - kl_loss: 0.0097 - loss: 3.6129 - reconstruction_loss: 1.8359 - val_ae_loss: 1.7186 - val_kl_loss: 0.0073 - val_loss: 3.4934 - val_reconstruction_loss: 1.7690 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7872 - kl_loss: 0.0064 - loss: 3.6199 - reconstruction_loss: 1.8276 - val_ae_loss: 1.7179 - val_kl_loss: 0.0048 - val_loss: 3.4703 - val_reconstruction_loss: 1.7486 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7935 - kl_loss: 0.0041 - loss: 3.6303 - reconstruction_loss: 1.8336 - val_ae_loss: 1.7173 - val_kl_loss: 0.0032 - val_loss: 3.4610 - val_reconstruction_loss: 1.7411 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7706 - kl_loss: 0.0027 - loss: 3.5805 - reconstruction_loss: 1.8078 - val_ae_loss: 1.7168 - val_kl_loss: 0.0023 - val_loss: 3.4630 - val_reconstruction_loss: 1.7444 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7562 - kl_loss: 0.0020 - loss: 3.5484 - reconstruction_loss: 1.7906 - val_ae_loss: 1.7162 - val_kl_loss: 0.0018 - val_loss: 3.4703 - val_reconstruction_loss: 1.7527 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7650 - kl_loss: 0.0015 - loss: 3.5523 - reconstruction_loss: 1.7861 - val_ae_loss: 1.7156 - val_kl_loss: 0.0013 - val_loss: 3.4569 - val_reconstruction_loss: 1.7402 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7686 - kl_loss: 0.0011 - loss: 3.5609 - reconstruction_loss: 1.7914 - val_ae_loss: 1.7150 - val_kl_loss: 0.0010 - val_loss: 3.4539 - val_reconstruction_loss: 1.7380 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7850 - kl_loss: 9.1076e-04 - loss: 3.5934 - reconstruction_loss: 1.8077 - val_ae_loss: 1.7144 - val_kl_loss: 8.2208e-04 - val_loss: 3.4483 - val_reconstruction_loss: 1.7333 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7892 - kl_loss: 6.6413e-04 - loss: 3.5972 - reconstruction_loss: 1.8075 - val_ae_loss: 1.7137 - val_kl_loss: 6.7298e-04 - val_loss: 3.4475 - val_reconstruction_loss: 1.7333 - learning_rate: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7698 - kl_loss: 5.4162e-04 - loss: 3.5611 - reconstruction_loss: 1.7909 - val_ae_loss: 1.7129 - val_kl_loss: 5.8939e-04 - val_loss: 3.4439 - val_reconstruction_loss: 1.7304 - learning_rate: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7677 - kl_loss: 4.6330e-04 - loss: 3.5570 - reconstruction_loss: 1.7889 - val_ae_loss: 1.7121 - val_kl_loss: 5.0288e-04 - val_loss: 3.4416 - val_reconstruction_loss: 1.7292 - learning_rate: 0.0010\n",
      "Epoch 23/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7369 - kl_loss: 4.1183e-04 - loss: 3.4942 - reconstruction_loss: 1.7570 - val_ae_loss: 1.7111 - val_kl_loss: 4.3619e-04 - val_loss: 3.4354 - val_reconstruction_loss: 1.7239 - learning_rate: 0.0010\n",
      "Epoch 24/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7839 - kl_loss: 3.1787e-04 - loss: 3.5855 - reconstruction_loss: 1.8014 - val_ae_loss: 1.7100 - val_kl_loss: 3.8082e-04 - val_loss: 3.4384 - val_reconstruction_loss: 1.7282 - learning_rate: 0.0010\n",
      "Epoch 25/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7585 - kl_loss: 2.9914e-04 - loss: 3.5381 - reconstruction_loss: 1.7794 - val_ae_loss: 1.7086 - val_kl_loss: 3.4629e-04 - val_loss: 3.4367 - val_reconstruction_loss: 1.7278 - learning_rate: 0.0010\n",
      "Epoch 26/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7478 - kl_loss: 2.4690e-04 - loss: 3.5181 - reconstruction_loss: 1.7701 - val_ae_loss: 1.7072 - val_kl_loss: 3.1376e-04 - val_loss: 3.4325 - val_reconstruction_loss: 1.7250 - learning_rate: 0.0010\n",
      "Epoch 27/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7667 - kl_loss: 2.0929e-04 - loss: 3.5608 - reconstruction_loss: 1.7939 - val_ae_loss: 1.7056 - val_kl_loss: 2.8284e-04 - val_loss: 3.4314 - val_reconstruction_loss: 1.7257 - learning_rate: 0.0010\n",
      "Epoch 28/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7365 - kl_loss: 1.7739e-04 - loss: 3.4964 - reconstruction_loss: 1.7598 - val_ae_loss: 1.7038 - val_kl_loss: 2.5872e-04 - val_loss: 3.4267 - val_reconstruction_loss: 1.7227 - learning_rate: 0.0010\n",
      "Epoch 29/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7676 - kl_loss: 1.5166e-04 - loss: 3.5609 - reconstruction_loss: 1.7932 - val_ae_loss: 1.7018 - val_kl_loss: 2.3996e-04 - val_loss: 3.4284 - val_reconstruction_loss: 1.7265 - learning_rate: 0.0010\n",
      "Epoch 30/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7556 - kl_loss: 1.5778e-04 - loss: 3.5417 - reconstruction_loss: 1.7860 - val_ae_loss: 1.6997 - val_kl_loss: 2.1642e-04 - val_loss: 3.4254 - val_reconstruction_loss: 1.7255 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:52:00,466 - INFO - Hybrid Autoencoder-VAE training completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:52:00,952 - INFO - Dynamic threshold: 0.727145 (fallback: 0.171343)\n",
      "2025-03-22 12:52:01,069 - INFO - Latent dim 9: validation loss = 3.425392\n",
      "2025-03-22 12:52:01,115 - INFO - Starting hybrid Autoencoder-VAE training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - ae_loss: 6.6303 - kl_loss: 0.2404 - loss: 13.6839 - reconstruction_loss: 6.8612 - val_ae_loss: 6.1826 - val_kl_loss: 0.1125 - val_loss: 12.4777 - val_reconstruction_loss: 6.2052 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 6.1343 - kl_loss: 0.0973 - loss: 12.2909 - reconstruction_loss: 6.0788 - val_ae_loss: 5.3296 - val_kl_loss: 0.0737 - val_loss: 10.6998 - val_reconstruction_loss: 5.3113 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - ae_loss: 5.0993 - kl_loss: 0.0689 - loss: 10.3998 - reconstruction_loss: 5.2454 - val_ae_loss: 3.9037 - val_kl_loss: 0.0683 - val_loss: 8.5616 - val_reconstruction_loss: 4.6033 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 3.6431 - kl_loss: 0.0681 - loss: 8.1307 - reconstruction_loss: 4.4331 - val_ae_loss: 2.4998 - val_kl_loss: 0.0794 - val_loss: 6.1283 - val_reconstruction_loss: 3.5650 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 2.3745 - kl_loss: 0.0804 - loss: 5.8996 - reconstruction_loss: 3.4607 - val_ae_loss: 1.8705 - val_kl_loss: 0.0874 - val_loss: 4.7962 - val_reconstruction_loss: 2.8558 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.8894 - kl_loss: 0.0834 - loss: 4.6969 - reconstruction_loss: 2.7408 - val_ae_loss: 1.7329 - val_kl_loss: 0.0760 - val_loss: 4.0504 - val_reconstruction_loss: 2.2567 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7857 - kl_loss: 0.0673 - loss: 4.0761 - reconstruction_loss: 2.2366 - val_ae_loss: 1.7177 - val_kl_loss: 0.0548 - val_loss: 3.7358 - val_reconstruction_loss: 1.9743 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7719 - kl_loss: 0.0471 - loss: 3.8065 - reconstruction_loss: 1.9969 - val_ae_loss: 1.7153 - val_kl_loss: 0.0374 - val_loss: 3.6205 - val_reconstruction_loss: 1.8753 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7852 - kl_loss: 0.0311 - loss: 3.7243 - reconstruction_loss: 1.9142 - val_ae_loss: 1.7143 - val_kl_loss: 0.0257 - val_loss: 3.5887 - val_reconstruction_loss: 1.8539 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7675 - kl_loss: 0.0210 - loss: 3.6356 - reconstruction_loss: 1.8513 - val_ae_loss: 1.7135 - val_kl_loss: 0.0178 - val_loss: 3.5266 - val_reconstruction_loss: 1.7988 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7633 - kl_loss: 0.0147 - loss: 3.6040 - reconstruction_loss: 1.8289 - val_ae_loss: 1.7128 - val_kl_loss: 0.0128 - val_loss: 3.4826 - val_reconstruction_loss: 1.7595 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7415 - kl_loss: 0.0098 - loss: 3.5440 - reconstruction_loss: 1.7946 - val_ae_loss: 1.7121 - val_kl_loss: 0.0094 - val_loss: 3.4801 - val_reconstruction_loss: 1.7604 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7749 - kl_loss: 0.0071 - loss: 3.6004 - reconstruction_loss: 1.8198 - val_ae_loss: 1.7114 - val_kl_loss: 0.0072 - val_loss: 3.4636 - val_reconstruction_loss: 1.7464 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7528 - kl_loss: 0.0053 - loss: 3.5474 - reconstruction_loss: 1.7904 - val_ae_loss: 1.7106 - val_kl_loss: 0.0056 - val_loss: 3.4685 - val_reconstruction_loss: 1.7534 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7735 - kl_loss: 0.0040 - loss: 3.5828 - reconstruction_loss: 1.8061 - val_ae_loss: 1.7098 - val_kl_loss: 0.0045 - val_loss: 3.4475 - val_reconstruction_loss: 1.7342 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7639 - kl_loss: 0.0030 - loss: 3.5570 - reconstruction_loss: 1.7907 - val_ae_loss: 1.7089 - val_kl_loss: 0.0036 - val_loss: 3.4461 - val_reconstruction_loss: 1.7343 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7668 - kl_loss: 0.0024 - loss: 3.5570 - reconstruction_loss: 1.7884 - val_ae_loss: 1.7079 - val_kl_loss: 0.0029 - val_loss: 3.4520 - val_reconstruction_loss: 1.7418 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7603 - kl_loss: 0.0019 - loss: 3.5460 - reconstruction_loss: 1.7842 - val_ae_loss: 1.7069 - val_kl_loss: 0.0024 - val_loss: 3.4377 - val_reconstruction_loss: 1.7289 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7399 - kl_loss: 0.0015 - loss: 3.5079 - reconstruction_loss: 1.7669 - val_ae_loss: 1.7057 - val_kl_loss: 0.0021 - val_loss: 3.4390 - val_reconstruction_loss: 1.7317 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7527 - kl_loss: 0.0012 - loss: 3.5290 - reconstruction_loss: 1.7753 - val_ae_loss: 1.7045 - val_kl_loss: 0.0018 - val_loss: 3.4413 - val_reconstruction_loss: 1.7353 - learning_rate: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7466 - kl_loss: 0.0011 - loss: 3.5147 - reconstruction_loss: 1.7673 - val_ae_loss: 1.7031 - val_kl_loss: 0.0015 - val_loss: 3.4320 - val_reconstruction_loss: 1.7277 - learning_rate: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7550 - kl_loss: 8.9072e-04 - loss: 3.5356 - reconstruction_loss: 1.7798 - val_ae_loss: 1.7017 - val_kl_loss: 0.0013 - val_loss: 3.4321 - val_reconstruction_loss: 1.7294 - learning_rate: 0.0010\n",
      "Epoch 23/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.8014 - kl_loss: 7.8372e-04 - loss: 3.6306 - reconstruction_loss: 1.8286 - val_ae_loss: 1.7000 - val_kl_loss: 0.0012 - val_loss: 3.4258 - val_reconstruction_loss: 1.7249 - learning_rate: 0.0010\n",
      "Epoch 24/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7476 - kl_loss: 6.6053e-04 - loss: 3.5243 - reconstruction_loss: 1.7762 - val_ae_loss: 1.6983 - val_kl_loss: 0.0010 - val_loss: 3.4229 - val_reconstruction_loss: 1.7238 - learning_rate: 0.0010\n",
      "Epoch 25/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7801 - kl_loss: 6.0031e-04 - loss: 3.5886 - reconstruction_loss: 1.8080 - val_ae_loss: 1.6965 - val_kl_loss: 9.3665e-04 - val_loss: 3.4215 - val_reconstruction_loss: 1.7243 - learning_rate: 0.0010\n",
      "Epoch 26/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.7332 - kl_loss: 4.6217e-04 - loss: 3.4977 - reconstruction_loss: 1.7642 - val_ae_loss: 1.6946 - val_kl_loss: 8.4416e-04 - val_loss: 3.4209 - val_reconstruction_loss: 1.7257 - learning_rate: 0.0010\n",
      "Epoch 27/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7709 - kl_loss: 3.9650e-04 - loss: 3.5694 - reconstruction_loss: 1.7982 - val_ae_loss: 1.6927 - val_kl_loss: 7.6729e-04 - val_loss: 3.4184 - val_reconstruction_loss: 1.7251 - learning_rate: 0.0010\n",
      "Epoch 28/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7336 - kl_loss: 3.6131e-04 - loss: 3.4966 - reconstruction_loss: 1.7627 - val_ae_loss: 1.6906 - val_kl_loss: 6.9808e-04 - val_loss: 3.4154 - val_reconstruction_loss: 1.7242 - learning_rate: 0.0010\n",
      "Epoch 29/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7390 - kl_loss: 3.3809e-04 - loss: 3.5117 - reconstruction_loss: 1.7725 - val_ae_loss: 1.6884 - val_kl_loss: 6.3744e-04 - val_loss: 3.4113 - val_reconstruction_loss: 1.7223 - learning_rate: 0.0010\n",
      "Epoch 30/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.7549 - kl_loss: 3.2383e-04 - loss: 3.5440 - reconstruction_loss: 1.7889 - val_ae_loss: 1.6863 - val_kl_loss: 5.8685e-04 - val_loss: 3.4101 - val_reconstruction_loss: 1.7233 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:52:08,530 - INFO - Hybrid Autoencoder-VAE training completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:52:09,049 - INFO - Dynamic threshold: 0.649912 (fallback: 0.168491)\n",
      "2025-03-22 12:52:09,167 - INFO - Latent dim 10: validation loss = 3.410115\n",
      "2025-03-22 12:52:09,224 - INFO - Optimal latent dimension: 8\n",
      "2025-03-22 12:52:09,224 - INFO - Creating model with latent_dim=8, layers=[64, 32, 16]\n",
      "2025-03-22 12:52:09,299 - INFO - Starting 5-fold cross-validation...\n",
      "2025-03-22 12:52:09,302 - INFO - Training fold 1/5\n",
      "2025-03-22 12:52:09,303 - INFO - Starting hybrid Autoencoder-VAE training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - ae_loss: 6.7306 - kl_loss: 0.1156 - loss: 13.4252 - reconstruction_loss: 6.6021 - val_ae_loss: 6.6192 - val_kl_loss: 0.0739 - val_loss: 12.9999 - val_reconstruction_loss: 6.3216 - learning_rate: 1.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 6.6507 - kl_loss: 0.0661 - loss: 13.0768 - reconstruction_loss: 6.3733 - val_ae_loss: 6.5222 - val_kl_loss: 0.0461 - val_loss: 12.6037 - val_reconstruction_loss: 6.0446 - learning_rate: 1.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 6.5394 - kl_loss: 0.0468 - loss: 12.6800 - reconstruction_loss: 6.1031 - val_ae_loss: 6.3721 - val_kl_loss: 0.0320 - val_loss: 12.1992 - val_reconstruction_loss: 5.8015 - learning_rate: 1.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 6.3347 - kl_loss: 0.0313 - loss: 12.1532 - reconstruction_loss: 5.7935 - val_ae_loss: 6.1290 - val_kl_loss: 0.0259 - val_loss: 11.6763 - val_reconstruction_loss: 5.5266 - learning_rate: 1.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 6.1071 - kl_loss: 0.0270 - loss: 11.7113 - reconstruction_loss: 5.5826 - val_ae_loss: 5.7499 - val_kl_loss: 0.0242 - val_loss: 10.9776 - val_reconstruction_loss: 5.2083 - learning_rate: 1.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 5.7110 - kl_loss: 0.0256 - loss: 10.9980 - reconstruction_loss: 5.2665 - val_ae_loss: 5.1941 - val_kl_loss: 0.0251 - val_loss: 10.0618 - val_reconstruction_loss: 4.8476 - learning_rate: 1.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - ae_loss: 5.0485 - kl_loss: 0.0273 - loss: 9.9356 - reconstruction_loss: 4.8653 - val_ae_loss: 4.4447 - val_kl_loss: 0.0301 - val_loss: 8.9083 - val_reconstruction_loss: 4.4395 - learning_rate: 1.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 4.2976 - kl_loss: 0.0340 - loss: 8.8497 - reconstruction_loss: 4.5249 - val_ae_loss: 3.5857 - val_kl_loss: 0.0368 - val_loss: 7.7192 - val_reconstruction_loss: 4.1040 - learning_rate: 1.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 3.4479 - kl_loss: 0.0407 - loss: 7.5967 - reconstruction_loss: 4.1162 - val_ae_loss: 2.8260 - val_kl_loss: 0.0443 - val_loss: 6.4759 - val_reconstruction_loss: 3.6145 - learning_rate: 1.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 2.6950 - kl_loss: 0.0487 - loss: 6.3653 - reconstruction_loss: 3.6313 - val_ae_loss: 2.3269 - val_kl_loss: 0.0509 - val_loss: 5.6553 - val_reconstruction_loss: 3.2877 - learning_rate: 1.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 2.2687 - kl_loss: 0.0545 - loss: 5.6463 - reconstruction_loss: 3.3340 - val_ae_loss: 2.0623 - val_kl_loss: 0.0549 - val_loss: 5.1056 - val_reconstruction_loss: 2.9995 - learning_rate: 1.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 2.0128 - kl_loss: 0.0573 - loss: 5.0140 - reconstruction_loss: 2.9555 - val_ae_loss: 1.9377 - val_kl_loss: 0.0561 - val_loss: 4.7026 - val_reconstruction_loss: 2.7200 - learning_rate: 1.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.9001 - kl_loss: 0.0580 - loss: 4.5917 - reconstruction_loss: 2.6452 - val_ae_loss: 1.8766 - val_kl_loss: 0.0536 - val_loss: 4.3838 - val_reconstruction_loss: 2.4643 - learning_rate: 1.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.8431 - kl_loss: 0.0543 - loss: 4.3888 - reconstruction_loss: 2.5022 - val_ae_loss: 1.8444 - val_kl_loss: 0.0485 - val_loss: 4.1694 - val_reconstruction_loss: 2.2861 - learning_rate: 1.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.8331 - kl_loss: 0.0491 - loss: 4.1887 - reconstruction_loss: 2.3163 - val_ae_loss: 1.8262 - val_kl_loss: 0.0419 - val_loss: 4.0378 - val_reconstruction_loss: 2.1780 - learning_rate: 1.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.8108 - kl_loss: 0.0411 - loss: 4.0262 - reconstruction_loss: 2.1825 - val_ae_loss: 1.8148 - val_kl_loss: 0.0371 - val_loss: 3.9177 - val_reconstruction_loss: 2.0732 - learning_rate: 1.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7858 - kl_loss: 0.0362 - loss: 3.9009 - reconstruction_loss: 2.0862 - val_ae_loss: 1.8075 - val_kl_loss: 0.0319 - val_loss: 3.8531 - val_reconstruction_loss: 2.0201 - learning_rate: 1.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7729 - kl_loss: 0.0316 - loss: 3.8135 - reconstruction_loss: 2.0153 - val_ae_loss: 1.8021 - val_kl_loss: 0.0276 - val_loss: 3.7769 - val_reconstruction_loss: 1.9528 - learning_rate: 1.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7710 - kl_loss: 0.0268 - loss: 3.7518 - reconstruction_loss: 1.9593 - val_ae_loss: 1.7983 - val_kl_loss: 0.0242 - val_loss: 3.7720 - val_reconstruction_loss: 1.9543 - learning_rate: 1.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7896 - kl_loss: 0.0239 - loss: 3.7632 - reconstruction_loss: 1.9545 - val_ae_loss: 1.7955 - val_kl_loss: 0.0212 - val_loss: 3.7586 - val_reconstruction_loss: 1.9462 - learning_rate: 1.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7508 - kl_loss: 0.0206 - loss: 3.6548 - reconstruction_loss: 1.8875 - val_ae_loss: 1.7934 - val_kl_loss: 0.0192 - val_loss: 3.7218 - val_reconstruction_loss: 1.9130 - learning_rate: 1.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7661 - kl_loss: 0.0193 - loss: 3.6814 - reconstruction_loss: 1.8998 - val_ae_loss: 1.7916 - val_kl_loss: 0.0173 - val_loss: 3.6601 - val_reconstruction_loss: 1.8546 - learning_rate: 1.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.7835 - kl_loss: 0.0170 - loss: 3.6885 - reconstruction_loss: 1.8914 - val_ae_loss: 1.7903 - val_kl_loss: 0.0156 - val_loss: 3.6449 - val_reconstruction_loss: 1.8422 - learning_rate: 1.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7393 - kl_loss: 0.0149 - loss: 3.5860 - reconstruction_loss: 1.8349 - val_ae_loss: 1.7891 - val_kl_loss: 0.0140 - val_loss: 3.6580 - val_reconstruction_loss: 1.8578 - learning_rate: 1.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7770 - kl_loss: 0.0135 - loss: 3.6454 - reconstruction_loss: 1.8575 - val_ae_loss: 1.7881 - val_kl_loss: 0.0126 - val_loss: 3.6318 - val_reconstruction_loss: 1.8336 - learning_rate: 1.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - ae_loss: 1.7550 - kl_loss: 0.0121 - loss: 3.5852 - reconstruction_loss: 1.8205 - val_ae_loss: 1.7873 - val_kl_loss: 0.0114 - val_loss: 3.6335 - val_reconstruction_loss: 1.8370 - learning_rate: 1.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7526 - kl_loss: 0.0111 - loss: 3.5736 - reconstruction_loss: 1.8121 - val_ae_loss: 1.7867 - val_kl_loss: 0.0104 - val_loss: 3.6292 - val_reconstruction_loss: 1.8342 - learning_rate: 1.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7672 - kl_loss: 0.0102 - loss: 3.5956 - reconstruction_loss: 1.8202 - val_ae_loss: 1.7860 - val_kl_loss: 0.0095 - val_loss: 3.6245 - val_reconstruction_loss: 1.8309 - learning_rate: 1.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7452 - kl_loss: 0.0091 - loss: 3.5463 - reconstruction_loss: 1.7938 - val_ae_loss: 1.7855 - val_kl_loss: 0.0086 - val_loss: 3.6137 - val_reconstruction_loss: 1.8213 - learning_rate: 1.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7671 - kl_loss: 0.0086 - loss: 3.5868 - reconstruction_loss: 1.8128 - val_ae_loss: 1.7850 - val_kl_loss: 0.0079 - val_loss: 3.6113 - val_reconstruction_loss: 1.8200 - learning_rate: 1.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7425 - kl_loss: 0.0077 - loss: 3.5386 - reconstruction_loss: 1.7899 - val_ae_loss: 1.7845 - val_kl_loss: 0.0072 - val_loss: 3.5970 - val_reconstruction_loss: 1.8067 - learning_rate: 1.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7624 - kl_loss: 0.0071 - loss: 3.5680 - reconstruction_loss: 1.7999 - val_ae_loss: 1.7841 - val_kl_loss: 0.0066 - val_loss: 3.5887 - val_reconstruction_loss: 1.7994 - learning_rate: 1.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7576 - kl_loss: 0.0064 - loss: 3.5488 - reconstruction_loss: 1.7860 - val_ae_loss: 1.7838 - val_kl_loss: 0.0060 - val_loss: 3.5971 - val_reconstruction_loss: 1.8086 - learning_rate: 1.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7512 - kl_loss: 0.0057 - loss: 3.5363 - reconstruction_loss: 1.7806 - val_ae_loss: 1.7834 - val_kl_loss: 0.0055 - val_loss: 3.5878 - val_reconstruction_loss: 1.8000 - learning_rate: 1.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7817 - kl_loss: 0.0054 - loss: 3.6000 - reconstruction_loss: 1.8140 - val_ae_loss: 1.7831 - val_kl_loss: 0.0050 - val_loss: 3.5997 - val_reconstruction_loss: 1.8126 - learning_rate: 1.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7490 - kl_loss: 0.0048 - loss: 3.5301 - reconstruction_loss: 1.7773 - val_ae_loss: 1.7828 - val_kl_loss: 0.0046 - val_loss: 3.5956 - val_reconstruction_loss: 1.8091 - learning_rate: 1.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7744 - kl_loss: 0.0046 - loss: 3.5914 - reconstruction_loss: 1.8133 - val_ae_loss: 1.7825 - val_kl_loss: 0.0042 - val_loss: 3.5913 - val_reconstruction_loss: 1.8055 - learning_rate: 1.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7639 - kl_loss: 0.0040 - loss: 3.5612 - reconstruction_loss: 1.7941 - val_ae_loss: 1.7821 - val_kl_loss: 0.0039 - val_loss: 3.5861 - val_reconstruction_loss: 1.8008 - learning_rate: 1.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7524 - kl_loss: 0.0037 - loss: 3.5311 - reconstruction_loss: 1.7757 - val_ae_loss: 1.7818 - val_kl_loss: 0.0035 - val_loss: 3.5800 - val_reconstruction_loss: 1.7954 - learning_rate: 1.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7706 - kl_loss: 0.0034 - loss: 3.5707 - reconstruction_loss: 1.7973 - val_ae_loss: 1.7815 - val_kl_loss: 0.0033 - val_loss: 3.5860 - val_reconstruction_loss: 1.8019 - learning_rate: 1.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7533 - kl_loss: 0.0032 - loss: 3.5340 - reconstruction_loss: 1.7782 - val_ae_loss: 1.7811 - val_kl_loss: 0.0030 - val_loss: 3.5797 - val_reconstruction_loss: 1.7961 - learning_rate: 1.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7852 - kl_loss: 0.0029 - loss: 3.5962 - reconstruction_loss: 1.8088 - val_ae_loss: 1.7808 - val_kl_loss: 0.0028 - val_loss: 3.5778 - val_reconstruction_loss: 1.7948 - learning_rate: 1.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7369 - kl_loss: 0.0026 - loss: 3.4984 - reconstruction_loss: 1.7594 - val_ae_loss: 1.7805 - val_kl_loss: 0.0025 - val_loss: 3.5793 - val_reconstruction_loss: 1.7968 - learning_rate: 1.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7864 - kl_loss: 0.0025 - loss: 3.5944 - reconstruction_loss: 1.8060 - val_ae_loss: 1.7801 - val_kl_loss: 0.0023 - val_loss: 3.5778 - val_reconstruction_loss: 1.7958 - learning_rate: 1.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7776 - kl_loss: 0.0023 - loss: 3.5811 - reconstruction_loss: 1.8016 - val_ae_loss: 1.7798 - val_kl_loss: 0.0022 - val_loss: 3.5786 - val_reconstruction_loss: 1.7971 - learning_rate: 1.0000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7863 - kl_loss: 0.0021 - loss: 3.5941 - reconstruction_loss: 1.8061 - val_ae_loss: 1.7794 - val_kl_loss: 0.0020 - val_loss: 3.5788 - val_reconstruction_loss: 1.7978 - learning_rate: 1.0000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.7582 - kl_loss: 0.0018 - loss: 3.5374 - reconstruction_loss: 1.7777 - val_ae_loss: 1.7790 - val_kl_loss: 0.0018 - val_loss: 3.5659 - val_reconstruction_loss: 1.7854 - learning_rate: 1.0000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7644 - kl_loss: 0.0018 - loss: 3.5506 - reconstruction_loss: 1.7848 - val_ae_loss: 1.7786 - val_kl_loss: 0.0017 - val_loss: 3.5733 - val_reconstruction_loss: 1.7934 - learning_rate: 1.0000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.7786 - kl_loss: 0.0016 - loss: 3.5773 - reconstruction_loss: 1.7974 - val_ae_loss: 1.7782 - val_kl_loss: 0.0016 - val_loss: 3.5711 - val_reconstruction_loss: 1.7916 - learning_rate: 1.0000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7923 - kl_loss: 0.0016 - loss: 3.6047 - reconstruction_loss: 1.8111 - val_ae_loss: 1.7778 - val_kl_loss: 0.0015 - val_loss: 3.5721 - val_reconstruction_loss: 1.7931 - learning_rate: 1.0000e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7758 - kl_loss: 0.0015 - loss: 3.5720 - reconstruction_loss: 1.7950 - val_ae_loss: 1.7774 - val_kl_loss: 0.0014 - val_loss: 3.5780 - val_reconstruction_loss: 1.7995 - learning_rate: 1.0000e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.7669 - kl_loss: 0.0013 - loss: 3.5571 - reconstruction_loss: 1.7892 - val_ae_loss: 1.7769 - val_kl_loss: 0.0013 - val_loss: 3.5696 - val_reconstruction_loss: 1.7916 - learning_rate: 1.0000e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.7479 - kl_loss: 0.0012 - loss: 3.5130 - reconstruction_loss: 1.7642 - val_ae_loss: 1.7765 - val_kl_loss: 0.0012 - val_loss: 3.5665 - val_reconstruction_loss: 1.7891 - learning_rate: 1.0000e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7614 - kl_loss: 0.0012 - loss: 3.5409 - reconstruction_loss: 1.7786 - val_ae_loss: 1.7760 - val_kl_loss: 0.0011 - val_loss: 3.5657 - val_reconstruction_loss: 1.7888 - learning_rate: 1.0000e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7679 - kl_loss: 0.0010 - loss: 3.5595 - reconstruction_loss: 1.7908 - val_ae_loss: 1.7755 - val_kl_loss: 0.0010 - val_loss: 3.5710 - val_reconstruction_loss: 1.7947 - learning_rate: 1.0000e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7776 - kl_loss: 9.8963e-04 - loss: 3.5819 - reconstruction_loss: 1.8035 - val_ae_loss: 1.7749 - val_kl_loss: 9.5394e-04 - val_loss: 3.5661 - val_reconstruction_loss: 1.7904 - learning_rate: 1.0000e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - ae_loss: 1.7403 - kl_loss: 8.9666e-04 - loss: 3.5029 - reconstruction_loss: 1.7619 - val_ae_loss: 1.7744 - val_kl_loss: 8.8953e-04 - val_loss: 3.5704 - val_reconstruction_loss: 1.7953 - learning_rate: 1.0000e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7537 - kl_loss: 8.3412e-04 - loss: 3.5268 - reconstruction_loss: 1.7724 - val_ae_loss: 1.7738 - val_kl_loss: 8.3097e-04 - val_loss: 3.5648 - val_reconstruction_loss: 1.7903 - learning_rate: 1.0000e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7490 - kl_loss: 7.4346e-04 - loss: 3.5210 - reconstruction_loss: 1.7714 - val_ae_loss: 1.7733 - val_kl_loss: 7.7917e-04 - val_loss: 3.5645 - val_reconstruction_loss: 1.7907 - learning_rate: 1.0000e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7237 - kl_loss: 6.8582e-04 - loss: 3.4680 - reconstruction_loss: 1.7438 - val_ae_loss: 1.7727 - val_kl_loss: 7.2733e-04 - val_loss: 3.5623 - val_reconstruction_loss: 1.7890 - learning_rate: 1.0000e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7518 - kl_loss: 6.8439e-04 - loss: 3.5272 - reconstruction_loss: 1.7748 - val_ae_loss: 1.7720 - val_kl_loss: 6.7813e-04 - val_loss: 3.5620 - val_reconstruction_loss: 1.7894 - learning_rate: 1.0000e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7526 - kl_loss: 5.9637e-04 - loss: 3.5299 - reconstruction_loss: 1.7769 - val_ae_loss: 1.7713 - val_kl_loss: 6.3774e-04 - val_loss: 3.5618 - val_reconstruction_loss: 1.7900 - learning_rate: 1.0000e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7418 - kl_loss: 5.8928e-04 - loss: 3.5098 - reconstruction_loss: 1.7676 - val_ae_loss: 1.7706 - val_kl_loss: 5.9747e-04 - val_loss: 3.5602 - val_reconstruction_loss: 1.7891 - learning_rate: 1.0000e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7387 - kl_loss: 5.2660e-04 - loss: 3.5015 - reconstruction_loss: 1.7624 - val_ae_loss: 1.7700 - val_kl_loss: 5.6019e-04 - val_loss: 3.5629 - val_reconstruction_loss: 1.7925 - learning_rate: 1.0000e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7610 - kl_loss: 5.3119e-04 - loss: 3.5468 - reconstruction_loss: 1.7854 - val_ae_loss: 1.7692 - val_kl_loss: 5.2564e-04 - val_loss: 3.5611 - val_reconstruction_loss: 1.7915 - learning_rate: 1.0000e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7192 - kl_loss: 4.6288e-04 - loss: 3.4659 - reconstruction_loss: 1.7463 - val_ae_loss: 1.7684 - val_kl_loss: 4.9543e-04 - val_loss: 3.5582 - val_reconstruction_loss: 1.7894 - learning_rate: 1.0000e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.7784 - kl_loss: 4.9455e-04 - loss: 3.5792 - reconstruction_loss: 1.8004 - val_ae_loss: 1.7679 - val_kl_loss: 4.6564e-04 - val_loss: 3.5575 - val_reconstruction_loss: 1.7892 - learning_rate: 1.0000e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7383 - kl_loss: 3.9080e-04 - loss: 3.5024 - reconstruction_loss: 1.7638 - val_ae_loss: 1.7670 - val_kl_loss: 4.3892e-04 - val_loss: 3.5601 - val_reconstruction_loss: 1.7928 - learning_rate: 1.0000e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7503 - kl_loss: 3.6173e-04 - loss: 3.5283 - reconstruction_loss: 1.7777 - val_ae_loss: 1.7662 - val_kl_loss: 4.1339e-04 - val_loss: 3.5596 - val_reconstruction_loss: 1.7931 - learning_rate: 1.0000e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7789 - kl_loss: 3.6314e-04 - loss: 3.5867 - reconstruction_loss: 1.8076 - val_ae_loss: 1.7654 - val_kl_loss: 3.9100e-04 - val_loss: 3.5528 - val_reconstruction_loss: 1.7871 - learning_rate: 1.0000e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7364 - kl_loss: 3.1196e-04 - loss: 3.5021 - reconstruction_loss: 1.7655 - val_ae_loss: 1.7645 - val_kl_loss: 3.6894e-04 - val_loss: 3.5571 - val_reconstruction_loss: 1.7924 - learning_rate: 1.0000e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7551 - kl_loss: 3.5118e-04 - loss: 3.5354 - reconstruction_loss: 1.7800 - val_ae_loss: 1.7636 - val_kl_loss: 3.4702e-04 - val_loss: 3.5534 - val_reconstruction_loss: 1.7895 - learning_rate: 1.0000e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7278 - kl_loss: 2.6679e-04 - loss: 3.4798 - reconstruction_loss: 1.7518 - val_ae_loss: 1.7628 - val_kl_loss: 3.2657e-04 - val_loss: 3.5520 - val_reconstruction_loss: 1.7889 - learning_rate: 1.0000e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7058 - kl_loss: 2.4525e-04 - loss: 3.4401 - reconstruction_loss: 1.7341 - val_ae_loss: 1.7620 - val_kl_loss: 3.0877e-04 - val_loss: 3.5527 - val_reconstruction_loss: 1.7905 - learning_rate: 1.0000e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7594 - kl_loss: 2.8912e-04 - loss: 3.5461 - reconstruction_loss: 1.7865 - val_ae_loss: 1.7612 - val_kl_loss: 2.9198e-04 - val_loss: 3.5558 - val_reconstruction_loss: 1.7944 - learning_rate: 1.0000e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7039 - kl_loss: 2.1958e-04 - loss: 3.4416 - reconstruction_loss: 1.7375 - val_ae_loss: 1.7604 - val_kl_loss: 2.7585e-04 - val_loss: 3.5503 - val_reconstruction_loss: 1.7897 - learning_rate: 1.0000e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7560 - kl_loss: 2.2691e-04 - loss: 3.5429 - reconstruction_loss: 1.7867 - val_ae_loss: 1.7594 - val_kl_loss: 2.6224e-04 - val_loss: 3.5483 - val_reconstruction_loss: 1.7887 - learning_rate: 1.0000e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7725 - kl_loss: 1.9865e-04 - loss: 3.5741 - reconstruction_loss: 1.8015 - val_ae_loss: 1.7587 - val_kl_loss: 2.5077e-04 - val_loss: 3.5471 - val_reconstruction_loss: 1.7882 - learning_rate: 1.0000e-04\n",
      "Epoch 79/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7157 - kl_loss: 2.0625e-04 - loss: 3.4693 - reconstruction_loss: 1.7534 - val_ae_loss: 1.7578 - val_kl_loss: 2.3949e-04 - val_loss: 3.5466 - val_reconstruction_loss: 1.7886 - learning_rate: 1.0000e-04\n",
      "Epoch 80/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7428 - kl_loss: 2.1255e-04 - loss: 3.5266 - reconstruction_loss: 1.7836 - val_ae_loss: 1.7570 - val_kl_loss: 2.2952e-04 - val_loss: 3.5474 - val_reconstruction_loss: 1.7902 - learning_rate: 1.0000e-04\n",
      "Epoch 81/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7364 - kl_loss: 1.8855e-04 - loss: 3.5056 - reconstruction_loss: 1.7691 - val_ae_loss: 1.7562 - val_kl_loss: 2.1763e-04 - val_loss: 3.5484 - val_reconstruction_loss: 1.7920 - learning_rate: 1.0000e-04\n",
      "Epoch 82/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7293 - kl_loss: 1.6867e-04 - loss: 3.4922 - reconstruction_loss: 1.7628 - val_ae_loss: 1.7555 - val_kl_loss: 2.0546e-04 - val_loss: 3.5435 - val_reconstruction_loss: 1.7879 - learning_rate: 1.0000e-04\n",
      "Epoch 83/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7405 - kl_loss: 1.7417e-04 - loss: 3.5181 - reconstruction_loss: 1.7775 - val_ae_loss: 1.7548 - val_kl_loss: 1.9540e-04 - val_loss: 3.5453 - val_reconstruction_loss: 1.7904 - learning_rate: 1.0000e-04\n",
      "Epoch 84/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7124 - kl_loss: 1.3655e-04 - loss: 3.4665 - reconstruction_loss: 1.7540 - val_ae_loss: 1.7540 - val_kl_loss: 1.8707e-04 - val_loss: 3.5432 - val_reconstruction_loss: 1.7891 - learning_rate: 1.0000e-04\n",
      "Epoch 85/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7684 - kl_loss: 1.6518e-04 - loss: 3.5770 - reconstruction_loss: 1.8084 - val_ae_loss: 1.7533 - val_kl_loss: 1.7831e-04 - val_loss: 3.5433 - val_reconstruction_loss: 1.7898 - learning_rate: 1.0000e-04\n",
      "Epoch 86/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7441 - kl_loss: 1.2110e-04 - loss: 3.5255 - reconstruction_loss: 1.7813 - val_ae_loss: 1.7526 - val_kl_loss: 1.7137e-04 - val_loss: 3.5396 - val_reconstruction_loss: 1.7869 - learning_rate: 1.0000e-04\n",
      "Epoch 87/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7253 - kl_loss: 1.3418e-04 - loss: 3.4897 - reconstruction_loss: 1.7643 - val_ae_loss: 1.7521 - val_kl_loss: 1.6336e-04 - val_loss: 3.5431 - val_reconstruction_loss: 1.7908 - learning_rate: 1.0000e-04\n",
      "Epoch 88/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7308 - kl_loss: 1.1280e-04 - loss: 3.5082 - reconstruction_loss: 1.7773 - val_ae_loss: 1.7515 - val_kl_loss: 1.5630e-04 - val_loss: 3.5473 - val_reconstruction_loss: 1.7956 - learning_rate: 1.0000e-04\n",
      "Epoch 89/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7108 - kl_loss: 1.0831e-04 - loss: 3.4640 - reconstruction_loss: 1.7531 - val_ae_loss: 1.7509 - val_kl_loss: 1.4840e-04 - val_loss: 3.5378 - val_reconstruction_loss: 1.7868 - learning_rate: 1.0000e-04\n",
      "Epoch 90/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7298 - kl_loss: 1.3789e-04 - loss: 3.4994 - reconstruction_loss: 1.7695 - val_ae_loss: 1.7505 - val_kl_loss: 1.4180e-04 - val_loss: 3.5391 - val_reconstruction_loss: 1.7885 - learning_rate: 1.0000e-04\n",
      "Epoch 91/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7433 - kl_loss: 1.0398e-04 - loss: 3.5309 - reconstruction_loss: 1.7875 - val_ae_loss: 1.7500 - val_kl_loss: 1.3676e-04 - val_loss: 3.5353 - val_reconstruction_loss: 1.7852 - learning_rate: 1.0000e-04\n",
      "Epoch 92/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7196 - kl_loss: 1.1119e-04 - loss: 3.4857 - reconstruction_loss: 1.7660 - val_ae_loss: 1.7494 - val_kl_loss: 1.3070e-04 - val_loss: 3.5378 - val_reconstruction_loss: 1.7883 - learning_rate: 1.0000e-04\n",
      "Epoch 93/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7580 - kl_loss: 1.0480e-04 - loss: 3.5587 - reconstruction_loss: 1.8006 - val_ae_loss: 1.7489 - val_kl_loss: 1.2551e-04 - val_loss: 3.5371 - val_reconstruction_loss: 1.7882 - learning_rate: 1.0000e-04\n",
      "Epoch 94/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7209 - kl_loss: 8.6606e-05 - loss: 3.4852 - reconstruction_loss: 1.7642 - val_ae_loss: 1.7483 - val_kl_loss: 1.2072e-04 - val_loss: 3.5364 - val_reconstruction_loss: 1.7879 - learning_rate: 1.0000e-04\n",
      "Epoch 95/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.7538 - kl_loss: 8.0476e-05 - loss: 3.5522 - reconstruction_loss: 1.7983 - val_ae_loss: 1.7480 - val_kl_loss: 1.1694e-04 - val_loss: 3.5367 - val_reconstruction_loss: 1.7886 - learning_rate: 1.0000e-04\n",
      "Epoch 96/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - ae_loss: 1.7336 - kl_loss: 7.6534e-05 - loss: 3.5140 - reconstruction_loss: 1.7803 - val_ae_loss: 1.7473 - val_kl_loss: 1.1241e-04 - val_loss: 3.5419 - val_reconstruction_loss: 1.7945 - learning_rate: 1.0000e-04\n",
      "Epoch 97/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.7621 - kl_loss: 7.2056e-05 - loss: 3.5679 - reconstruction_loss: 1.8057 - val_ae_loss: 1.7469 - val_kl_loss: 1.0893e-04 - val_loss: 3.5346 - val_reconstruction_loss: 1.7876 - learning_rate: 1.0000e-04\n",
      "Epoch 98/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7305 - kl_loss: 7.0356e-05 - loss: 3.5067 - reconstruction_loss: 1.7762 - val_ae_loss: 1.7464 - val_kl_loss: 1.0504e-04 - val_loss: 3.5342 - val_reconstruction_loss: 1.7878 - learning_rate: 1.0000e-04\n",
      "Epoch 99/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - ae_loss: 1.6941 - kl_loss: 7.7980e-05 - loss: 3.4350 - reconstruction_loss: 1.7408 - val_ae_loss: 1.7458 - val_kl_loss: 1.0118e-04 - val_loss: 3.5372 - val_reconstruction_loss: 1.7913 - learning_rate: 1.0000e-04\n",
      "Epoch 100/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7403 - kl_loss: 8.9692e-05 - loss: 3.5276 - reconstruction_loss: 1.7872 - val_ae_loss: 1.7453 - val_kl_loss: 9.7088e-05 - val_loss: 3.5345 - val_reconstruction_loss: 1.7891 - learning_rate: 1.0000e-04\n",
      "Epoch 101/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7676 - kl_loss: 7.0121e-05 - loss: 3.5889 - reconstruction_loss: 1.8212 - val_ae_loss: 1.7446 - val_kl_loss: 9.3400e-05 - val_loss: 3.5339 - val_reconstruction_loss: 1.7892 - learning_rate: 1.0000e-04\n",
      "Epoch 102/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7199 - kl_loss: 5.9930e-05 - loss: 3.4823 - reconstruction_loss: 1.7624 - val_ae_loss: 1.7436 - val_kl_loss: 9.0840e-05 - val_loss: 3.5310 - val_reconstruction_loss: 1.7874 - learning_rate: 1.0000e-04\n",
      "Epoch 103/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7118 - kl_loss: 6.8731e-05 - loss: 3.4759 - reconstruction_loss: 1.7641 - val_ae_loss: 1.7428 - val_kl_loss: 8.8683e-05 - val_loss: 3.5321 - val_reconstruction_loss: 1.7892 - learning_rate: 1.0000e-04\n",
      "Epoch 104/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7172 - kl_loss: 7.0026e-05 - loss: 3.4900 - reconstruction_loss: 1.7728 - val_ae_loss: 1.7418 - val_kl_loss: 8.5848e-05 - val_loss: 3.5324 - val_reconstruction_loss: 1.7905 - learning_rate: 1.0000e-04\n",
      "Epoch 105/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7611 - kl_loss: 6.4190e-05 - loss: 3.5742 - reconstruction_loss: 1.8130 - val_ae_loss: 1.7406 - val_kl_loss: 8.3454e-05 - val_loss: 3.5319 - val_reconstruction_loss: 1.7912 - learning_rate: 1.0000e-04\n",
      "Epoch 106/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7222 - kl_loss: 4.9416e-05 - loss: 3.4995 - reconstruction_loss: 1.7773 - val_ae_loss: 1.7390 - val_kl_loss: 8.1441e-05 - val_loss: 3.5271 - val_reconstruction_loss: 1.7880 - learning_rate: 1.0000e-04\n",
      "Epoch 107/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7107 - kl_loss: 5.3458e-05 - loss: 3.4749 - reconstruction_loss: 1.7642 - val_ae_loss: 1.7369 - val_kl_loss: 7.8090e-05 - val_loss: 3.5254 - val_reconstruction_loss: 1.7884 - learning_rate: 1.0000e-04\n",
      "Epoch 108/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7054 - kl_loss: 4.2400e-05 - loss: 3.4674 - reconstruction_loss: 1.7620 - val_ae_loss: 1.7343 - val_kl_loss: 7.5103e-05 - val_loss: 3.5219 - val_reconstruction_loss: 1.7875 - learning_rate: 1.0000e-04\n",
      "Epoch 109/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7215 - kl_loss: 4.7050e-05 - loss: 3.5023 - reconstruction_loss: 1.7808 - val_ae_loss: 1.7312 - val_kl_loss: 7.2588e-05 - val_loss: 3.5204 - val_reconstruction_loss: 1.7892 - learning_rate: 1.0000e-04\n",
      "Epoch 110/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7071 - kl_loss: 4.3508e-05 - loss: 3.4760 - reconstruction_loss: 1.7688 - val_ae_loss: 1.7271 - val_kl_loss: 7.0082e-05 - val_loss: 3.5146 - val_reconstruction_loss: 1.7874 - learning_rate: 1.0000e-04\n",
      "Epoch 111/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7154 - kl_loss: 3.6868e-05 - loss: 3.4937 - reconstruction_loss: 1.7783 - val_ae_loss: 1.7225 - val_kl_loss: 6.7969e-05 - val_loss: 3.5102 - val_reconstruction_loss: 1.7876 - learning_rate: 1.0000e-04\n",
      "Epoch 112/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6755 - kl_loss: 3.8067e-05 - loss: 3.4180 - reconstruction_loss: 1.7425 - val_ae_loss: 1.7185 - val_kl_loss: 6.5864e-05 - val_loss: 3.5074 - val_reconstruction_loss: 1.7888 - learning_rate: 1.0000e-04\n",
      "Epoch 113/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.6929 - kl_loss: 4.4805e-05 - loss: 3.4569 - reconstruction_loss: 1.7640 - val_ae_loss: 1.7151 - val_kl_loss: 6.3673e-05 - val_loss: 3.5044 - val_reconstruction_loss: 1.7892 - learning_rate: 1.0000e-04\n",
      "Epoch 114/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6792 - kl_loss: 5.2846e-05 - loss: 3.4330 - reconstruction_loss: 1.7538 - val_ae_loss: 1.7124 - val_kl_loss: 6.1908e-05 - val_loss: 3.5008 - val_reconstruction_loss: 1.7884 - learning_rate: 1.0000e-04\n",
      "Epoch 115/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6867 - kl_loss: 2.8687e-05 - loss: 3.4506 - reconstruction_loss: 1.7638 - val_ae_loss: 1.7105 - val_kl_loss: 6.0207e-05 - val_loss: 3.4987 - val_reconstruction_loss: 1.7882 - learning_rate: 1.0000e-04\n",
      "Epoch 116/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6933 - kl_loss: 4.7396e-05 - loss: 3.4690 - reconstruction_loss: 1.7756 - val_ae_loss: 1.7088 - val_kl_loss: 5.8437e-05 - val_loss: 3.4981 - val_reconstruction_loss: 1.7893 - learning_rate: 1.0000e-04\n",
      "Epoch 117/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6817 - kl_loss: 3.7929e-05 - loss: 3.4453 - reconstruction_loss: 1.7636 - val_ae_loss: 1.7074 - val_kl_loss: 5.6601e-05 - val_loss: 3.4955 - val_reconstruction_loss: 1.7881 - learning_rate: 1.0000e-04\n",
      "Epoch 118/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6631 - kl_loss: 3.4912e-05 - loss: 3.4155 - reconstruction_loss: 1.7524 - val_ae_loss: 1.7060 - val_kl_loss: 5.4475e-05 - val_loss: 3.4953 - val_reconstruction_loss: 1.7892 - learning_rate: 1.0000e-04\n",
      "Epoch 119/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6791 - kl_loss: 3.0853e-05 - loss: 3.4435 - reconstruction_loss: 1.7644 - val_ae_loss: 1.7049 - val_kl_loss: 5.3001e-05 - val_loss: 3.4928 - val_reconstruction_loss: 1.7879 - learning_rate: 1.0000e-04\n",
      "Epoch 120/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6682 - kl_loss: 3.7329e-05 - loss: 3.4264 - reconstruction_loss: 1.7582 - val_ae_loss: 1.7038 - val_kl_loss: 5.1090e-05 - val_loss: 3.4933 - val_reconstruction_loss: 1.7894 - learning_rate: 1.0000e-04\n",
      "Epoch 121/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.7031 - kl_loss: 3.6671e-05 - loss: 3.5038 - reconstruction_loss: 1.8007 - val_ae_loss: 1.7028 - val_kl_loss: 5.0079e-05 - val_loss: 3.4902 - val_reconstruction_loss: 1.7873 - learning_rate: 1.0000e-04\n",
      "Epoch 122/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6834 - kl_loss: 3.2253e-05 - loss: 3.4589 - reconstruction_loss: 1.7755 - val_ae_loss: 1.7020 - val_kl_loss: 4.8275e-05 - val_loss: 3.4910 - val_reconstruction_loss: 1.7890 - learning_rate: 1.0000e-04\n",
      "Epoch 123/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6823 - kl_loss: 2.7587e-05 - loss: 3.4495 - reconstruction_loss: 1.7672 - val_ae_loss: 1.7011 - val_kl_loss: 4.6910e-05 - val_loss: 3.4892 - val_reconstruction_loss: 1.7880 - learning_rate: 1.0000e-04\n",
      "Epoch 124/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6888 - kl_loss: 2.3707e-05 - loss: 3.4739 - reconstruction_loss: 1.7851 - val_ae_loss: 1.7003 - val_kl_loss: 4.5945e-05 - val_loss: 3.4880 - val_reconstruction_loss: 1.7877 - learning_rate: 1.0000e-04\n",
      "Epoch 125/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6886 - kl_loss: 4.1109e-05 - loss: 3.4701 - reconstruction_loss: 1.7814 - val_ae_loss: 1.6996 - val_kl_loss: 4.4993e-05 - val_loss: 3.4887 - val_reconstruction_loss: 1.7891 - learning_rate: 1.0000e-04\n",
      "Epoch 126/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6877 - kl_loss: 2.2595e-05 - loss: 3.4653 - reconstruction_loss: 1.7776 - val_ae_loss: 1.6990 - val_kl_loss: 4.3139e-05 - val_loss: 3.4890 - val_reconstruction_loss: 1.7899 - learning_rate: 1.0000e-04\n",
      "Epoch 127/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6932 - kl_loss: 2.9371e-05 - loss: 3.4812 - reconstruction_loss: 1.7879 - val_ae_loss: 1.6984 - val_kl_loss: 4.1892e-05 - val_loss: 3.4901 - val_reconstruction_loss: 1.7916 - learning_rate: 1.0000e-04\n",
      "Epoch 128/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.6923 - kl_loss: 2.2463e-05 - loss: 3.4792 - reconstruction_loss: 1.7869 - val_ae_loss: 1.6974 - val_kl_loss: 4.0734e-05 - val_loss: 3.4845 - val_reconstruction_loss: 1.7870 - learning_rate: 1.0000e-04\n",
      "Epoch 129/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6617 - kl_loss: 2.2648e-05 - loss: 3.4136 - reconstruction_loss: 1.7519 - val_ae_loss: 1.6968 - val_kl_loss: 3.9929e-05 - val_loss: 3.4861 - val_reconstruction_loss: 1.7893 - learning_rate: 1.0000e-04\n",
      "Epoch 130/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6451 - kl_loss: 2.5456e-05 - loss: 3.3831 - reconstruction_loss: 1.7380 - val_ae_loss: 1.6963 - val_kl_loss: 3.8867e-05 - val_loss: 3.4866 - val_reconstruction_loss: 1.7902 - learning_rate: 1.0000e-04\n",
      "Epoch 131/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6787 - kl_loss: 2.4957e-05 - loss: 3.4453 - reconstruction_loss: 1.7666 - val_ae_loss: 1.6952 - val_kl_loss: 3.8412e-05 - val_loss: 3.4842 - val_reconstruction_loss: 1.7890 - learning_rate: 1.0000e-04\n",
      "Epoch 132/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6991 - kl_loss: 2.3091e-05 - loss: 3.4911 - reconstruction_loss: 1.7919 - val_ae_loss: 1.6947 - val_kl_loss: 3.7501e-05 - val_loss: 3.4835 - val_reconstruction_loss: 1.7888 - learning_rate: 1.0000e-04\n",
      "Epoch 133/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6774 - kl_loss: 1.9404e-05 - loss: 3.4502 - reconstruction_loss: 1.7727 - val_ae_loss: 1.6938 - val_kl_loss: 3.6439e-05 - val_loss: 3.4800 - val_reconstruction_loss: 1.7862 - learning_rate: 1.0000e-04\n",
      "Epoch 134/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6854 - kl_loss: 2.5072e-05 - loss: 3.4687 - reconstruction_loss: 1.7833 - val_ae_loss: 1.6929 - val_kl_loss: 3.5686e-05 - val_loss: 3.4819 - val_reconstruction_loss: 1.7889 - learning_rate: 1.0000e-04\n",
      "Epoch 135/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6593 - kl_loss: 2.1911e-05 - loss: 3.4232 - reconstruction_loss: 1.7639 - val_ae_loss: 1.6923 - val_kl_loss: 3.5006e-05 - val_loss: 3.4819 - val_reconstruction_loss: 1.7896 - learning_rate: 1.0000e-04\n",
      "Epoch 136/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6706 - kl_loss: 1.6270e-05 - loss: 3.4506 - reconstruction_loss: 1.7799 - val_ae_loss: 1.6918 - val_kl_loss: 3.4154e-05 - val_loss: 3.4812 - val_reconstruction_loss: 1.7894 - learning_rate: 1.0000e-04\n",
      "Epoch 137/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - ae_loss: 1.6775 - kl_loss: 1.8241e-05 - loss: 3.4590 - reconstruction_loss: 1.7815 - val_ae_loss: 1.6907 - val_kl_loss: 3.3080e-05 - val_loss: 3.4808 - val_reconstruction_loss: 1.7901 - learning_rate: 1.0000e-04\n",
      "Epoch 138/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6689 - kl_loss: 2.3360e-05 - loss: 3.4326 - reconstruction_loss: 1.7637 - val_ae_loss: 1.6899 - val_kl_loss: 3.2336e-05 - val_loss: 3.4796 - val_reconstruction_loss: 1.7897 - learning_rate: 1.0000e-04\n",
      "Epoch 139/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6530 - kl_loss: 1.8569e-05 - loss: 3.4100 - reconstruction_loss: 1.7569 - val_ae_loss: 1.6890 - val_kl_loss: 3.1622e-05 - val_loss: 3.4770 - val_reconstruction_loss: 1.7879 - learning_rate: 1.0000e-04\n",
      "Epoch 140/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6486 - kl_loss: 1.5741e-05 - loss: 3.4016 - reconstruction_loss: 1.7529 - val_ae_loss: 1.6879 - val_kl_loss: 3.0992e-05 - val_loss: 3.4764 - val_reconstruction_loss: 1.7884 - learning_rate: 1.0000e-04\n",
      "Epoch 141/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6384 - kl_loss: 1.8691e-05 - loss: 3.3857 - reconstruction_loss: 1.7473 - val_ae_loss: 1.6871 - val_kl_loss: 3.0156e-05 - val_loss: 3.4765 - val_reconstruction_loss: 1.7894 - learning_rate: 1.0000e-04\n",
      "Epoch 142/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6482 - kl_loss: 1.4041e-05 - loss: 3.4127 - reconstruction_loss: 1.7645 - val_ae_loss: 1.6861 - val_kl_loss: 2.9401e-05 - val_loss: 3.4741 - val_reconstruction_loss: 1.7880 - learning_rate: 1.0000e-04\n",
      "Epoch 143/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6442 - kl_loss: 1.8916e-05 - loss: 3.3910 - reconstruction_loss: 1.7469 - val_ae_loss: 1.6848 - val_kl_loss: 2.8857e-05 - val_loss: 3.4740 - val_reconstruction_loss: 1.7892 - learning_rate: 1.0000e-04\n",
      "Epoch 144/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6617 - kl_loss: 1.3660e-05 - loss: 3.4323 - reconstruction_loss: 1.7706 - val_ae_loss: 1.6836 - val_kl_loss: 2.8410e-05 - val_loss: 3.4724 - val_reconstruction_loss: 1.7887 - learning_rate: 1.0000e-04\n",
      "Epoch 145/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6424 - kl_loss: 1.5010e-05 - loss: 3.4049 - reconstruction_loss: 1.7625 - val_ae_loss: 1.6824 - val_kl_loss: 2.8085e-05 - val_loss: 3.4708 - val_reconstruction_loss: 1.7884 - learning_rate: 1.0000e-04\n",
      "Epoch 146/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6464 - kl_loss: 1.2714e-05 - loss: 3.4047 - reconstruction_loss: 1.7582 - val_ae_loss: 1.6813 - val_kl_loss: 2.7183e-05 - val_loss: 3.4689 - val_reconstruction_loss: 1.7876 - learning_rate: 1.0000e-04\n",
      "Epoch 147/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6631 - kl_loss: 1.1414e-05 - loss: 3.4454 - reconstruction_loss: 1.7822 - val_ae_loss: 1.6806 - val_kl_loss: 2.6445e-05 - val_loss: 3.4698 - val_reconstruction_loss: 1.7891 - learning_rate: 1.0000e-04\n",
      "Epoch 148/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6677 - kl_loss: 1.1791e-05 - loss: 3.4377 - reconstruction_loss: 1.7700 - val_ae_loss: 1.6791 - val_kl_loss: 2.6128e-05 - val_loss: 3.4680 - val_reconstruction_loss: 1.7888 - learning_rate: 1.0000e-04\n",
      "Epoch 149/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6576 - kl_loss: 8.3629e-06 - loss: 3.4285 - reconstruction_loss: 1.7710 - val_ae_loss: 1.6779 - val_kl_loss: 2.5695e-05 - val_loss: 3.4662 - val_reconstruction_loss: 1.7883 - learning_rate: 1.0000e-04\n",
      "Epoch 150/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6670 - kl_loss: 1.1469e-05 - loss: 3.4471 - reconstruction_loss: 1.7801 - val_ae_loss: 1.6765 - val_kl_loss: 2.5049e-05 - val_loss: 3.4664 - val_reconstruction_loss: 1.7899 - learning_rate: 1.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 149.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:52:48,268 - INFO - Hybrid Autoencoder-VAE training completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:52:48,812 - INFO - Dynamic threshold: 1.029132 (fallback: 0.165687)\n",
      "2025-03-22 12:52:48,933 - INFO - Fold 1 - Training time: 39.63s, Best val loss: 3.466235\n",
      "2025-03-22 12:52:48,933 - INFO - Training fold 2/5\n",
      "2025-03-22 12:52:48,934 - INFO - Starting hybrid Autoencoder-VAE training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - ae_loss: 1.6669 - kl_loss: 1.7747e-05 - loss: 3.4312 - reconstruction_loss: 1.7643 - val_ae_loss: 1.6164 - val_kl_loss: 6.3498e-06 - val_loss: 3.3648 - val_reconstruction_loss: 1.7484 - learning_rate: 1.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6242 - kl_loss: 1.1376e-05 - loss: 3.3560 - reconstruction_loss: 1.7319 - val_ae_loss: 1.6146 - val_kl_loss: 5.9724e-06 - val_loss: 3.3632 - val_reconstruction_loss: 1.7486 - learning_rate: 1.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6875 - kl_loss: 9.2915e-06 - loss: 3.4888 - reconstruction_loss: 1.8013 - val_ae_loss: 1.6137 - val_kl_loss: 5.6136e-06 - val_loss: 3.3615 - val_reconstruction_loss: 1.7478 - learning_rate: 1.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6645 - kl_loss: 1.2923e-05 - loss: 3.4392 - reconstruction_loss: 1.7747 - val_ae_loss: 1.6127 - val_kl_loss: 5.4122e-06 - val_loss: 3.3616 - val_reconstruction_loss: 1.7489 - learning_rate: 1.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6522 - kl_loss: 1.5536e-05 - loss: 3.4322 - reconstruction_loss: 1.7800 - val_ae_loss: 1.6118 - val_kl_loss: 5.5092e-06 - val_loss: 3.3605 - val_reconstruction_loss: 1.7487 - learning_rate: 1.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.6519 - kl_loss: 1.6439e-05 - loss: 3.4199 - reconstruction_loss: 1.7680 - val_ae_loss: 1.6109 - val_kl_loss: 5.2185e-06 - val_loss: 3.3607 - val_reconstruction_loss: 1.7498 - learning_rate: 1.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6333 - kl_loss: 8.9535e-06 - loss: 3.3768 - reconstruction_loss: 1.7435 - val_ae_loss: 1.6093 - val_kl_loss: 4.9468e-06 - val_loss: 3.3581 - val_reconstruction_loss: 1.7488 - learning_rate: 1.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6444 - kl_loss: 1.0756e-05 - loss: 3.4077 - reconstruction_loss: 1.7633 - val_ae_loss: 1.6078 - val_kl_loss: 4.9995e-06 - val_loss: 3.3570 - val_reconstruction_loss: 1.7492 - learning_rate: 1.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6452 - kl_loss: 1.4394e-05 - loss: 3.4117 - reconstruction_loss: 1.7665 - val_ae_loss: 1.6066 - val_kl_loss: 4.7134e-06 - val_loss: 3.3560 - val_reconstruction_loss: 1.7494 - learning_rate: 1.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6668 - kl_loss: 1.5177e-05 - loss: 3.4548 - reconstruction_loss: 1.7880 - val_ae_loss: 1.6055 - val_kl_loss: 4.6683e-06 - val_loss: 3.3537 - val_reconstruction_loss: 1.7483 - learning_rate: 1.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6205 - kl_loss: 1.2800e-05 - loss: 3.3547 - reconstruction_loss: 1.7342 - val_ae_loss: 1.6038 - val_kl_loss: 4.4737e-06 - val_loss: 3.3539 - val_reconstruction_loss: 1.7501 - learning_rate: 1.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6572 - kl_loss: 9.4368e-06 - loss: 3.4344 - reconstruction_loss: 1.7771 - val_ae_loss: 1.6026 - val_kl_loss: 4.4065e-06 - val_loss: 3.3521 - val_reconstruction_loss: 1.7495 - learning_rate: 1.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6605 - kl_loss: 1.0164e-05 - loss: 3.4522 - reconstruction_loss: 1.7917 - val_ae_loss: 1.6013 - val_kl_loss: 4.5063e-06 - val_loss: 3.3503 - val_reconstruction_loss: 1.7489 - learning_rate: 1.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6298 - kl_loss: 7.7513e-06 - loss: 3.3878 - reconstruction_loss: 1.7580 - val_ae_loss: 1.5995 - val_kl_loss: 4.4882e-06 - val_loss: 3.3496 - val_reconstruction_loss: 1.7501 - learning_rate: 1.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6648 - kl_loss: 7.9215e-06 - loss: 3.4652 - reconstruction_loss: 1.8004 - val_ae_loss: 1.5981 - val_kl_loss: 4.1545e-06 - val_loss: 3.3473 - val_reconstruction_loss: 1.7492 - learning_rate: 1.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6405 - kl_loss: 9.6628e-06 - loss: 3.4114 - reconstruction_loss: 1.7709 - val_ae_loss: 1.5960 - val_kl_loss: 4.1959e-06 - val_loss: 3.3462 - val_reconstruction_loss: 1.7502 - learning_rate: 1.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6536 - kl_loss: 7.3299e-06 - loss: 3.4414 - reconstruction_loss: 1.7878 - val_ae_loss: 1.5944 - val_kl_loss: 4.2548e-06 - val_loss: 3.3443 - val_reconstruction_loss: 1.7498 - learning_rate: 1.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.6675 - kl_loss: 9.6034e-06 - loss: 3.4740 - reconstruction_loss: 1.8064 - val_ae_loss: 1.5932 - val_kl_loss: 4.0592e-06 - val_loss: 3.3422 - val_reconstruction_loss: 1.7490 - learning_rate: 1.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6268 - kl_loss: 5.8252e-06 - loss: 3.3909 - reconstruction_loss: 1.7641 - val_ae_loss: 1.5913 - val_kl_loss: 4.1195e-06 - val_loss: 3.3405 - val_reconstruction_loss: 1.7492 - learning_rate: 1.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6477 - kl_loss: 7.2107e-06 - loss: 3.4343 - reconstruction_loss: 1.7865 - val_ae_loss: 1.5895 - val_kl_loss: 3.8374e-06 - val_loss: 3.3390 - val_reconstruction_loss: 1.7495 - learning_rate: 1.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - ae_loss: 1.5778 - kl_loss: 5.1400e-06 - loss: 3.3038 - reconstruction_loss: 1.7261 - val_ae_loss: 1.5881 - val_kl_loss: 3.7057e-06 - val_loss: 3.3376 - val_reconstruction_loss: 1.7495 - learning_rate: 1.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6265 - kl_loss: 7.5775e-06 - loss: 3.3974 - reconstruction_loss: 1.7710 - val_ae_loss: 1.5859 - val_kl_loss: 3.5699e-06 - val_loss: 3.3356 - val_reconstruction_loss: 1.7497 - learning_rate: 1.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6602 - kl_loss: 5.9925e-06 - loss: 3.4596 - reconstruction_loss: 1.7995 - val_ae_loss: 1.5841 - val_kl_loss: 3.6086e-06 - val_loss: 3.3327 - val_reconstruction_loss: 1.7486 - learning_rate: 1.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6392 - kl_loss: 8.5028e-06 - loss: 3.4275 - reconstruction_loss: 1.7884 - val_ae_loss: 1.5826 - val_kl_loss: 3.6193e-06 - val_loss: 3.3308 - val_reconstruction_loss: 1.7482 - learning_rate: 1.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6373 - kl_loss: 6.3342e-06 - loss: 3.4278 - reconstruction_loss: 1.7906 - val_ae_loss: 1.5806 - val_kl_loss: 3.6608e-06 - val_loss: 3.3297 - val_reconstruction_loss: 1.7491 - learning_rate: 1.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6168 - kl_loss: 3.3343e-06 - loss: 3.3763 - reconstruction_loss: 1.7595 - val_ae_loss: 1.5781 - val_kl_loss: 3.6950e-06 - val_loss: 3.3274 - val_reconstruction_loss: 1.7493 - learning_rate: 1.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6156 - kl_loss: 4.4898e-06 - loss: 3.3772 - reconstruction_loss: 1.7616 - val_ae_loss: 1.5774 - val_kl_loss: 3.8158e-06 - val_loss: 3.3271 - val_reconstruction_loss: 1.7496 - learning_rate: 1.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5905 - kl_loss: 5.5765e-06 - loss: 3.3355 - reconstruction_loss: 1.7450 - val_ae_loss: 1.5747 - val_kl_loss: 3.4117e-06 - val_loss: 3.3239 - val_reconstruction_loss: 1.7492 - learning_rate: 1.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6292 - kl_loss: 4.3629e-06 - loss: 3.4099 - reconstruction_loss: 1.7806 - val_ae_loss: 1.5736 - val_kl_loss: 3.3230e-06 - val_loss: 3.3227 - val_reconstruction_loss: 1.7491 - learning_rate: 1.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6178 - kl_loss: 4.3261e-06 - loss: 3.3968 - reconstruction_loss: 1.7790 - val_ae_loss: 1.5711 - val_kl_loss: 4.1582e-06 - val_loss: 3.3206 - val_reconstruction_loss: 1.7495 - learning_rate: 1.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5809 - kl_loss: 5.7788e-06 - loss: 3.3317 - reconstruction_loss: 1.7508 - val_ae_loss: 1.5691 - val_kl_loss: 3.2868e-06 - val_loss: 3.3180 - val_reconstruction_loss: 1.7489 - learning_rate: 1.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6150 - kl_loss: 4.6070e-06 - loss: 3.3876 - reconstruction_loss: 1.7726 - val_ae_loss: 1.5673 - val_kl_loss: 3.2719e-06 - val_loss: 3.3149 - val_reconstruction_loss: 1.7475 - learning_rate: 1.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6297 - kl_loss: 3.8559e-06 - loss: 3.4132 - reconstruction_loss: 1.7835 - val_ae_loss: 1.5657 - val_kl_loss: 3.2975e-06 - val_loss: 3.3156 - val_reconstruction_loss: 1.7499 - learning_rate: 1.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6215 - kl_loss: 6.8215e-06 - loss: 3.4003 - reconstruction_loss: 1.7788 - val_ae_loss: 1.5629 - val_kl_loss: 3.1125e-06 - val_loss: 3.3131 - val_reconstruction_loss: 1.7502 - learning_rate: 1.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5810 - kl_loss: 3.0564e-06 - loss: 3.3361 - reconstruction_loss: 1.7551 - val_ae_loss: 1.5610 - val_kl_loss: 3.0868e-06 - val_loss: 3.3093 - val_reconstruction_loss: 1.7482 - learning_rate: 1.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6148 - kl_loss: 4.6184e-06 - loss: 3.3874 - reconstruction_loss: 1.7726 - val_ae_loss: 1.5580 - val_kl_loss: 3.1093e-06 - val_loss: 3.3069 - val_reconstruction_loss: 1.7489 - learning_rate: 1.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6059 - kl_loss: 3.6451e-06 - loss: 3.3687 - reconstruction_loss: 1.7628 - val_ae_loss: 1.5554 - val_kl_loss: 3.1243e-06 - val_loss: 3.3045 - val_reconstruction_loss: 1.7491 - learning_rate: 1.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.6009 - kl_loss: 3.6762e-06 - loss: 3.3711 - reconstruction_loss: 1.7702 - val_ae_loss: 1.5526 - val_kl_loss: 3.0941e-06 - val_loss: 3.3018 - val_reconstruction_loss: 1.7491 - learning_rate: 1.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5668 - kl_loss: 4.3016e-06 - loss: 3.3082 - reconstruction_loss: 1.7414 - val_ae_loss: 1.5493 - val_kl_loss: 3.0362e-06 - val_loss: 3.2998 - val_reconstruction_loss: 1.7505 - learning_rate: 1.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5834 - kl_loss: 3.4768e-06 - loss: 3.3468 - reconstruction_loss: 1.7634 - val_ae_loss: 1.5471 - val_kl_loss: 3.2172e-06 - val_loss: 3.2961 - val_reconstruction_loss: 1.7490 - learning_rate: 1.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5884 - kl_loss: 2.6992e-06 - loss: 3.3528 - reconstruction_loss: 1.7644 - val_ae_loss: 1.5438 - val_kl_loss: 3.0328e-06 - val_loss: 3.2936 - val_reconstruction_loss: 1.7499 - learning_rate: 1.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5923 - kl_loss: 3.2025e-06 - loss: 3.3759 - reconstruction_loss: 1.7836 - val_ae_loss: 1.5414 - val_kl_loss: 2.9419e-06 - val_loss: 3.2899 - val_reconstruction_loss: 1.7485 - learning_rate: 1.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5843 - kl_loss: 2.0694e-06 - loss: 3.3527 - reconstruction_loss: 1.7684 - val_ae_loss: 1.5403 - val_kl_loss: 2.9857e-06 - val_loss: 3.2891 - val_reconstruction_loss: 1.7488 - learning_rate: 1.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.6098 - kl_loss: 2.7438e-06 - loss: 3.4069 - reconstruction_loss: 1.7970 - val_ae_loss: 1.5361 - val_kl_loss: 2.9790e-06 - val_loss: 3.2858 - val_reconstruction_loss: 1.7497 - learning_rate: 1.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5750 - kl_loss: 3.2483e-06 - loss: 3.3385 - reconstruction_loss: 1.7635 - val_ae_loss: 1.5343 - val_kl_loss: 2.8254e-06 - val_loss: 3.2832 - val_reconstruction_loss: 1.7489 - learning_rate: 1.0000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5840 - kl_loss: 2.3840e-06 - loss: 3.3794 - reconstruction_loss: 1.7954 - val_ae_loss: 1.5327 - val_kl_loss: 3.1411e-06 - val_loss: 3.2822 - val_reconstruction_loss: 1.7495 - learning_rate: 1.0000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5865 - kl_loss: 4.0927e-06 - loss: 3.3678 - reconstruction_loss: 1.7813 - val_ae_loss: 1.5313 - val_kl_loss: 2.8717e-06 - val_loss: 3.2809 - val_reconstruction_loss: 1.7496 - learning_rate: 1.0000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5564 - kl_loss: 2.5144e-06 - loss: 3.3175 - reconstruction_loss: 1.7611 - val_ae_loss: 1.5293 - val_kl_loss: 2.8041e-06 - val_loss: 3.2778 - val_reconstruction_loss: 1.7485 - learning_rate: 1.0000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5627 - kl_loss: 2.2331e-06 - loss: 3.3324 - reconstruction_loss: 1.7697 - val_ae_loss: 1.5283 - val_kl_loss: 2.7909e-06 - val_loss: 3.2768 - val_reconstruction_loss: 1.7485 - learning_rate: 1.0000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5467 - kl_loss: 2.3087e-06 - loss: 3.2863 - reconstruction_loss: 1.7396 - val_ae_loss: 1.5268 - val_kl_loss: 3.0195e-06 - val_loss: 3.2753 - val_reconstruction_loss: 1.7486 - learning_rate: 1.0000e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5411 - kl_loss: 2.5672e-06 - loss: 3.2801 - reconstruction_loss: 1.7390 - val_ae_loss: 1.5269 - val_kl_loss: 2.6436e-06 - val_loss: 3.2757 - val_reconstruction_loss: 1.7488 - learning_rate: 1.0000e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5759 - kl_loss: 1.4993e-06 - loss: 3.3583 - reconstruction_loss: 1.7824 - val_ae_loss: 1.5255 - val_kl_loss: 2.6613e-06 - val_loss: 3.2752 - val_reconstruction_loss: 1.7497 - learning_rate: 1.0000e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5589 - kl_loss: 2.2560e-06 - loss: 3.3228 - reconstruction_loss: 1.7639 - val_ae_loss: 1.5241 - val_kl_loss: 2.4905e-06 - val_loss: 3.2736 - val_reconstruction_loss: 1.7495 - learning_rate: 1.0000e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5645 - kl_loss: 1.9758e-06 - loss: 3.3344 - reconstruction_loss: 1.7699 - val_ae_loss: 1.5234 - val_kl_loss: 2.5457e-06 - val_loss: 3.2726 - val_reconstruction_loss: 1.7493 - learning_rate: 1.0000e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5728 - kl_loss: 1.9473e-06 - loss: 3.3713 - reconstruction_loss: 1.7985 - val_ae_loss: 1.5220 - val_kl_loss: 2.5649e-06 - val_loss: 3.2713 - val_reconstruction_loss: 1.7493 - learning_rate: 1.0000e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5610 - kl_loss: 2.7266e-06 - loss: 3.3349 - reconstruction_loss: 1.7739 - val_ae_loss: 1.5221 - val_kl_loss: 2.5750e-06 - val_loss: 3.2722 - val_reconstruction_loss: 1.7500 - learning_rate: 1.0000e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5336 - kl_loss: 2.0829e-06 - loss: 3.2844 - reconstruction_loss: 1.7508 - val_ae_loss: 1.5220 - val_kl_loss: 2.8223e-06 - val_loss: 3.2717 - val_reconstruction_loss: 1.7497 - learning_rate: 1.0000e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5756 - kl_loss: 2.4449e-06 - loss: 3.3683 - reconstruction_loss: 1.7927 - val_ae_loss: 1.5209 - val_kl_loss: 2.5875e-06 - val_loss: 3.2698 - val_reconstruction_loss: 1.7490 - learning_rate: 1.0000e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5505 - kl_loss: 1.5761e-06 - loss: 3.3071 - reconstruction_loss: 1.7566 - val_ae_loss: 1.5213 - val_kl_loss: 2.7109e-06 - val_loss: 3.2699 - val_reconstruction_loss: 1.7486 - learning_rate: 1.0000e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5647 - kl_loss: 2.2835e-06 - loss: 3.3470 - reconstruction_loss: 1.7823 - val_ae_loss: 1.5195 - val_kl_loss: 2.6066e-06 - val_loss: 3.2685 - val_reconstruction_loss: 1.7489 - learning_rate: 1.0000e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5767 - kl_loss: 1.5305e-06 - loss: 3.3632 - reconstruction_loss: 1.7864 - val_ae_loss: 1.5201 - val_kl_loss: 2.5977e-06 - val_loss: 3.2685 - val_reconstruction_loss: 1.7483 - learning_rate: 1.0000e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5654 - kl_loss: 1.6897e-06 - loss: 3.3524 - reconstruction_loss: 1.7871 - val_ae_loss: 1.5199 - val_kl_loss: 2.6627e-06 - val_loss: 3.2680 - val_reconstruction_loss: 1.7481 - learning_rate: 1.0000e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5582 - kl_loss: 1.2291e-06 - loss: 3.3275 - reconstruction_loss: 1.7693 - val_ae_loss: 1.5196 - val_kl_loss: 2.6177e-06 - val_loss: 3.2693 - val_reconstruction_loss: 1.7497 - learning_rate: 1.0000e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5775 - kl_loss: 1.4284e-06 - loss: 3.3663 - reconstruction_loss: 1.7888 - val_ae_loss: 1.5199 - val_kl_loss: 2.6058e-06 - val_loss: 3.2693 - val_reconstruction_loss: 1.7494 - learning_rate: 1.0000e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5568 - kl_loss: 1.8243e-06 - loss: 3.3332 - reconstruction_loss: 1.7764 - val_ae_loss: 1.5194 - val_kl_loss: 2.7764e-06 - val_loss: 3.2693 - val_reconstruction_loss: 1.7499 - learning_rate: 1.0000e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5577 - kl_loss: 1.5386e-06 - loss: 3.3325 - reconstruction_loss: 1.7748 - val_ae_loss: 1.5185 - val_kl_loss: 2.6508e-06 - val_loss: 3.2670 - val_reconstruction_loss: 1.7485 - learning_rate: 1.0000e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5526 - kl_loss: 1.1802e-06 - loss: 3.3241 - reconstruction_loss: 1.7715 - val_ae_loss: 1.5191 - val_kl_loss: 2.3560e-06 - val_loss: 3.2679 - val_reconstruction_loss: 1.7488 - learning_rate: 1.0000e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5708 - kl_loss: 1.3390e-06 - loss: 3.3554 - reconstruction_loss: 1.7846 - val_ae_loss: 1.5176 - val_kl_loss: 2.5534e-06 - val_loss: 3.2680 - val_reconstruction_loss: 1.7503 - learning_rate: 1.0000e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.5360 - kl_loss: 1.8060e-06 - loss: 3.2844 - reconstruction_loss: 1.7484 - val_ae_loss: 1.5175 - val_kl_loss: 2.4314e-06 - val_loss: 3.2673 - val_reconstruction_loss: 1.7497 - learning_rate: 1.0000e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5404 - kl_loss: 1.2310e-06 - loss: 3.3042 - reconstruction_loss: 1.7637 - val_ae_loss: 1.5180 - val_kl_loss: 2.1849e-06 - val_loss: 3.2673 - val_reconstruction_loss: 1.7493 - learning_rate: 1.0000e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5727 - kl_loss: 9.8405e-07 - loss: 3.3677 - reconstruction_loss: 1.7950 - val_ae_loss: 1.5181 - val_kl_loss: 2.2168e-06 - val_loss: 3.2667 - val_reconstruction_loss: 1.7485 - learning_rate: 1.0000e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5543 - kl_loss: 1.6224e-06 - loss: 3.3218 - reconstruction_loss: 1.7675 - val_ae_loss: 1.5173 - val_kl_loss: 2.4222e-06 - val_loss: 3.2668 - val_reconstruction_loss: 1.7495 - learning_rate: 1.0000e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5347 - kl_loss: 1.3015e-06 - loss: 3.2962 - reconstruction_loss: 1.7616 - val_ae_loss: 1.5172 - val_kl_loss: 2.4091e-06 - val_loss: 3.2667 - val_reconstruction_loss: 1.7495 - learning_rate: 1.0000e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5578 - kl_loss: 2.1733e-06 - loss: 3.3351 - reconstruction_loss: 1.7773 - val_ae_loss: 1.5171 - val_kl_loss: 2.0730e-06 - val_loss: 3.2667 - val_reconstruction_loss: 1.7496 - learning_rate: 1.0000e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5192 - kl_loss: 1.1148e-06 - loss: 3.2578 - reconstruction_loss: 1.7386 - val_ae_loss: 1.5156 - val_kl_loss: 2.0912e-06 - val_loss: 3.2649 - val_reconstruction_loss: 1.7493 - learning_rate: 1.0000e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5297 - kl_loss: 9.9198e-07 - loss: 3.2852 - reconstruction_loss: 1.7554 - val_ae_loss: 1.5159 - val_kl_loss: 2.3612e-06 - val_loss: 3.2654 - val_reconstruction_loss: 1.7495 - learning_rate: 1.0000e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5590 - kl_loss: 1.3346e-06 - loss: 3.3433 - reconstruction_loss: 1.7844 - val_ae_loss: 1.5154 - val_kl_loss: 2.1068e-06 - val_loss: 3.2651 - val_reconstruction_loss: 1.7497 - learning_rate: 1.0000e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5432 - kl_loss: 1.5157e-06 - loss: 3.3066 - reconstruction_loss: 1.7634 - val_ae_loss: 1.5158 - val_kl_loss: 2.3699e-06 - val_loss: 3.2649 - val_reconstruction_loss: 1.7491 - learning_rate: 1.0000e-04\n",
      "Epoch 79/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5441 - kl_loss: 1.4118e-06 - loss: 3.3048 - reconstruction_loss: 1.7607 - val_ae_loss: 1.5153 - val_kl_loss: 2.2235e-06 - val_loss: 3.2637 - val_reconstruction_loss: 1.7484 - learning_rate: 1.0000e-04\n",
      "Epoch 80/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5164 - kl_loss: 1.0131e-06 - loss: 3.2637 - reconstruction_loss: 1.7473 - val_ae_loss: 1.5144 - val_kl_loss: 2.0367e-06 - val_loss: 3.2635 - val_reconstruction_loss: 1.7491 - learning_rate: 1.0000e-04\n",
      "Epoch 81/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5490 - kl_loss: 9.4364e-07 - loss: 3.3281 - reconstruction_loss: 1.7791 - val_ae_loss: 1.5142 - val_kl_loss: 2.1760e-06 - val_loss: 3.2636 - val_reconstruction_loss: 1.7494 - learning_rate: 1.0000e-04\n",
      "Epoch 82/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5369 - kl_loss: 1.0128e-06 - loss: 3.3066 - reconstruction_loss: 1.7697 - val_ae_loss: 1.5153 - val_kl_loss: 2.2402e-06 - val_loss: 3.2636 - val_reconstruction_loss: 1.7483 - learning_rate: 1.0000e-04\n",
      "Epoch 83/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5373 - kl_loss: 7.2043e-07 - loss: 3.3069 - reconstruction_loss: 1.7696 - val_ae_loss: 1.5142 - val_kl_loss: 2.8224e-06 - val_loss: 3.2631 - val_reconstruction_loss: 1.7490 - learning_rate: 1.0000e-04\n",
      "Epoch 84/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5372 - kl_loss: 9.6380e-07 - loss: 3.3135 - reconstruction_loss: 1.7763 - val_ae_loss: 1.5152 - val_kl_loss: 2.4504e-06 - val_loss: 3.2640 - val_reconstruction_loss: 1.7488 - learning_rate: 1.0000e-04\n",
      "Epoch 85/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5366 - kl_loss: 1.1383e-06 - loss: 3.3090 - reconstruction_loss: 1.7724 - val_ae_loss: 1.5146 - val_kl_loss: 2.3262e-06 - val_loss: 3.2627 - val_reconstruction_loss: 1.7480 - learning_rate: 1.0000e-04\n",
      "Epoch 86/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5442 - kl_loss: 1.4152e-06 - loss: 3.3219 - reconstruction_loss: 1.7776 - val_ae_loss: 1.5138 - val_kl_loss: 1.9220e-06 - val_loss: 3.2633 - val_reconstruction_loss: 1.7495 - learning_rate: 1.0000e-04\n",
      "Epoch 87/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5198 - kl_loss: 4.8356e-07 - loss: 3.2727 - reconstruction_loss: 1.7529 - val_ae_loss: 1.5135 - val_kl_loss: 1.9803e-06 - val_loss: 3.2636 - val_reconstruction_loss: 1.7501 - learning_rate: 1.0000e-04\n",
      "Epoch 88/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5029 - kl_loss: 5.9942e-07 - loss: 3.2392 - reconstruction_loss: 1.7363 - val_ae_loss: 1.5130 - val_kl_loss: 2.0988e-06 - val_loss: 3.2623 - val_reconstruction_loss: 1.7493 - learning_rate: 1.0000e-04\n",
      "Epoch 89/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5835 - kl_loss: 8.9057e-07 - loss: 3.3938 - reconstruction_loss: 1.8103 - val_ae_loss: 1.5128 - val_kl_loss: 1.9973e-06 - val_loss: 3.2636 - val_reconstruction_loss: 1.7508 - learning_rate: 1.0000e-04\n",
      "Epoch 90/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5513 - kl_loss: 6.0310e-07 - loss: 3.3408 - reconstruction_loss: 1.7896 - val_ae_loss: 1.5124 - val_kl_loss: 2.1282e-06 - val_loss: 3.2631 - val_reconstruction_loss: 1.7507 - learning_rate: 1.0000e-04\n",
      "Epoch 91/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5298 - kl_loss: 7.9006e-07 - loss: 3.2953 - reconstruction_loss: 1.7656 - val_ae_loss: 1.5128 - val_kl_loss: 2.2200e-06 - val_loss: 3.2624 - val_reconstruction_loss: 1.7496 - learning_rate: 1.0000e-04\n",
      "Epoch 92/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5415 - kl_loss: 8.6984e-07 - loss: 3.3117 - reconstruction_loss: 1.7702 - val_ae_loss: 1.5125 - val_kl_loss: 2.4559e-06 - val_loss: 3.2629 - val_reconstruction_loss: 1.7504 - learning_rate: 1.0000e-04\n",
      "Epoch 93/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5061 - kl_loss: 7.4148e-07 - loss: 3.2688 - reconstruction_loss: 1.7627 - val_ae_loss: 1.5130 - val_kl_loss: 2.2030e-06 - val_loss: 3.2623 - val_reconstruction_loss: 1.7493 - learning_rate: 1.0000e-04\n",
      "Epoch 94/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5179 - kl_loss: 1.0223e-06 - loss: 3.2820 - reconstruction_loss: 1.7641 - val_ae_loss: 1.5123 - val_kl_loss: 2.1608e-06 - val_loss: 3.2614 - val_reconstruction_loss: 1.7490 - learning_rate: 1.0000e-04\n",
      "Epoch 95/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5434 - kl_loss: 6.8970e-07 - loss: 3.3141 - reconstruction_loss: 1.7707 - val_ae_loss: 1.5116 - val_kl_loss: 1.9587e-06 - val_loss: 3.2614 - val_reconstruction_loss: 1.7498 - learning_rate: 1.0000e-04\n",
      "Epoch 96/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5278 - kl_loss: 3.8795e-07 - loss: 3.3039 - reconstruction_loss: 1.7760 - val_ae_loss: 1.5122 - val_kl_loss: 2.4675e-06 - val_loss: 3.2609 - val_reconstruction_loss: 1.7486 - learning_rate: 1.0000e-04\n",
      "Epoch 97/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5209 - kl_loss: 7.4124e-07 - loss: 3.2822 - reconstruction_loss: 1.7613 - val_ae_loss: 1.5116 - val_kl_loss: 2.3829e-06 - val_loss: 3.2619 - val_reconstruction_loss: 1.7504 - learning_rate: 1.0000e-04\n",
      "Epoch 98/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5551 - kl_loss: 8.5063e-07 - loss: 3.3371 - reconstruction_loss: 1.7820 - val_ae_loss: 1.5112 - val_kl_loss: 1.8600e-06 - val_loss: 3.2601 - val_reconstruction_loss: 1.7489 - learning_rate: 1.0000e-04\n",
      "Epoch 99/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5381 - kl_loss: 5.8543e-07 - loss: 3.3210 - reconstruction_loss: 1.7829 - val_ae_loss: 1.5116 - val_kl_loss: 1.9493e-06 - val_loss: 3.2604 - val_reconstruction_loss: 1.7487 - learning_rate: 1.0000e-04\n",
      "Epoch 100/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5042 - kl_loss: 9.7400e-07 - loss: 3.2506 - reconstruction_loss: 1.7465 - val_ae_loss: 1.5103 - val_kl_loss: 2.1995e-06 - val_loss: 3.2594 - val_reconstruction_loss: 1.7491 - learning_rate: 1.0000e-04\n",
      "Epoch 101/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5494 - kl_loss: 6.4642e-07 - loss: 3.3287 - reconstruction_loss: 1.7793 - val_ae_loss: 1.5120 - val_kl_loss: 2.2513e-06 - val_loss: 3.2615 - val_reconstruction_loss: 1.7495 - learning_rate: 1.0000e-04\n",
      "Epoch 102/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5368 - kl_loss: 8.2012e-07 - loss: 3.3168 - reconstruction_loss: 1.7800 - val_ae_loss: 1.5107 - val_kl_loss: 2.0436e-06 - val_loss: 3.2595 - val_reconstruction_loss: 1.7488 - learning_rate: 1.0000e-04\n",
      "Epoch 103/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5124 - kl_loss: 5.6868e-07 - loss: 3.2712 - reconstruction_loss: 1.7588 - val_ae_loss: 1.5101 - val_kl_loss: 2.5488e-06 - val_loss: 3.2587 - val_reconstruction_loss: 1.7485 - learning_rate: 1.0000e-04\n",
      "Epoch 104/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.4975 - kl_loss: 1.0123e-06 - loss: 3.2451 - reconstruction_loss: 1.7476 - val_ae_loss: 1.5103 - val_kl_loss: 2.1890e-06 - val_loss: 3.2597 - val_reconstruction_loss: 1.7494 - learning_rate: 1.0000e-04\n",
      "Epoch 105/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5190 - kl_loss: 5.4222e-07 - loss: 3.2631 - reconstruction_loss: 1.7441 - val_ae_loss: 1.5102 - val_kl_loss: 2.2300e-06 - val_loss: 3.2598 - val_reconstruction_loss: 1.7496 - learning_rate: 1.0000e-04\n",
      "Epoch 106/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5214 - kl_loss: 6.2668e-07 - loss: 3.2797 - reconstruction_loss: 1.7583 - val_ae_loss: 1.5107 - val_kl_loss: 2.0199e-06 - val_loss: 3.2597 - val_reconstruction_loss: 1.7490 - learning_rate: 1.0000e-04\n",
      "Epoch 107/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5191 - kl_loss: 7.9641e-07 - loss: 3.2877 - reconstruction_loss: 1.7686 - val_ae_loss: 1.5101 - val_kl_loss: 2.2821e-06 - val_loss: 3.2594 - val_reconstruction_loss: 1.7493 - learning_rate: 1.0000e-04\n",
      "Epoch 108/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - ae_loss: 1.5319 - kl_loss: 1.0029e-06 - loss: 3.2965 - reconstruction_loss: 1.7646 - val_ae_loss: 1.5098 - val_kl_loss: 2.8027e-06 - val_loss: 3.2592 - val_reconstruction_loss: 1.7494 - learning_rate: 1.0000e-04\n",
      "Epoch 109/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5299 - kl_loss: 9.3888e-07 - loss: 3.3221 - reconstruction_loss: 1.7922 - val_ae_loss: 1.5113 - val_kl_loss: 2.1052e-06 - val_loss: 3.2609 - val_reconstruction_loss: 1.7496 - learning_rate: 1.0000e-04\n",
      "Epoch 110/150\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - ae_loss: 1.6077 - kl_loss: 1.6969e-06 - loss: 3.4513 - reconstruction_loss: 1.8437\n",
      "Epoch 110: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5424 - kl_loss: 9.5466e-07 - loss: 3.3192 - reconstruction_loss: 1.7767 - val_ae_loss: 1.5093 - val_kl_loss: 2.6281e-06 - val_loss: 3.2586 - val_reconstruction_loss: 1.7493 - learning_rate: 1.0000e-04\n",
      "Epoch 111/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5282 - kl_loss: 8.7457e-07 - loss: 3.3109 - reconstruction_loss: 1.7826 - val_ae_loss: 1.5093 - val_kl_loss: 1.8469e-06 - val_loss: 3.2588 - val_reconstruction_loss: 1.7495 - learning_rate: 5.0000e-05\n",
      "Epoch 112/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5470 - kl_loss: 5.2591e-07 - loss: 3.3299 - reconstruction_loss: 1.7829 - val_ae_loss: 1.5095 - val_kl_loss: 1.8605e-06 - val_loss: 3.2586 - val_reconstruction_loss: 1.7490 - learning_rate: 5.0000e-05\n",
      "Epoch 113/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5013 - kl_loss: 3.3218e-07 - loss: 3.2534 - reconstruction_loss: 1.7521 - val_ae_loss: 1.5087 - val_kl_loss: 1.7755e-06 - val_loss: 3.2579 - val_reconstruction_loss: 1.7492 - learning_rate: 5.0000e-05\n",
      "Epoch 114/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5189 - kl_loss: 2.4163e-07 - loss: 3.2924 - reconstruction_loss: 1.7735 - val_ae_loss: 1.5089 - val_kl_loss: 1.8451e-06 - val_loss: 3.2578 - val_reconstruction_loss: 1.7489 - learning_rate: 5.0000e-05\n",
      "Epoch 115/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5259 - kl_loss: 3.5466e-07 - loss: 3.3113 - reconstruction_loss: 1.7855 - val_ae_loss: 1.5090 - val_kl_loss: 1.8387e-06 - val_loss: 3.2579 - val_reconstruction_loss: 1.7489 - learning_rate: 5.0000e-05\n",
      "Epoch 116/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5048 - kl_loss: 3.6169e-07 - loss: 3.2584 - reconstruction_loss: 1.7536 - val_ae_loss: 1.5086 - val_kl_loss: 1.9051e-06 - val_loss: 3.2582 - val_reconstruction_loss: 1.7495 - learning_rate: 5.0000e-05\n",
      "Epoch 117/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.4877 - kl_loss: 4.3859e-07 - loss: 3.2227 - reconstruction_loss: 1.7350 - val_ae_loss: 1.5086 - val_kl_loss: 1.8159e-06 - val_loss: 3.2585 - val_reconstruction_loss: 1.7499 - learning_rate: 5.0000e-05\n",
      "Epoch 118/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5112 - kl_loss: 2.8892e-07 - loss: 3.2760 - reconstruction_loss: 1.7648 - val_ae_loss: 1.5089 - val_kl_loss: 1.7619e-06 - val_loss: 3.2585 - val_reconstruction_loss: 1.7496 - learning_rate: 5.0000e-05\n",
      "Epoch 119/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5496 - kl_loss: 3.1816e-07 - loss: 3.3404 - reconstruction_loss: 1.7908 - val_ae_loss: 1.5085 - val_kl_loss: 1.8370e-06 - val_loss: 3.2563 - val_reconstruction_loss: 1.7479 - learning_rate: 5.0000e-05\n",
      "Epoch 120/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5414 - kl_loss: 2.3254e-07 - loss: 3.3212 - reconstruction_loss: 1.7799 - val_ae_loss: 1.5086 - val_kl_loss: 1.7977e-06 - val_loss: 3.2581 - val_reconstruction_loss: 1.7495 - learning_rate: 5.0000e-05\n",
      "Epoch 121/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5189 - kl_loss: 2.7883e-07 - loss: 3.2791 - reconstruction_loss: 1.7602 - val_ae_loss: 1.5085 - val_kl_loss: 2.1162e-06 - val_loss: 3.2575 - val_reconstruction_loss: 1.7491 - learning_rate: 5.0000e-05\n",
      "Epoch 122/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5078 - kl_loss: 7.1714e-07 - loss: 3.2647 - reconstruction_loss: 1.7568 - val_ae_loss: 1.5080 - val_kl_loss: 1.9604e-06 - val_loss: 3.2571 - val_reconstruction_loss: 1.7491 - learning_rate: 5.0000e-05\n",
      "Epoch 123/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5177 - kl_loss: 3.6247e-07 - loss: 3.2820 - reconstruction_loss: 1.7643 - val_ae_loss: 1.5078 - val_kl_loss: 1.7917e-06 - val_loss: 3.2578 - val_reconstruction_loss: 1.7499 - learning_rate: 5.0000e-05\n",
      "Epoch 124/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5305 - kl_loss: 2.8673e-07 - loss: 3.3161 - reconstruction_loss: 1.7856 - val_ae_loss: 1.5079 - val_kl_loss: 1.7661e-06 - val_loss: 3.2571 - val_reconstruction_loss: 1.7491 - learning_rate: 5.0000e-05\n",
      "Epoch 125/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5296 - kl_loss: 4.0093e-07 - loss: 3.3118 - reconstruction_loss: 1.7822 - val_ae_loss: 1.5079 - val_kl_loss: 1.9556e-06 - val_loss: 3.2573 - val_reconstruction_loss: 1.7494 - learning_rate: 5.0000e-05\n",
      "Epoch 126/150\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.4559 - kl_loss: 2.3842e-07 - loss: 3.1216 - reconstruction_loss: 1.6657\n",
      "Epoch 126: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5056 - kl_loss: 3.9097e-07 - loss: 3.2601 - reconstruction_loss: 1.7544 - val_ae_loss: 1.5082 - val_kl_loss: 1.7618e-06 - val_loss: 3.2571 - val_reconstruction_loss: 1.7488 - learning_rate: 5.0000e-05\n",
      "Epoch 127/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5020 - kl_loss: 3.3308e-07 - loss: 3.2582 - reconstruction_loss: 1.7562 - val_ae_loss: 1.5078 - val_kl_loss: 1.7417e-06 - val_loss: 3.2566 - val_reconstruction_loss: 1.7488 - learning_rate: 2.5000e-05\n",
      "Epoch 128/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5311 - kl_loss: 2.3076e-07 - loss: 3.3242 - reconstruction_loss: 1.7931 - val_ae_loss: 1.5078 - val_kl_loss: 1.7492e-06 - val_loss: 3.2567 - val_reconstruction_loss: 1.7489 - learning_rate: 2.5000e-05\n",
      "Epoch 129/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.4976 - kl_loss: 1.2657e-07 - loss: 3.2645 - reconstruction_loss: 1.7669 - val_ae_loss: 1.5078 - val_kl_loss: 1.7275e-06 - val_loss: 3.2562 - val_reconstruction_loss: 1.7484 - learning_rate: 2.5000e-05\n",
      "Epoch 130/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5148 - kl_loss: 2.6261e-07 - loss: 3.3070 - reconstruction_loss: 1.7922 - val_ae_loss: 1.5077 - val_kl_loss: 1.7751e-06 - val_loss: 3.2581 - val_reconstruction_loss: 1.7504 - learning_rate: 2.5000e-05\n",
      "Epoch 131/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5081 - kl_loss: 1.9629e-07 - loss: 3.2756 - reconstruction_loss: 1.7675 - val_ae_loss: 1.5077 - val_kl_loss: 1.6597e-06 - val_loss: 3.2576 - val_reconstruction_loss: 1.7499 - learning_rate: 2.5000e-05\n",
      "Epoch 132/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5044 - kl_loss: 2.0053e-07 - loss: 3.2544 - reconstruction_loss: 1.7500 - val_ae_loss: 1.5076 - val_kl_loss: 1.6969e-06 - val_loss: 3.2568 - val_reconstruction_loss: 1.7492 - learning_rate: 2.5000e-05\n",
      "Epoch 133/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5098 - kl_loss: 1.6246e-07 - loss: 3.2858 - reconstruction_loss: 1.7760 - val_ae_loss: 1.5076 - val_kl_loss: 1.6668e-06 - val_loss: 3.2580 - val_reconstruction_loss: 1.7505 - learning_rate: 2.5000e-05\n",
      "Epoch 134/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5464 - kl_loss: 1.4919e-07 - loss: 3.3406 - reconstruction_loss: 1.7942 - val_ae_loss: 1.5074 - val_kl_loss: 1.6539e-06 - val_loss: 3.2566 - val_reconstruction_loss: 1.7492 - learning_rate: 2.5000e-05\n",
      "Epoch 135/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5269 - kl_loss: 2.5879e-07 - loss: 3.2994 - reconstruction_loss: 1.7725 - val_ae_loss: 1.5072 - val_kl_loss: 1.6659e-06 - val_loss: 3.2571 - val_reconstruction_loss: 1.7499 - learning_rate: 2.5000e-05\n",
      "Epoch 136/150\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.6045 - kl_loss: 5.3179e-07 - loss: 3.4972 - reconstruction_loss: 1.8928\n",
      "Epoch 136: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5366 - kl_loss: 2.7730e-07 - loss: 3.3322 - reconstruction_loss: 1.7957 - val_ae_loss: 1.5076 - val_kl_loss: 1.6519e-06 - val_loss: 3.2561 - val_reconstruction_loss: 1.7485 - learning_rate: 2.5000e-05\n",
      "Epoch 137/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5197 - kl_loss: 2.2789e-07 - loss: 3.2822 - reconstruction_loss: 1.7625 - val_ae_loss: 1.5073 - val_kl_loss: 1.6528e-06 - val_loss: 3.2565 - val_reconstruction_loss: 1.7491 - learning_rate: 1.2500e-05\n",
      "Epoch 138/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.4907 - kl_loss: 1.1006e-07 - loss: 3.2521 - reconstruction_loss: 1.7614 - val_ae_loss: 1.5074 - val_kl_loss: 1.7321e-06 - val_loss: 3.2567 - val_reconstruction_loss: 1.7493 - learning_rate: 1.2500e-05\n",
      "Epoch 139/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.4855 - kl_loss: 2.2657e-07 - loss: 3.2169 - reconstruction_loss: 1.7314 - val_ae_loss: 1.5074 - val_kl_loss: 1.7349e-06 - val_loss: 3.2571 - val_reconstruction_loss: 1.7497 - learning_rate: 1.2500e-05\n",
      "Epoch 140/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5154 - kl_loss: 2.9855e-07 - loss: 3.2768 - reconstruction_loss: 1.7614 - val_ae_loss: 1.5074 - val_kl_loss: 1.7130e-06 - val_loss: 3.2568 - val_reconstruction_loss: 1.7494 - learning_rate: 1.2500e-05\n",
      "Epoch 141/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5046 - kl_loss: 2.5712e-07 - loss: 3.2804 - reconstruction_loss: 1.7758 - val_ae_loss: 1.5072 - val_kl_loss: 1.6699e-06 - val_loss: 3.2555 - val_reconstruction_loss: 1.7483 - learning_rate: 1.2500e-05\n",
      "Epoch 142/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5239 - kl_loss: 1.7428e-07 - loss: 3.3005 - reconstruction_loss: 1.7767 - val_ae_loss: 1.5073 - val_kl_loss: 1.6923e-06 - val_loss: 3.2568 - val_reconstruction_loss: 1.7495 - learning_rate: 1.2500e-05\n",
      "Epoch 143/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.4978 - kl_loss: 1.1139e-07 - loss: 3.2524 - reconstruction_loss: 1.7546 - val_ae_loss: 1.5073 - val_kl_loss: 1.6503e-06 - val_loss: 3.2568 - val_reconstruction_loss: 1.7495 - learning_rate: 1.2500e-05\n",
      "Epoch 144/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.5094 - kl_loss: 2.0724e-07 - loss: 3.2484 - reconstruction_loss: 1.7390 - val_ae_loss: 1.5073 - val_kl_loss: 1.6572e-06 - val_loss: 3.2559 - val_reconstruction_loss: 1.7486 - learning_rate: 1.2500e-05\n",
      "Epoch 145/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5375 - kl_loss: 1.6612e-07 - loss: 3.3267 - reconstruction_loss: 1.7893 - val_ae_loss: 1.5073 - val_kl_loss: 1.6592e-06 - val_loss: 3.2562 - val_reconstruction_loss: 1.7489 - learning_rate: 1.2500e-05\n",
      "Epoch 146/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5133 - kl_loss: 1.1454e-07 - loss: 3.2782 - reconstruction_loss: 1.7649 - val_ae_loss: 1.5072 - val_kl_loss: 1.6444e-06 - val_loss: 3.2561 - val_reconstruction_loss: 1.7489 - learning_rate: 1.2500e-05\n",
      "Epoch 147/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.4920 - kl_loss: 1.7280e-07 - loss: 3.2545 - reconstruction_loss: 1.7624 - val_ae_loss: 1.5072 - val_kl_loss: 1.6411e-06 - val_loss: 3.2567 - val_reconstruction_loss: 1.7495 - learning_rate: 1.2500e-05\n",
      "Epoch 148/150\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - ae_loss: 1.3300 - kl_loss: 0.0000e+00 - loss: 2.9195 - reconstruction_loss: 1.5894\n",
      "Epoch 148: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5242 - kl_loss: 1.2880e-07 - loss: 3.3024 - reconstruction_loss: 1.7783 - val_ae_loss: 1.5072 - val_kl_loss: 1.6442e-06 - val_loss: 3.2561 - val_reconstruction_loss: 1.7489 - learning_rate: 1.2500e-05\n",
      "Epoch 149/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5146 - kl_loss: 1.9085e-07 - loss: 3.2955 - reconstruction_loss: 1.7809 - val_ae_loss: 1.5071 - val_kl_loss: 1.6488e-06 - val_loss: 3.2557 - val_reconstruction_loss: 1.7487 - learning_rate: 6.2500e-06\n",
      "Epoch 150/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5400 - kl_loss: 1.1901e-07 - loss: 3.3268 - reconstruction_loss: 1.7869 - val_ae_loss: 1.5071 - val_kl_loss: 1.6547e-06 - val_loss: 3.2554 - val_reconstruction_loss: 1.7482 - learning_rate: 6.2500e-06\n",
      "Restoring model weights from the end of the best epoch: 150.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:53:24,528 - INFO - Hybrid Autoencoder-VAE training completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:53:24,918 - INFO - Dynamic threshold: 0.665232 (fallback: 0.159999)\n",
      "2025-03-22 12:53:25,045 - INFO - Fold 2 - Training time: 36.11s, Best val loss: 3.255355\n",
      "2025-03-22 12:53:25,045 - INFO - Training fold 3/5\n",
      "2025-03-22 12:53:25,046 - INFO - Starting hybrid Autoencoder-VAE training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - ae_loss: 1.4816 - kl_loss: 5.2205e-07 - loss: 3.2187 - reconstruction_loss: 1.7371 - val_ae_loss: 1.5703 - val_kl_loss: 1.7602e-07 - val_loss: 3.3773 - val_reconstruction_loss: 1.8071 - learning_rate: 6.2500e-06\n",
      "Epoch 2/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5040 - kl_loss: 5.6350e-07 - loss: 3.2632 - reconstruction_loss: 1.7592 - val_ae_loss: 1.5702 - val_kl_loss: 1.7535e-07 - val_loss: 3.3767 - val_reconstruction_loss: 1.8065 - learning_rate: 6.2500e-06\n",
      "Epoch 3/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.4949 - kl_loss: 7.8014e-07 - loss: 3.2540 - reconstruction_loss: 1.7591 - val_ae_loss: 1.5702 - val_kl_loss: 1.7150e-07 - val_loss: 3.3779 - val_reconstruction_loss: 1.8077 - learning_rate: 6.2500e-06\n",
      "Epoch 4/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5324 - kl_loss: 6.3225e-07 - loss: 3.3109 - reconstruction_loss: 1.7785 - val_ae_loss: 1.5703 - val_kl_loss: 1.6923e-07 - val_loss: 3.3774 - val_reconstruction_loss: 1.8071 - learning_rate: 6.2500e-06\n",
      "Epoch 5/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.4901 - kl_loss: 4.6364e-07 - loss: 3.2532 - reconstruction_loss: 1.7631 - val_ae_loss: 1.5702 - val_kl_loss: 1.7522e-07 - val_loss: 3.3777 - val_reconstruction_loss: 1.8074 - learning_rate: 6.2500e-06\n",
      "Epoch 6/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.4955 - kl_loss: 2.1746e-07 - loss: 3.2403 - reconstruction_loss: 1.7448 - val_ae_loss: 1.5703 - val_kl_loss: 1.7722e-07 - val_loss: 3.3774 - val_reconstruction_loss: 1.8071 - learning_rate: 6.2500e-06\n",
      "Epoch 7/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.4939 - kl_loss: 6.6491e-07 - loss: 3.2446 - reconstruction_loss: 1.7507 - val_ae_loss: 1.5703 - val_kl_loss: 1.7669e-07 - val_loss: 3.3781 - val_reconstruction_loss: 1.8078 - learning_rate: 6.2500e-06\n",
      "Epoch 8/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5188 - kl_loss: 3.3235e-07 - loss: 3.3038 - reconstruction_loss: 1.7850 - val_ae_loss: 1.5703 - val_kl_loss: 1.7775e-07 - val_loss: 3.3777 - val_reconstruction_loss: 1.8074 - learning_rate: 6.2500e-06\n",
      "Epoch 9/150\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5821 - kl_loss: 4.2561e-07 - loss: 3.4528 - reconstruction_loss: 1.8708\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5212 - kl_loss: 4.4240e-07 - loss: 3.2977 - reconstruction_loss: 1.7765 - val_ae_loss: 1.5704 - val_kl_loss: 1.7695e-07 - val_loss: 3.3782 - val_reconstruction_loss: 1.8079 - learning_rate: 6.2500e-06\n",
      "Epoch 10/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5029 - kl_loss: 6.7022e-07 - loss: 3.2646 - reconstruction_loss: 1.7616 - val_ae_loss: 1.5703 - val_kl_loss: 1.7469e-07 - val_loss: 3.3783 - val_reconstruction_loss: 1.8080 - learning_rate: 3.1250e-06\n",
      "Epoch 11/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5313 - kl_loss: 6.8156e-07 - loss: 3.3250 - reconstruction_loss: 1.7937 - val_ae_loss: 1.5703 - val_kl_loss: 1.7123e-07 - val_loss: 3.3780 - val_reconstruction_loss: 1.8077 - learning_rate: 3.1250e-06\n",
      "Epoch 12/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5221 - kl_loss: 9.7821e-07 - loss: 3.3027 - reconstruction_loss: 1.7806 - val_ae_loss: 1.5704 - val_kl_loss: 1.6777e-07 - val_loss: 3.3770 - val_reconstruction_loss: 1.8067 - learning_rate: 3.1250e-06\n",
      "Epoch 13/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5189 - kl_loss: 7.7564e-07 - loss: 3.2821 - reconstruction_loss: 1.7632 - val_ae_loss: 1.5703 - val_kl_loss: 1.6591e-07 - val_loss: 3.3770 - val_reconstruction_loss: 1.8067 - learning_rate: 3.1250e-06\n",
      "Epoch 14/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5085 - kl_loss: 3.4942e-07 - loss: 3.2684 - reconstruction_loss: 1.7599 - val_ae_loss: 1.5704 - val_kl_loss: 1.7030e-07 - val_loss: 3.3796 - val_reconstruction_loss: 1.8093 - learning_rate: 3.1250e-06\n",
      "Epoch 15/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.4800 - kl_loss: 3.2635e-07 - loss: 3.2269 - reconstruction_loss: 1.7469 - val_ae_loss: 1.5704 - val_kl_loss: 1.7469e-07 - val_loss: 3.3778 - val_reconstruction_loss: 1.8074 - learning_rate: 3.1250e-06\n",
      "Epoch 16/150\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5434 - kl_loss: 2.5332e-07 - loss: 3.4375 - reconstruction_loss: 1.8941\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5056 - kl_loss: 5.4598e-07 - loss: 3.2716 - reconstruction_loss: 1.7660 - val_ae_loss: 1.5704 - val_kl_loss: 1.7615e-07 - val_loss: 3.3772 - val_reconstruction_loss: 1.8069 - learning_rate: 3.1250e-06\n",
      "Epoch 17/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5215 - kl_loss: 4.8592e-07 - loss: 3.2957 - reconstruction_loss: 1.7742 - val_ae_loss: 1.5704 - val_kl_loss: 1.7376e-07 - val_loss: 3.3774 - val_reconstruction_loss: 1.8070 - learning_rate: 1.5625e-06\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:53:29,110 - INFO - Hybrid Autoencoder-VAE training completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:53:29,492 - INFO - Dynamic threshold: 0.143155 (fallback: 0.162367)\n",
      "2025-03-22 12:53:29,604 - INFO - Fold 3 - Training time: 4.56s, Best val loss: 3.376719\n",
      "2025-03-22 12:53:29,605 - INFO - Training fold 4/5\n",
      "2025-03-22 12:53:29,605 - INFO - Starting hybrid Autoencoder-VAE training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - ae_loss: 1.5155 - kl_loss: 6.2787e-07 - loss: 3.2858 - reconstruction_loss: 1.7703 - val_ae_loss: 1.5134 - val_kl_loss: 1.1575e-07 - val_loss: 3.2714 - val_reconstruction_loss: 1.7581 - learning_rate: 1.5625e-06\n",
      "Epoch 2/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5179 - kl_loss: 5.8494e-07 - loss: 3.2758 - reconstruction_loss: 1.7579 - val_ae_loss: 1.5134 - val_kl_loss: 1.1415e-07 - val_loss: 3.2715 - val_reconstruction_loss: 1.7581 - learning_rate: 1.5625e-06\n",
      "Epoch 3/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5194 - kl_loss: 1.0499e-06 - loss: 3.2824 - reconstruction_loss: 1.7631 - val_ae_loss: 1.5135 - val_kl_loss: 1.1322e-07 - val_loss: 3.2708 - val_reconstruction_loss: 1.7573 - learning_rate: 1.5625e-06\n",
      "Epoch 4/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5309 - kl_loss: 1.3444e-06 - loss: 3.3216 - reconstruction_loss: 1.7907 - val_ae_loss: 1.5136 - val_kl_loss: 1.1309e-07 - val_loss: 3.2714 - val_reconstruction_loss: 1.7578 - learning_rate: 1.5625e-06\n",
      "Epoch 5/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.4881 - kl_loss: 5.7013e-07 - loss: 3.2359 - reconstruction_loss: 1.7477 - val_ae_loss: 1.5136 - val_kl_loss: 1.1269e-07 - val_loss: 3.2722 - val_reconstruction_loss: 1.7586 - learning_rate: 1.5625e-06\n",
      "Epoch 6/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5289 - kl_loss: 2.6697e-07 - loss: 3.3130 - reconstruction_loss: 1.7842 - val_ae_loss: 1.5137 - val_kl_loss: 1.1296e-07 - val_loss: 3.2714 - val_reconstruction_loss: 1.7577 - learning_rate: 1.5625e-06\n",
      "Epoch 7/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - ae_loss: 1.5362 - kl_loss: 2.7153e-07 - loss: 3.3128 - reconstruction_loss: 1.7766 - val_ae_loss: 1.5138 - val_kl_loss: 1.1216e-07 - val_loss: 3.2715 - val_reconstruction_loss: 1.7578 - learning_rate: 1.5625e-06\n",
      "Epoch 8/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5186 - kl_loss: 2.7438e-07 - loss: 3.3031 - reconstruction_loss: 1.7845 - val_ae_loss: 1.5138 - val_kl_loss: 1.1202e-07 - val_loss: 3.2715 - val_reconstruction_loss: 1.7577 - learning_rate: 1.5625e-06\n",
      "Epoch 9/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.4964 - kl_loss: 2.7790e-07 - loss: 3.2420 - reconstruction_loss: 1.7457 - val_ae_loss: 1.5138 - val_kl_loss: 1.1296e-07 - val_loss: 3.2719 - val_reconstruction_loss: 1.7581 - learning_rate: 1.5625e-06\n",
      "Epoch 10/150\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - ae_loss: 1.4827 - kl_loss: 2.8778e-07 - loss: 3.2658 - reconstruction_loss: 1.7831\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5134 - kl_loss: 4.8679e-07 - loss: 3.2733 - reconstruction_loss: 1.7599 - val_ae_loss: 1.5139 - val_kl_loss: 1.1309e-07 - val_loss: 3.2711 - val_reconstruction_loss: 1.7572 - learning_rate: 1.5625e-06\n",
      "Epoch 11/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.4963 - kl_loss: 8.4444e-07 - loss: 3.2510 - reconstruction_loss: 1.7547 - val_ae_loss: 1.5139 - val_kl_loss: 1.1349e-07 - val_loss: 3.2724 - val_reconstruction_loss: 1.7585 - learning_rate: 7.8125e-07\n",
      "Epoch 12/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5163 - kl_loss: 2.6969e-07 - loss: 3.2884 - reconstruction_loss: 1.7721 - val_ae_loss: 1.5139 - val_kl_loss: 1.1375e-07 - val_loss: 3.2707 - val_reconstruction_loss: 1.7568 - learning_rate: 7.8125e-07\n",
      "Epoch 13/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5046 - kl_loss: 2.0004e-07 - loss: 3.2488 - reconstruction_loss: 1.7442 - val_ae_loss: 1.5140 - val_kl_loss: 1.1362e-07 - val_loss: 3.2712 - val_reconstruction_loss: 1.7573 - learning_rate: 7.8125e-07\n",
      "Epoch 14/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5068 - kl_loss: 4.7625e-07 - loss: 3.2607 - reconstruction_loss: 1.7539 - val_ae_loss: 1.5140 - val_kl_loss: 1.1375e-07 - val_loss: 3.2713 - val_reconstruction_loss: 1.7573 - learning_rate: 7.8125e-07\n",
      "Epoch 15/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.4941 - kl_loss: 6.3994e-07 - loss: 3.2302 - reconstruction_loss: 1.7362 - val_ae_loss: 1.5140 - val_kl_loss: 1.1322e-07 - val_loss: 3.2721 - val_reconstruction_loss: 1.7581 - learning_rate: 7.8125e-07\n",
      "Epoch 16/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5409 - kl_loss: 5.9581e-07 - loss: 3.3202 - reconstruction_loss: 1.7793 - val_ae_loss: 1.5140 - val_kl_loss: 1.1349e-07 - val_loss: 3.2723 - val_reconstruction_loss: 1.7583 - learning_rate: 7.8125e-07\n",
      "Epoch 17/150\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - ae_loss: 1.4141 - kl_loss: 7.4506e-09 - loss: 3.0380 - reconstruction_loss: 1.6238\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.4901 - kl_loss: 3.4379e-07 - loss: 3.2315 - reconstruction_loss: 1.7414 - val_ae_loss: 1.5140 - val_kl_loss: 1.1336e-07 - val_loss: 3.2712 - val_reconstruction_loss: 1.7572 - learning_rate: 7.8125e-07\n",
      "Epoch 18/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5326 - kl_loss: 5.0948e-07 - loss: 3.3195 - reconstruction_loss: 1.7869 - val_ae_loss: 1.5140 - val_kl_loss: 1.1336e-07 - val_loss: 3.2725 - val_reconstruction_loss: 1.7585 - learning_rate: 3.9062e-07\n",
      "Epoch 19/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5107 - kl_loss: 5.3767e-07 - loss: 3.2792 - reconstruction_loss: 1.7685 - val_ae_loss: 1.5140 - val_kl_loss: 1.1322e-07 - val_loss: 3.2720 - val_reconstruction_loss: 1.7580 - learning_rate: 3.9062e-07\n",
      "Epoch 20/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5419 - kl_loss: 3.5532e-07 - loss: 3.3339 - reconstruction_loss: 1.7920 - val_ae_loss: 1.5140 - val_kl_loss: 1.1322e-07 - val_loss: 3.2712 - val_reconstruction_loss: 1.7571 - learning_rate: 3.9062e-07\n",
      "Epoch 21/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.4861 - kl_loss: 3.6649e-07 - loss: 3.2322 - reconstruction_loss: 1.7461 - val_ae_loss: 1.5141 - val_kl_loss: 1.1269e-07 - val_loss: 3.2709 - val_reconstruction_loss: 1.7569 - learning_rate: 3.9062e-07\n",
      "Epoch 22/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5416 - kl_loss: 3.4122e-07 - loss: 3.3270 - reconstruction_loss: 1.7854 - val_ae_loss: 1.5141 - val_kl_loss: 1.1309e-07 - val_loss: 3.2712 - val_reconstruction_loss: 1.7572 - learning_rate: 3.9062e-07\n",
      "Epoch 23/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - ae_loss: 1.5314 - kl_loss: 5.9348e-07 - loss: 3.2980 - reconstruction_loss: 1.7666 - val_ae_loss: 1.5141 - val_kl_loss: 1.1216e-07 - val_loss: 3.2712 - val_reconstruction_loss: 1.7571 - learning_rate: 3.9062e-07\n",
      "Epoch 24/150\n",
      "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - ae_loss: 1.5356 - kl_loss: 5.6966e-07 - loss: 3.3257 - reconstruction_loss: 1.7901 \n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - ae_loss: 1.5340 - kl_loss: 5.6729e-07 - loss: 3.3217 - reconstruction_loss: 1.7878 - val_ae_loss: 1.5141 - val_kl_loss: 1.1176e-07 - val_loss: 3.2714 - val_reconstruction_loss: 1.7573 - learning_rate: 3.9062e-07\n",
      "Epoch 25/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5228 - kl_loss: 4.0680e-07 - loss: 3.3080 - reconstruction_loss: 1.7852 - val_ae_loss: 1.5141 - val_kl_loss: 1.1176e-07 - val_loss: 3.2725 - val_reconstruction_loss: 1.7584 - learning_rate: 1.9531e-07\n",
      "Epoch 26/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5207 - kl_loss: 5.6042e-07 - loss: 3.2939 - reconstruction_loss: 1.7732 - val_ae_loss: 1.5141 - val_kl_loss: 1.1189e-07 - val_loss: 3.2706 - val_reconstruction_loss: 1.7565 - learning_rate: 1.9531e-07\n",
      "Epoch 27/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5172 - kl_loss: 4.5933e-07 - loss: 3.2762 - reconstruction_loss: 1.7591 - val_ae_loss: 1.5141 - val_kl_loss: 1.1176e-07 - val_loss: 3.2722 - val_reconstruction_loss: 1.7581 - learning_rate: 1.9531e-07\n",
      "Epoch 28/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5157 - kl_loss: 5.0632e-07 - loss: 3.2753 - reconstruction_loss: 1.7596 - val_ae_loss: 1.5141 - val_kl_loss: 1.1176e-07 - val_loss: 3.2717 - val_reconstruction_loss: 1.7576 - learning_rate: 1.9531e-07\n",
      "Epoch 29/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5251 - kl_loss: 6.6605e-07 - loss: 3.2963 - reconstruction_loss: 1.7711 - val_ae_loss: 1.5141 - val_kl_loss: 1.1216e-07 - val_loss: 3.2712 - val_reconstruction_loss: 1.7571 - learning_rate: 1.9531e-07\n",
      "Epoch 30/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5062 - kl_loss: 5.2365e-07 - loss: 3.2545 - reconstruction_loss: 1.7483 - val_ae_loss: 1.5141 - val_kl_loss: 1.1216e-07 - val_loss: 3.2721 - val_reconstruction_loss: 1.7580 - learning_rate: 1.9531e-07\n",
      "Epoch 31/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5162 - kl_loss: 5.1163e-07 - loss: 3.2764 - reconstruction_loss: 1.7602 - val_ae_loss: 1.5141 - val_kl_loss: 1.1216e-07 - val_loss: 3.2718 - val_reconstruction_loss: 1.7577 - learning_rate: 1.9531e-07\n",
      "Epoch 32/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5049 - kl_loss: 3.1761e-07 - loss: 3.2541 - reconstruction_loss: 1.7492 - val_ae_loss: 1.5141 - val_kl_loss: 1.1216e-07 - val_loss: 3.2710 - val_reconstruction_loss: 1.7569 - learning_rate: 1.9531e-07\n",
      "Epoch 33/150\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - ae_loss: 1.6076 - kl_loss: 1.0850e-06 - loss: 3.4070 - reconstruction_loss: 1.7994\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5337 - kl_loss: 7.4091e-07 - loss: 3.3098 - reconstruction_loss: 1.7761 - val_ae_loss: 1.5141 - val_kl_loss: 1.1216e-07 - val_loss: 3.2713 - val_reconstruction_loss: 1.7572 - learning_rate: 1.9531e-07\n",
      "Epoch 34/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5083 - kl_loss: 3.7843e-07 - loss: 3.2678 - reconstruction_loss: 1.7595 - val_ae_loss: 1.5141 - val_kl_loss: 1.1216e-07 - val_loss: 3.2719 - val_reconstruction_loss: 1.7578 - learning_rate: 1.0000e-07\n",
      "Epoch 35/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5187 - kl_loss: 1.0991e-06 - loss: 3.2824 - reconstruction_loss: 1.7637 - val_ae_loss: 1.5141 - val_kl_loss: 1.1216e-07 - val_loss: 3.2718 - val_reconstruction_loss: 1.7576 - learning_rate: 1.0000e-07\n",
      "Epoch 36/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5410 - kl_loss: 2.3441e-07 - loss: 3.3232 - reconstruction_loss: 1.7822 - val_ae_loss: 1.5141 - val_kl_loss: 1.1202e-07 - val_loss: 3.2716 - val_reconstruction_loss: 1.7575 - learning_rate: 1.0000e-07\n",
      "Epoch 37/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5554 - kl_loss: 4.8366e-07 - loss: 3.3624 - reconstruction_loss: 1.8070 - val_ae_loss: 1.5141 - val_kl_loss: 1.1163e-07 - val_loss: 3.2702 - val_reconstruction_loss: 1.7561 - learning_rate: 1.0000e-07\n",
      "Epoch 38/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5129 - kl_loss: 6.4698e-07 - loss: 3.2797 - reconstruction_loss: 1.7669 - val_ae_loss: 1.5141 - val_kl_loss: 1.1163e-07 - val_loss: 3.2721 - val_reconstruction_loss: 1.7580 - learning_rate: 1.0000e-07\n",
      "Epoch 39/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5346 - kl_loss: 9.1435e-07 - loss: 3.3178 - reconstruction_loss: 1.7832 - val_ae_loss: 1.5141 - val_kl_loss: 1.1163e-07 - val_loss: 3.2716 - val_reconstruction_loss: 1.7575 - learning_rate: 1.0000e-07\n",
      "Epoch 40/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5406 - kl_loss: 3.8402e-07 - loss: 3.3375 - reconstruction_loss: 1.7969 - val_ae_loss: 1.5141 - val_kl_loss: 1.1163e-07 - val_loss: 3.2719 - val_reconstruction_loss: 1.7578 - learning_rate: 1.0000e-07\n",
      "Epoch 41/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5162 - kl_loss: 3.0619e-07 - loss: 3.2811 - reconstruction_loss: 1.7649 - val_ae_loss: 1.5141 - val_kl_loss: 1.1176e-07 - val_loss: 3.2720 - val_reconstruction_loss: 1.7579 - learning_rate: 1.0000e-07\n",
      "Epoch 42/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5523 - kl_loss: 8.2180e-07 - loss: 3.3511 - reconstruction_loss: 1.7988 - val_ae_loss: 1.5141 - val_kl_loss: 1.1149e-07 - val_loss: 3.2722 - val_reconstruction_loss: 1.7581 - learning_rate: 1.0000e-07\n",
      "Epoch 43/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - ae_loss: 1.5395 - kl_loss: 7.2395e-07 - loss: 3.3489 - reconstruction_loss: 1.8094 - val_ae_loss: 1.5141 - val_kl_loss: 1.1123e-07 - val_loss: 3.2728 - val_reconstruction_loss: 1.7586 - learning_rate: 1.0000e-07\n",
      "Epoch 44/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5023 - kl_loss: 5.8908e-07 - loss: 3.2577 - reconstruction_loss: 1.7554 - val_ae_loss: 1.5141 - val_kl_loss: 1.1096e-07 - val_loss: 3.2712 - val_reconstruction_loss: 1.7571 - learning_rate: 1.0000e-07\n",
      "Epoch 45/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.4838 - kl_loss: 6.9451e-07 - loss: 3.2114 - reconstruction_loss: 1.7276 - val_ae_loss: 1.5141 - val_kl_loss: 1.1109e-07 - val_loss: 3.2714 - val_reconstruction_loss: 1.7573 - learning_rate: 1.0000e-07\n",
      "Epoch 46/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.4940 - kl_loss: 4.2595e-07 - loss: 3.2361 - reconstruction_loss: 1.7421 - val_ae_loss: 1.5141 - val_kl_loss: 1.1109e-07 - val_loss: 3.2714 - val_reconstruction_loss: 1.7573 - learning_rate: 1.0000e-07\n",
      "Epoch 47/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5287 - kl_loss: 4.3844e-07 - loss: 3.2905 - reconstruction_loss: 1.7618 - val_ae_loss: 1.5141 - val_kl_loss: 1.1109e-07 - val_loss: 3.2715 - val_reconstruction_loss: 1.7574 - learning_rate: 1.0000e-07\n",
      "Epoch 48/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.4910 - kl_loss: 1.0201e-06 - loss: 3.2229 - reconstruction_loss: 1.7319 - val_ae_loss: 1.5141 - val_kl_loss: 1.1109e-07 - val_loss: 3.2718 - val_reconstruction_loss: 1.7577 - learning_rate: 1.0000e-07\n",
      "Epoch 49/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5356 - kl_loss: 5.1102e-07 - loss: 3.3105 - reconstruction_loss: 1.7749 - val_ae_loss: 1.5141 - val_kl_loss: 1.1136e-07 - val_loss: 3.2722 - val_reconstruction_loss: 1.7580 - learning_rate: 1.0000e-07\n",
      "Epoch 50/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5361 - kl_loss: 5.5343e-07 - loss: 3.3279 - reconstruction_loss: 1.7918 - val_ae_loss: 1.5141 - val_kl_loss: 1.1136e-07 - val_loss: 3.2724 - val_reconstruction_loss: 1.7583 - learning_rate: 1.0000e-07\n",
      "Epoch 51/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.5156 - kl_loss: 5.3932e-07 - loss: 3.2699 - reconstruction_loss: 1.7543 - val_ae_loss: 1.5141 - val_kl_loss: 1.1136e-07 - val_loss: 3.2725 - val_reconstruction_loss: 1.7584 - learning_rate: 1.0000e-07\n",
      "Epoch 52/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - ae_loss: 1.4902 - kl_loss: 3.4528e-07 - loss: 3.2156 - reconstruction_loss: 1.7254 - val_ae_loss: 1.5141 - val_kl_loss: 1.1109e-07 - val_loss: 3.2720 - val_reconstruction_loss: 1.7579 - learning_rate: 1.0000e-07\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:53:42,838 - INFO - Hybrid Autoencoder-VAE training completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:53:43,269 - INFO - Dynamic threshold: 0.144352 (fallback: 0.162052)\n",
      "2025-03-22 12:53:43,397 - INFO - Fold 4 - Training time: 13.79s, Best val loss: 3.270205\n",
      "2025-03-22 12:53:43,397 - INFO - Training fold 5/5\n",
      "2025-03-22 12:53:43,398 - INFO - Starting hybrid Autoencoder-VAE training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - ae_loss: 1.4951 - kl_loss: 4.3927e-07 - loss: 3.2382 - reconstruction_loss: 1.7430 - val_ae_loss: 1.5670 - val_kl_loss: 1.4422e-07 - val_loss: 3.3614 - val_reconstruction_loss: 1.7944 - learning_rate: 1.0000e-07\n",
      "Epoch 2/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5061 - kl_loss: 3.9915e-07 - loss: 3.2688 - reconstruction_loss: 1.7627 - val_ae_loss: 1.5670 - val_kl_loss: 1.4422e-07 - val_loss: 3.3617 - val_reconstruction_loss: 1.7947 - learning_rate: 1.0000e-07\n",
      "Epoch 3/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.4858 - kl_loss: 3.6313e-07 - loss: 3.2202 - reconstruction_loss: 1.7344 - val_ae_loss: 1.5670 - val_kl_loss: 1.4422e-07 - val_loss: 3.3631 - val_reconstruction_loss: 1.7961 - learning_rate: 1.0000e-07\n",
      "Epoch 4/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5039 - kl_loss: 6.7142e-07 - loss: 3.2547 - reconstruction_loss: 1.7508 - val_ae_loss: 1.5670 - val_kl_loss: 1.4422e-07 - val_loss: 3.3622 - val_reconstruction_loss: 1.7952 - learning_rate: 1.0000e-07\n",
      "Epoch 5/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5277 - kl_loss: 9.1207e-07 - loss: 3.3234 - reconstruction_loss: 1.7957 - val_ae_loss: 1.5670 - val_kl_loss: 1.4422e-07 - val_loss: 3.3621 - val_reconstruction_loss: 1.7951 - learning_rate: 1.0000e-07\n",
      "Epoch 6/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.4829 - kl_loss: 2.8585e-07 - loss: 3.2441 - reconstruction_loss: 1.7612 - val_ae_loss: 1.5670 - val_kl_loss: 1.4422e-07 - val_loss: 3.3615 - val_reconstruction_loss: 1.7945 - learning_rate: 1.0000e-07\n",
      "Epoch 7/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5025 - kl_loss: 5.6875e-07 - loss: 3.2592 - reconstruction_loss: 1.7567 - val_ae_loss: 1.5670 - val_kl_loss: 1.4422e-07 - val_loss: 3.3616 - val_reconstruction_loss: 1.7947 - learning_rate: 1.0000e-07\n",
      "Epoch 8/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.4835 - kl_loss: 4.7826e-07 - loss: 3.2076 - reconstruction_loss: 1.7241 - val_ae_loss: 1.5670 - val_kl_loss: 1.4422e-07 - val_loss: 3.3613 - val_reconstruction_loss: 1.7943 - learning_rate: 1.0000e-07\n",
      "Epoch 9/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5110 - kl_loss: 7.2621e-07 - loss: 3.2730 - reconstruction_loss: 1.7620 - val_ae_loss: 1.5670 - val_kl_loss: 1.4422e-07 - val_loss: 3.3620 - val_reconstruction_loss: 1.7950 - learning_rate: 1.0000e-07\n",
      "Epoch 10/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.4939 - kl_loss: 5.6750e-07 - loss: 3.2389 - reconstruction_loss: 1.7450 - val_ae_loss: 1.5670 - val_kl_loss: 1.4422e-07 - val_loss: 3.3622 - val_reconstruction_loss: 1.7952 - learning_rate: 1.0000e-07\n",
      "Epoch 11/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5144 - kl_loss: 8.1134e-07 - loss: 3.2800 - reconstruction_loss: 1.7656 - val_ae_loss: 1.5670 - val_kl_loss: 1.4422e-07 - val_loss: 3.3619 - val_reconstruction_loss: 1.7949 - learning_rate: 1.0000e-07\n",
      "Epoch 12/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.4999 - kl_loss: 1.0947e-06 - loss: 3.2643 - reconstruction_loss: 1.7643 - val_ae_loss: 1.5670 - val_kl_loss: 1.4422e-07 - val_loss: 3.3621 - val_reconstruction_loss: 1.7951 - learning_rate: 1.0000e-07\n",
      "Epoch 13/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.4919 - kl_loss: 2.4576e-07 - loss: 3.2467 - reconstruction_loss: 1.7547 - val_ae_loss: 1.5670 - val_kl_loss: 1.4422e-07 - val_loss: 3.3618 - val_reconstruction_loss: 1.7948 - learning_rate: 1.0000e-07\n",
      "Epoch 14/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5035 - kl_loss: 9.2130e-07 - loss: 3.2418 - reconstruction_loss: 1.7382 - val_ae_loss: 1.5670 - val_kl_loss: 1.4422e-07 - val_loss: 3.3610 - val_reconstruction_loss: 1.7940 - learning_rate: 1.0000e-07\n",
      "Epoch 15/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - ae_loss: 1.4804 - kl_loss: 4.8342e-07 - loss: 3.2308 - reconstruction_loss: 1.7504 - val_ae_loss: 1.5670 - val_kl_loss: 1.4422e-07 - val_loss: 3.3614 - val_reconstruction_loss: 1.7944 - learning_rate: 1.0000e-07\n",
      "Epoch 16/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5082 - kl_loss: 1.2973e-06 - loss: 3.2722 - reconstruction_loss: 1.7640 - val_ae_loss: 1.5670 - val_kl_loss: 1.4422e-07 - val_loss: 3.3635 - val_reconstruction_loss: 1.7965 - learning_rate: 1.0000e-07\n",
      "Epoch 17/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.4784 - kl_loss: 2.2768e-07 - loss: 3.2254 - reconstruction_loss: 1.7470 - val_ae_loss: 1.5670 - val_kl_loss: 1.4422e-07 - val_loss: 3.3630 - val_reconstruction_loss: 1.7960 - learning_rate: 1.0000e-07\n",
      "Epoch 18/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5345 - kl_loss: 5.0775e-07 - loss: 3.3316 - reconstruction_loss: 1.7971 - val_ae_loss: 1.5670 - val_kl_loss: 1.4422e-07 - val_loss: 3.3625 - val_reconstruction_loss: 1.7955 - learning_rate: 1.0000e-07\n",
      "Epoch 19/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.4926 - kl_loss: 4.2073e-07 - loss: 3.2473 - reconstruction_loss: 1.7546 - val_ae_loss: 1.5670 - val_kl_loss: 1.4422e-07 - val_loss: 3.3627 - val_reconstruction_loss: 1.7957 - learning_rate: 1.0000e-07\n",
      "Epoch 20/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.4960 - kl_loss: 3.2693e-07 - loss: 3.2394 - reconstruction_loss: 1.7434 - val_ae_loss: 1.5670 - val_kl_loss: 1.4422e-07 - val_loss: 3.3624 - val_reconstruction_loss: 1.7954 - learning_rate: 1.0000e-07\n",
      "Epoch 21/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.4946 - kl_loss: 3.4723e-07 - loss: 3.2480 - reconstruction_loss: 1.7534 - val_ae_loss: 1.5670 - val_kl_loss: 1.4422e-07 - val_loss: 3.3616 - val_reconstruction_loss: 1.7945 - learning_rate: 1.0000e-07\n",
      "Epoch 22/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5052 - kl_loss: 3.2184e-07 - loss: 3.2760 - reconstruction_loss: 1.7708 - val_ae_loss: 1.5670 - val_kl_loss: 1.4422e-07 - val_loss: 3.3628 - val_reconstruction_loss: 1.7958 - learning_rate: 1.0000e-07\n",
      "Epoch 23/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.4946 - kl_loss: 6.2895e-07 - loss: 3.2554 - reconstruction_loss: 1.7608 - val_ae_loss: 1.5670 - val_kl_loss: 1.4422e-07 - val_loss: 3.3623 - val_reconstruction_loss: 1.7953 - learning_rate: 1.0000e-07\n",
      "Epoch 24/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5271 - kl_loss: 4.7066e-07 - loss: 3.3034 - reconstruction_loss: 1.7763 - val_ae_loss: 1.5670 - val_kl_loss: 1.4422e-07 - val_loss: 3.3614 - val_reconstruction_loss: 1.7944 - learning_rate: 1.0000e-07\n",
      "Epoch 25/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.4970 - kl_loss: 6.5676e-07 - loss: 3.2591 - reconstruction_loss: 1.7621 - val_ae_loss: 1.5670 - val_kl_loss: 1.4422e-07 - val_loss: 3.3618 - val_reconstruction_loss: 1.7948 - learning_rate: 1.0000e-07\n",
      "Epoch 26/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - ae_loss: 1.4945 - kl_loss: 7.7127e-07 - loss: 3.2404 - reconstruction_loss: 1.7459 - val_ae_loss: 1.5670 - val_kl_loss: 1.4449e-07 - val_loss: 3.3628 - val_reconstruction_loss: 1.7957 - learning_rate: 1.0000e-07\n",
      "Epoch 27/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - ae_loss: 1.4796 - kl_loss: 3.3328e-07 - loss: 3.2043 - reconstruction_loss: 1.7247 - val_ae_loss: 1.5670 - val_kl_loss: 1.4449e-07 - val_loss: 3.3618 - val_reconstruction_loss: 1.7948 - learning_rate: 1.0000e-07\n",
      "Epoch 28/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5093 - kl_loss: 4.0792e-07 - loss: 3.2715 - reconstruction_loss: 1.7622 - val_ae_loss: 1.5670 - val_kl_loss: 1.4449e-07 - val_loss: 3.3611 - val_reconstruction_loss: 1.7940 - learning_rate: 1.0000e-07\n",
      "Epoch 29/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - ae_loss: 1.5003 - kl_loss: 1.0761e-06 - loss: 3.2565 - reconstruction_loss: 1.7562 - val_ae_loss: 1.5670 - val_kl_loss: 1.4449e-07 - val_loss: 3.3626 - val_reconstruction_loss: 1.7956 - learning_rate: 1.0000e-07\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:53:50,507 - INFO - Hybrid Autoencoder-VAE training completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:53:50,881 - INFO - Dynamic threshold: 0.709434 (fallback: 0.159233)\n",
      "2025-03-22 12:53:50,994 - INFO - Fold 5 - Training time: 7.60s, Best val loss: 3.360989\n",
      "2025-03-22 12:53:50,994 - INFO - Cross-validation complete - Avg val loss: 3.345901, Avg train time: 20.34s\n",
      "2025-03-22 12:53:50,994 - INFO - Training final model on all normal data...\n",
      "2025-03-22 12:53:50,994 - INFO - Starting hybrid Autoencoder-VAE training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - ae_loss: 1.5441 - kl_loss: 6.1592e-07 - loss: 3.3448 - reconstruction_loss: 1.8007 - val_ae_loss: 1.5376 - val_kl_loss: 3.3062e-08 - val_loss: 3.2444 - val_reconstruction_loss: 1.7068 - learning_rate: 1.0000e-07\n",
      "Epoch 2/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - ae_loss: 1.5046 - kl_loss: 5.3522e-07 - loss: 3.2527 - reconstruction_loss: 1.7482 - val_ae_loss: 1.5376 - val_kl_loss: 3.3062e-08 - val_loss: 3.2437 - val_reconstruction_loss: 1.7060 - learning_rate: 1.0000e-07\n",
      "Epoch 3/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - ae_loss: 1.5118 - kl_loss: 3.6836e-07 - loss: 3.2843 - reconstruction_loss: 1.7725 - val_ae_loss: 1.5376 - val_kl_loss: 3.3062e-08 - val_loss: 3.2428 - val_reconstruction_loss: 1.7051 - learning_rate: 1.0000e-07\n",
      "Epoch 4/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - ae_loss: 1.5193 - kl_loss: 3.5018e-07 - loss: 3.2933 - reconstruction_loss: 1.7740 - val_ae_loss: 1.5376 - val_kl_loss: 3.3062e-08 - val_loss: 3.2445 - val_reconstruction_loss: 1.7069 - learning_rate: 1.0000e-07\n",
      "Epoch 5/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - ae_loss: 1.5064 - kl_loss: 3.9464e-07 - loss: 3.2717 - reconstruction_loss: 1.7653 - val_ae_loss: 1.5376 - val_kl_loss: 3.3062e-08 - val_loss: 3.2438 - val_reconstruction_loss: 1.7061 - learning_rate: 1.0000e-07\n",
      "Epoch 6/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - ae_loss: 1.5277 - kl_loss: 3.9219e-07 - loss: 3.3098 - reconstruction_loss: 1.7821 - val_ae_loss: 1.5376 - val_kl_loss: 3.3062e-08 - val_loss: 3.2434 - val_reconstruction_loss: 1.7058 - learning_rate: 1.0000e-07\n",
      "Epoch 7/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - ae_loss: 1.5313 - kl_loss: 5.0078e-07 - loss: 3.3215 - reconstruction_loss: 1.7902 - val_ae_loss: 1.5376 - val_kl_loss: 3.3062e-08 - val_loss: 3.2452 - val_reconstruction_loss: 1.7076 - learning_rate: 1.0000e-07\n",
      "Epoch 8/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - ae_loss: 1.5000 - kl_loss: 4.7983e-07 - loss: 3.2533 - reconstruction_loss: 1.7533 - val_ae_loss: 1.5376 - val_kl_loss: 3.3062e-08 - val_loss: 3.2430 - val_reconstruction_loss: 1.7054 - learning_rate: 1.0000e-07\n",
      "Epoch 9/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - ae_loss: 1.5017 - kl_loss: 4.3249e-07 - loss: 3.2567 - reconstruction_loss: 1.7550 - val_ae_loss: 1.5376 - val_kl_loss: 3.2829e-08 - val_loss: 3.2476 - val_reconstruction_loss: 1.7100 - learning_rate: 1.0000e-07\n",
      "Epoch 10/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - ae_loss: 1.4968 - kl_loss: 4.8353e-07 - loss: 3.2415 - reconstruction_loss: 1.7446 - val_ae_loss: 1.5376 - val_kl_loss: 3.2829e-08 - val_loss: 3.2419 - val_reconstruction_loss: 1.7043 - learning_rate: 1.0000e-07\n",
      "Epoch 11/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - ae_loss: 1.5366 - kl_loss: 4.5889e-07 - loss: 3.3119 - reconstruction_loss: 1.7753 - val_ae_loss: 1.5376 - val_kl_loss: 3.2596e-08 - val_loss: 3.2455 - val_reconstruction_loss: 1.7078 - learning_rate: 1.0000e-07\n",
      "Epoch 12/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - ae_loss: 1.5020 - kl_loss: 3.1787e-07 - loss: 3.2683 - reconstruction_loss: 1.7663 - val_ae_loss: 1.5376 - val_kl_loss: 3.2596e-08 - val_loss: 3.2436 - val_reconstruction_loss: 1.7059 - learning_rate: 1.0000e-07\n",
      "Epoch 13/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - ae_loss: 1.5132 - kl_loss: 7.8166e-07 - loss: 3.2763 - reconstruction_loss: 1.7631 - val_ae_loss: 1.5376 - val_kl_loss: 3.2596e-08 - val_loss: 3.2438 - val_reconstruction_loss: 1.7062 - learning_rate: 1.0000e-07\n",
      "Epoch 14/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - ae_loss: 1.5058 - kl_loss: 5.8575e-07 - loss: 3.2673 - reconstruction_loss: 1.7615 - val_ae_loss: 1.5376 - val_kl_loss: 3.2596e-08 - val_loss: 3.2430 - val_reconstruction_loss: 1.7054 - learning_rate: 1.0000e-07\n",
      "Epoch 15/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - ae_loss: 1.4934 - kl_loss: 7.7737e-07 - loss: 3.2355 - reconstruction_loss: 1.7421 - val_ae_loss: 1.5376 - val_kl_loss: 3.2363e-08 - val_loss: 3.2429 - val_reconstruction_loss: 1.7053 - learning_rate: 1.0000e-07\n",
      "Epoch 16/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - ae_loss: 1.5119 - kl_loss: 2.2312e-07 - loss: 3.2765 - reconstruction_loss: 1.7647 - val_ae_loss: 1.5376 - val_kl_loss: 3.2829e-08 - val_loss: 3.2429 - val_reconstruction_loss: 1.7053 - learning_rate: 1.0000e-07\n",
      "Epoch 17/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - ae_loss: 1.5468 - kl_loss: 2.7373e-07 - loss: 3.3359 - reconstruction_loss: 1.7891 - val_ae_loss: 1.5376 - val_kl_loss: 3.2829e-08 - val_loss: 3.2436 - val_reconstruction_loss: 1.7059 - learning_rate: 1.0000e-07\n",
      "Epoch 18/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - ae_loss: 1.5264 - kl_loss: 6.2215e-07 - loss: 3.2957 - reconstruction_loss: 1.7693 - val_ae_loss: 1.5376 - val_kl_loss: 3.2829e-08 - val_loss: 3.2438 - val_reconstruction_loss: 1.7061 - learning_rate: 1.0000e-07\n",
      "Epoch 19/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - ae_loss: 1.5156 - kl_loss: 5.2182e-07 - loss: 3.2801 - reconstruction_loss: 1.7645 - val_ae_loss: 1.5376 - val_kl_loss: 3.2829e-08 - val_loss: 3.2434 - val_reconstruction_loss: 1.7058 - learning_rate: 1.0000e-07\n",
      "Epoch 20/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - ae_loss: 1.4968 - kl_loss: 2.0602e-07 - loss: 3.2401 - reconstruction_loss: 1.7433 - val_ae_loss: 1.5376 - val_kl_loss: 3.2596e-08 - val_loss: 3.2427 - val_reconstruction_loss: 1.7051 - learning_rate: 1.0000e-07\n",
      "Epoch 21/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - ae_loss: 1.5160 - kl_loss: 3.5945e-07 - loss: 3.2875 - reconstruction_loss: 1.7714 - val_ae_loss: 1.5376 - val_kl_loss: 3.2596e-08 - val_loss: 3.2454 - val_reconstruction_loss: 1.7077 - learning_rate: 1.0000e-07\n",
      "Epoch 22/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - ae_loss: 1.5040 - kl_loss: 3.4776e-07 - loss: 3.2675 - reconstruction_loss: 1.7635 - val_ae_loss: 1.5376 - val_kl_loss: 3.2596e-08 - val_loss: 3.2455 - val_reconstruction_loss: 1.7078 - learning_rate: 1.0000e-07\n",
      "Epoch 23/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - ae_loss: 1.5127 - kl_loss: 2.5299e-07 - loss: 3.2702 - reconstruction_loss: 1.7574 - val_ae_loss: 1.5376 - val_kl_loss: 3.2596e-08 - val_loss: 3.2461 - val_reconstruction_loss: 1.7085 - learning_rate: 1.0000e-07\n",
      "Epoch 24/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - ae_loss: 1.5203 - kl_loss: 2.6139e-07 - loss: 3.2851 - reconstruction_loss: 1.7648 - val_ae_loss: 1.5376 - val_kl_loss: 3.2596e-08 - val_loss: 3.2444 - val_reconstruction_loss: 1.7067 - learning_rate: 1.0000e-07\n",
      "Epoch 25/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - ae_loss: 1.5275 - kl_loss: 3.9126e-07 - loss: 3.3081 - reconstruction_loss: 1.7806 - val_ae_loss: 1.5376 - val_kl_loss: 3.2131e-08 - val_loss: 3.2439 - val_reconstruction_loss: 1.7063 - learning_rate: 1.0000e-07\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:53:59,515 - INFO - Hybrid Autoencoder-VAE training completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:54:00,265 - INFO - Dynamic threshold: 0.143639 (fallback: 0.161913)\n",
      "2025-03-22 12:54:00,400 - WARNING - You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2025-03-22 12:54:00,450 - WARNING - You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2025-03-22 12:54:00,457 - WARNING - You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2025-03-22 12:54:00,463 - WARNING - You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2025-03-22 12:54:00,475 - INFO - Generating evaluation plots with labeled test data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:54:02,037 - INFO - ROC AUC: 1.0000\n",
      "2025-03-22 12:54:02,038 - INFO - PR AUC: 1.0000\n",
      "2025-03-22 12:54:02,039 - INFO - Layer 1 VAE model training and evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers, backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_curve, roc_auc_score\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "import time\n",
    "import logging\n",
    "import warnings\n",
    "import json\n",
    "\n",
    "# Setup logging and suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger('Layer1_VAE')\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('plots', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('reports', exist_ok=True)\n",
    "\n",
    "class Layer1AutoencoderVAE:\n",
    "    def __init__(self, input_dim, latent_dim=6, learning_rate=1e-4, layer_sizes=None, beta=0.8):\n",
    "        \"\"\"Initialize the hybrid Autoencoder-VAE model with configurable architecture\"\"\"\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.layer_sizes = layer_sizes or [64, 32]\n",
    "        self.beta = beta  # KL weight factor\n",
    "        self.encoder = None\n",
    "        self.decoder = None\n",
    "        self.ae_encoder = None  # Pure autoencoder encoder\n",
    "        self.ae_decoder = None  # Pure autoencoder decoder\n",
    "        self.vae = None\n",
    "        self.kde = None\n",
    "        self.threshold = None\n",
    "        self.fallback_threshold = None\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.build_model()\n",
    "        \n",
    "    def sampling(self, args):\n",
    "        \"\"\"Reparameterization trick for VAE\"\"\"\n",
    "        z_mean, z_log_var = args\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.random.normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "        \n",
    "    def build_model(self):\n",
    "        \"\"\"Build the hybrid Autoencoder-VAE with dual reconstruction paths\"\"\"\n",
    "        # Input layer\n",
    "        encoder_inputs = keras.Input(shape=(self.input_dim,))\n",
    "        \n",
    "        # === PURE AUTOENCODER PATH ===\n",
    "        ae_x = encoder_inputs\n",
    "        \n",
    "        # Encoder layers for pure autoencoder\n",
    "        for i, size in enumerate(self.layer_sizes):\n",
    "            ae_x = layers.Dense(\n",
    "                size, \n",
    "                activation=\"relu\",\n",
    "                kernel_regularizer=regularizers.l2(1e-5),\n",
    "                name=f\"ae_encoder_dense_{i}\"\n",
    "            )(ae_x)\n",
    "            ae_x = layers.BatchNormalization(name=f\"ae_encoder_bn_{i}\")(ae_x)\n",
    "            \n",
    "        # Pure autoencoder bottleneck (non-variational)\n",
    "        ae_bottleneck = layers.Dense(\n",
    "            self.latent_dim,\n",
    "            activation=\"relu\",\n",
    "            name=\"ae_bottleneck\"\n",
    "        )(ae_x)\n",
    "        \n",
    "        # Decoder layers for pure autoencoder\n",
    "        ae_decoded = ae_bottleneck\n",
    "        for i, size in enumerate(reversed(self.layer_sizes)):\n",
    "            ae_decoded = layers.Dense(\n",
    "                size,\n",
    "                activation=\"relu\",\n",
    "                kernel_regularizer=regularizers.l2(1e-5),\n",
    "                name=f\"ae_decoder_dense_{i}\"\n",
    "            )(ae_decoded)\n",
    "            ae_decoded = layers.BatchNormalization(name=f\"ae_decoder_bn_{i}\")(ae_decoded)\n",
    "            \n",
    "        # Output layer for pure autoencoder\n",
    "        ae_outputs = layers.Dense(\n",
    "            self.input_dim, \n",
    "            activation=\"sigmoid\",\n",
    "            name=\"ae_output\"\n",
    "        )(ae_decoded)\n",
    "        \n",
    "        # Create pure autoencoder model\n",
    "        self.ae_encoder = keras.Model(encoder_inputs, ae_bottleneck, name=\"ae_encoder\")\n",
    "        self.ae_decoder = keras.Model(ae_bottleneck, ae_outputs, name=\"ae_decoder\")\n",
    "        \n",
    "        # === VAE PATH ===\n",
    "        vae_x = encoder_inputs\n",
    "        \n",
    "        # Encoder layers for VAE\n",
    "        for i, size in enumerate(self.layer_sizes):\n",
    "            vae_x = layers.Dense(\n",
    "                size, \n",
    "                activation=\"relu\", \n",
    "                kernel_regularizer=regularizers.l2(1e-5),\n",
    "                name=f\"vae_encoder_dense_{i}\"\n",
    "            )(vae_x)\n",
    "            vae_x = layers.BatchNormalization(name=f\"vae_encoder_bn_{i}\")(vae_x)\n",
    "            vae_x = layers.Dropout(0.2, name=f\"vae_encoder_dropout_{i}\")(vae_x)\n",
    "        \n",
    "        # VAE latent space parameters\n",
    "        z_mean = layers.Dense(self.latent_dim, name=\"z_mean\")(vae_x)\n",
    "        z_log_var = layers.Dense(self.latent_dim, name=\"z_log_var\")(vae_x)\n",
    "        \n",
    "        # Sampling layer\n",
    "        z = layers.Lambda(self.sampling, output_shape=(self.latent_dim,), name=\"z\")([z_mean, z_log_var])\n",
    "        \n",
    "        # Instantiate encoder\n",
    "        self.encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "        \n",
    "        # Decoder for VAE\n",
    "        latent_inputs = keras.Input(shape=(self.latent_dim,), name=\"decoder_input\")\n",
    "        vae_decoded = latent_inputs\n",
    "        \n",
    "        for i, size in enumerate(reversed(self.layer_sizes)):\n",
    "            vae_decoded = layers.Dense(\n",
    "                size, \n",
    "                activation=\"relu\", \n",
    "                kernel_regularizer=regularizers.l2(1e-5),\n",
    "                name=f\"vae_decoder_dense_{i}\"\n",
    "            )(vae_decoded)\n",
    "            vae_decoded = layers.BatchNormalization(name=f\"vae_decoder_bn_{i}\")(vae_decoded)\n",
    "            vae_decoded = layers.Dropout(0.2, name=f\"vae_decoder_dropout_{i}\")(vae_decoded)\n",
    "        \n",
    "        # VAE output layer\n",
    "        vae_outputs = layers.Dense(self.input_dim, activation=\"sigmoid\", name=\"vae_output\")(vae_decoded)\n",
    "        \n",
    "        # Instantiate decoder\n",
    "        self.decoder = keras.Model(latent_inputs, vae_outputs, name=\"decoder\")\n",
    "        \n",
    "        # Define full VAE model with custom loss\n",
    "        class VAEModel(keras.Model):\n",
    "            def __init__(self, encoder, decoder, ae_encoder, ae_decoder, beta=0.8, **kwargs):\n",
    "                super(VAEModel, self).__init__(**kwargs)\n",
    "                self.encoder = encoder\n",
    "                self.decoder = decoder\n",
    "                self.ae_encoder = ae_encoder\n",
    "                self.ae_decoder = ae_decoder\n",
    "                self.beta = beta\n",
    "                self.total_loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "                self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "                self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "                self.ae_loss_tracker = keras.metrics.Mean(name=\"ae_loss\")\n",
    "                \n",
    "            def call(self, inputs):\n",
    "                # Get VAE outputs\n",
    "                z_mean, z_log_var, z = self.encoder(inputs)\n",
    "                vae_reconstructed = self.decoder(z)\n",
    "                \n",
    "                # Get pure AE outputs\n",
    "                ae_bottleneck = self.ae_encoder(inputs)\n",
    "                ae_reconstructed = self.ae_decoder(ae_bottleneck)\n",
    "                \n",
    "                # Combine both reconstructions\n",
    "                return ae_reconstructed, vae_reconstructed\n",
    "                \n",
    "            def train_step(self, data):\n",
    "                inputs = data\n",
    "                \n",
    "                with tf.GradientTape() as tape:\n",
    "                    # Encode and decode using both paths\n",
    "                    z_mean, z_log_var, z = self.encoder(inputs)\n",
    "                    vae_reconstructed = self.decoder(z)\n",
    "                    \n",
    "                    ae_bottleneck = self.ae_encoder(inputs)\n",
    "                    ae_reconstructed = self.ae_decoder(ae_bottleneck)\n",
    "                    \n",
    "                    # VAE reconstruction loss - fixed MSE calculation\n",
    "                    vae_reconstruction_loss = tf.reduce_mean(\n",
    "                        tf.reduce_sum(\n",
    "                            tf.square(inputs - vae_reconstructed),\n",
    "                            axis=1\n",
    "                        )\n",
    "                    )\n",
    "                    \n",
    "                    # Pure autoencoder loss - fixed MSE calculation\n",
    "                    ae_loss = tf.reduce_mean(\n",
    "                        tf.reduce_sum(\n",
    "                            tf.square(inputs - ae_reconstructed),\n",
    "                            axis=1\n",
    "                        )\n",
    "                    )\n",
    "                    \n",
    "                    # KL divergence loss\n",
    "                    kl_loss = -0.5 * tf.reduce_mean(\n",
    "                        tf.reduce_sum(\n",
    "                            1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), \n",
    "                            axis=1\n",
    "                        )\n",
    "                    )\n",
    "                    \n",
    "                    # Hybrid loss: AE loss + VAE loss (reconstruction + weighted KL)\n",
    "                    total_loss = ae_loss + vae_reconstruction_loss + self.beta * kl_loss\n",
    "                    \n",
    "                # Compute gradients\n",
    "                grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "                self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "                \n",
    "                # Update metrics\n",
    "                self.total_loss_tracker.update_state(total_loss)\n",
    "                self.reconstruction_loss_tracker.update_state(vae_reconstruction_loss)\n",
    "                self.kl_loss_tracker.update_state(kl_loss)\n",
    "                self.ae_loss_tracker.update_state(ae_loss)\n",
    "                \n",
    "                return {\n",
    "                    \"loss\": self.total_loss_tracker.result(),\n",
    "                    \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "                    \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "                    \"ae_loss\": self.ae_loss_tracker.result()\n",
    "                }\n",
    "                \n",
    "            def test_step(self, data):\n",
    "                inputs = data\n",
    "                \n",
    "                # Encode and decode\n",
    "                z_mean, z_log_var, z = self.encoder(inputs)\n",
    "                vae_reconstructed = self.decoder(z)\n",
    "                \n",
    "                ae_bottleneck = self.ae_encoder(inputs)\n",
    "                ae_reconstructed = self.ae_decoder(ae_bottleneck)\n",
    "                \n",
    "                # VAE reconstruction loss - fixed MSE calculation\n",
    "                vae_reconstruction_loss = tf.reduce_mean(\n",
    "                    tf.reduce_sum(\n",
    "                        tf.square(inputs - vae_reconstructed),\n",
    "                        axis=1\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "                # Pure autoencoder loss - fixed MSE calculation\n",
    "                ae_loss = tf.reduce_mean(\n",
    "                    tf.reduce_sum(\n",
    "                        tf.square(inputs - ae_reconstructed),\n",
    "                        axis=1\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "                # KL divergence loss\n",
    "                kl_loss = -0.5 * tf.reduce_mean(\n",
    "                    tf.reduce_sum(\n",
    "                        1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), \n",
    "                        axis=1\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "                # Total loss\n",
    "                total_loss = ae_loss + vae_reconstruction_loss + self.beta * kl_loss\n",
    "                \n",
    "                # Update metrics\n",
    "                self.total_loss_tracker.update_state(total_loss)\n",
    "                self.reconstruction_loss_tracker.update_state(vae_reconstruction_loss)\n",
    "                self.kl_loss_tracker.update_state(kl_loss)\n",
    "                self.ae_loss_tracker.update_state(ae_loss)\n",
    "                \n",
    "                return {\n",
    "                    \"loss\": self.total_loss_tracker.result(),\n",
    "                    \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "                    \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "                    \"ae_loss\": self.ae_loss_tracker.result()\n",
    "                }\n",
    "        \n",
    "        # Instantiate the VAE model with custom loss\n",
    "        self.vae = VAEModel(\n",
    "            self.encoder, \n",
    "            self.decoder, \n",
    "            self.ae_encoder, \n",
    "            self.ae_decoder, \n",
    "            beta=self.beta,\n",
    "            name=\"hybrid_vae\"\n",
    "        )\n",
    "        \n",
    "        # Compile the model\n",
    "        self.vae.compile(optimizer=keras.optimizers.Adam(learning_rate=self.learning_rate))\n",
    "    \n",
    "    def train(self, X_train, X_val, epochs=100, batch_size=32):\n",
    "        \"\"\"Train the VAE model with early stopping and LR reduction\"\"\"\n",
    "        early_stopping = keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', patience=15, restore_best_weights=True, verbose=1\n",
    "        )\n",
    "        \n",
    "        reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss', factor=0.5, patience=7, min_lr=1e-7, verbose=1\n",
    "        )\n",
    "        \n",
    "        tensorboard_callback = keras.callbacks.TensorBoard(\n",
    "            log_dir=f'./logs/vae_{time.strftime(\"%Y%m%d-%H%M%S\")}',\n",
    "            histogram_freq=1\n",
    "        )\n",
    "        \n",
    "        logger.info(\"Starting hybrid Autoencoder-VAE training...\")\n",
    "        history = self.vae.fit(\n",
    "            X_train, \n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_val, None),\n",
    "            callbacks=[early_stopping, reduce_lr, tensorboard_callback],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        logger.info(\"Hybrid Autoencoder-VAE training completed.\")\n",
    "        self._set_dynamic_threshold(X_train)\n",
    "        return history\n",
    "    \n",
    "    def _set_dynamic_threshold(self, X_data):\n",
    "        \"\"\"Set robust thresholds using KDE with percentile-based fallback\"\"\"\n",
    "        # Get latent representations and reconstructions\n",
    "        ae_bottleneck = self.ae_encoder.predict(X_data)\n",
    "        ae_reconstructed = self.ae_decoder.predict(ae_bottleneck)\n",
    "        \n",
    "        _, _, z = self.encoder.predict(X_data)\n",
    "        vae_reconstructed = self.decoder.predict(z)\n",
    "        \n",
    "        # Compute reconstruction error (weighted combination of AE and VAE)\n",
    "        ae_mse = np.mean(np.square(X_data - ae_reconstructed), axis=1)\n",
    "        vae_mse = np.mean(np.square(X_data - vae_reconstructed), axis=1)\n",
    "        combined_mse = 0.4 * ae_mse + 0.6 * vae_mse  # Weight VAE slightly higher\n",
    "        \n",
    "        # Set multiple percentile-based fallback thresholds\n",
    "        self.fallback_threshold = np.percentile(combined_mse, 99)\n",
    "        conservative_threshold = np.percentile(combined_mse, 97.5)\n",
    "        \n",
    "        try:\n",
    "            # Optimize KDE bandwidth using grid search\n",
    "            param_grid = {'bandwidth': np.logspace(-3, 0, 10)}\n",
    "            grid_search = GridSearchCV(KernelDensity(kernel='gaussian'), param_grid, cv=3)\n",
    "            grid_search.fit(combined_mse.reshape(-1, 1))\n",
    "            \n",
    "            # Use the optimized bandwidth\n",
    "            best_bandwidth = grid_search.best_params_['bandwidth']\n",
    "            self.kde = KernelDensity(kernel='gaussian', bandwidth=best_bandwidth).fit(combined_mse.reshape(-1, 1))\n",
    "            \n",
    "            # Calculate density and anomaly scores\n",
    "            log_dens = self.kde.score_samples(combined_mse.reshape(-1, 1))\n",
    "            scores = -log_dens\n",
    "            \n",
    "            # Find threshold using robust elbow method\n",
    "            sorted_scores = np.sort(scores)\n",
    "            n_samples = len(sorted_scores)\n",
    "            \n",
    "            # Use smoother gradient calculation for more robust elbow detection\n",
    "            if n_samples > 50:\n",
    "                # Calculate gradient\n",
    "                gradient = np.gradient(sorted_scores)\n",
    "                # Calculate second derivative (change in gradient)\n",
    "                grad2 = np.gradient(gradient)\n",
    "                \n",
    "                # Find where second derivative is maximized (the \"elbow\")\n",
    "                elbow_idx = np.argmax(grad2)\n",
    "                kde_threshold = sorted_scores[elbow_idx]\n",
    "                \n",
    "                # Blend KDE threshold with percentile-based threshold for robustness\n",
    "                self.threshold = 0.7 * kde_threshold + 0.3 * self.fallback_threshold\n",
    "                \n",
    "                # Safety check - ensure threshold isn't too aggressive\n",
    "                if self.threshold < conservative_threshold:\n",
    "                    self.threshold = conservative_threshold\n",
    "            else:\n",
    "                # Not enough samples for reliable KDE - use fallback\n",
    "                self.threshold = self.fallback_threshold\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error in KDE threshold calculation: {str(e)}. Using fallback threshold.\")\n",
    "            self.threshold = self.fallback_threshold\n",
    "        \n",
    "        logger.info(f\"Dynamic threshold: {self.threshold:.6f} (fallback: {self.fallback_threshold:.6f})\")\n",
    "        \n",
    "        # Visualize the threshold\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(combined_mse, bins=50, alpha=0.6, color='blue', density=True)\n",
    "        plt.axvline(x=self.threshold, color='red', linestyle='--', \n",
    "                    label=f'Threshold: {self.threshold:.6f}')\n",
    "        plt.axvline(x=self.fallback_threshold, color='green', linestyle=':', \n",
    "                    label=f'Fallback: {self.fallback_threshold:.6f}')\n",
    "        \n",
    "        # Plot KDE curve if available\n",
    "        if self.kde is not None:\n",
    "            x_plot = np.linspace(0, max(combined_mse) * 1.1, 1000).reshape(-1, 1)\n",
    "            log_dens = self.kde.score_samples(x_plot)\n",
    "            plt.plot(x_plot, np.exp(log_dens), '-', color='purple', lw=2, \n",
    "                     label='KDE Estimate')\n",
    "        \n",
    "        plt.title('Anomaly Score Distribution and Thresholds')\n",
    "        plt.xlabel('Reconstruction Error (MSE)')\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend()\n",
    "        plt.savefig('plots/anomaly_threshold.png')\n",
    "        plt.close()\n",
    "    \n",
    "    def detect_anomalies(self, X_data):\n",
    "        \"\"\"Detect anomalies using both AE and VAE reconstruction errors\"\"\"\n",
    "        if self.kde is None or self.threshold is None:\n",
    "            raise ValueError(\"Model hasn't been trained yet. Call train() first.\")\n",
    "        \n",
    "        # Get reconstructions from both models\n",
    "        ae_bottleneck = self.ae_encoder.predict(X_data)\n",
    "        ae_reconstructed = self.ae_decoder.predict(ae_bottleneck)\n",
    "        \n",
    "        _, _, z = self.encoder.predict(X_data)\n",
    "        vae_reconstructed = self.decoder.predict(z)\n",
    "        \n",
    "        # Compute combined reconstruction error\n",
    "        ae_mse = np.mean(np.square(X_data - ae_reconstructed), axis=1)\n",
    "        vae_mse = np.mean(np.square(X_data - vae_reconstructed), axis=1)\n",
    "        combined_mse = 0.4 * ae_mse + 0.6 * vae_mse\n",
    "        \n",
    "        # Use KDE to get anomaly scores if available\n",
    "        if self.kde is not None:\n",
    "            log_dens = self.kde.score_samples(combined_mse.reshape(-1, 1))\n",
    "            anomaly_scores = -log_dens\n",
    "        else:\n",
    "            # Fallback to direct MSE if KDE failed\n",
    "            anomaly_scores = combined_mse\n",
    "        \n",
    "        # Normalize scores to [0,1] range for easier interpretation\n",
    "        min_score = np.min(anomaly_scores)\n",
    "        max_score = np.max(anomaly_scores)\n",
    "        normalized_scores = (anomaly_scores - min_score) / (max_score - min_score) if max_score > min_score else anomaly_scores\n",
    "        \n",
    "        # Identify anomalies\n",
    "        is_anomaly = normalized_scores > self.threshold\n",
    "        anomaly_indices = np.where(is_anomaly)[0]\n",
    "        anomalies = X_data[anomaly_indices]\n",
    "        \n",
    "        # Calculate confidence (how far above threshold)\n",
    "        confidence = np.zeros_like(normalized_scores)\n",
    "        confidence[is_anomaly] = (normalized_scores[is_anomaly] - self.threshold) / (1 - self.threshold)\n",
    "        confidence = np.clip(confidence, 0, 1)\n",
    "        \n",
    "        return anomalies, anomaly_indices, normalized_scores, confidence\n",
    "    \n",
    "    def get_encoded_features(self, X_data):\n",
    "        \"\"\"Extract features from the encoder's latent space\"\"\"\n",
    "        _, _, z = self.encoder.predict(X_data)\n",
    "        return z\n",
    "    \n",
    "    def save_model(self, base_path='models'):\n",
    "        \"\"\"Save the model and artifacts\"\"\"\n",
    "        timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        \n",
    "        # Save VAE components\n",
    "        self.encoder.save(f'{base_path}/layer1_encoder_{timestamp}.h5')\n",
    "        self.decoder.save(f'{base_path}/layer1_decoder_{timestamp}.h5')\n",
    "        \n",
    "        # Save AE components\n",
    "        self.ae_encoder.save(f'{base_path}/layer1_ae_encoder_{timestamp}.h5')\n",
    "        self.ae_decoder.save(f'{base_path}/layer1_ae_decoder_{timestamp}.h5')\n",
    "        \n",
    "        # Create symlinks to latest models\n",
    "        for model_type in ['encoder', 'decoder', 'ae_encoder', 'ae_decoder']:\n",
    "            latest_link = f'{base_path}/layer1_{model_type}.h5'\n",
    "            if os.path.exists(latest_link):\n",
    "                os.remove(latest_link)\n",
    "            os.symlink(f'layer1_{model_type}_{timestamp}.h5', latest_link)\n",
    "        \n",
    "        # Save threshold and metadata\n",
    "        model_config = {\n",
    "            'input_dim': self.input_dim,\n",
    "            'latent_dim': self.latent_dim,\n",
    "            'layer_sizes': self.layer_sizes,\n",
    "            'threshold': float(self.threshold),\n",
    "            'fallback_threshold': float(self.fallback_threshold),\n",
    "            'beta': self.beta,\n",
    "            'timestamp': timestamp\n",
    "        }\n",
    "        \n",
    "        with open(f'{base_path}/layer1_config_{timestamp}.json', 'w') as f:\n",
    "            json.dump(model_config, f, indent=4)\n",
    "        \n",
    "        # Save the KDE model if available\n",
    "        if self.kde is not None:\n",
    "            joblib.dump(self.kde, f'{base_path}/layer1_kde_{timestamp}.pkl')\n",
    "            joblib.dump(self.kde, f'{base_path}/layer1_kde.pkl')\n",
    "        \n",
    "        return timestamp\n",
    "\n",
    "def find_optimal_latent_dim(X_train, X_val, input_dim, min_dim=3, max_dim=12):\n",
    "    \"\"\"Find optimal latent dimension using cross-validation\"\"\"\n",
    "    logger.info(\"Finding optimal latent dimension...\")\n",
    "    \n",
    "    # Define candidate dimensions to test\n",
    "    if input_dim <= 10:\n",
    "        candidate_dims = list(range(min_dim, min(max_dim, input_dim) + 1))\n",
    "    else:\n",
    "        step = 1 if max_dim - min_dim <= 10 else 2\n",
    "        candidate_dims = list(range(min_dim, min(max_dim, input_dim // 2) + 1, step))\n",
    "    \n",
    "    # Remove duplicates and sort\n",
    "    candidate_dims = sorted(list(set(candidate_dims)))\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for latent_dim in candidate_dims:\n",
    "        # Create a smaller model for quick evaluation\n",
    "        model = Layer1AutoencoderVAE(\n",
    "            input_dim=input_dim, \n",
    "            latent_dim=latent_dim,\n",
    "            layer_sizes=[32, 16],  # Smaller network for quick evaluation\n",
    "            learning_rate=1e-3\n",
    "        )\n",
    "        \n",
    "        # Train with fewer epochs for efficiency\n",
    "        history = model.train(\n",
    "            X_train, X_val, \n",
    "            epochs=30, \n",
    "            batch_size=64\n",
    "        )\n",
    "        \n",
    "        # Get the best validation loss\n",
    "        best_val_loss = min(history.history['val_loss'])\n",
    "        logger.info(f\"Latent dim {latent_dim}: validation loss = {best_val_loss:.6f}\")\n",
    "        results.append((latent_dim, best_val_loss))\n",
    "    \n",
    "    # Find dimension with lowest loss\n",
    "    results.sort(key=lambda x: x[1])\n",
    "    best_dim = results[0][0]\n",
    "    \n",
    "    # Visualize dimension search\n",
    "    dims, losses = zip(*results)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(dims, losses, 'o-')\n",
    "    plt.axvline(x=best_dim, color='red', linestyle='--')\n",
    "    plt.title(f'Latent Dimension Optimization (Best: {best_dim})')\n",
    "    plt.xlabel('Latent Dimension')\n",
    "    plt.ylabel('Validation Loss')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('plots/latent_dim_optimization.png')\n",
    "    plt.close()\n",
    "    \n",
    "    logger.info(f\"Optimal latent dimension: {best_dim}\")\n",
    "    return best_dim\n",
    "\n",
    "def generate_evaluation_plots(model, X_normal, X_test=None, y_test=None, save_dir='plots'):\n",
    "    \"\"\"Generate evaluation plots for the model\"\"\"\n",
    "    # Get reconstructions from both AE and VAE models\n",
    "    ae_bottleneck = model.ae_encoder.predict(X_normal)\n",
    "    ae_reconstructed = model.ae_decoder.predict(ae_bottleneck)\n",
    "    \n",
    "    _, _, z_normal = model.encoder.predict(X_normal)\n",
    "    vae_reconstructed = model.decoder.predict(z_normal)\n",
    "    \n",
    "    # Compute combined reconstruction error\n",
    "    ae_mse = np.mean(np.square(X_normal - ae_reconstructed), axis=1)\n",
    "    vae_mse = np.mean(np.square(X_normal - vae_reconstructed), axis=1)\n",
    "    combined_mse = 0.4 * ae_mse + 0.6 * vae_mse\n",
    "    \n",
    "    # Plot reconstruction error distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(combined_mse, kde=True, color='blue', label='Normal')\n",
    "    \n",
    "    # If test data with labels is available\n",
    "    if X_test is not None and y_test is not None:\n",
    "        ae_bottleneck_test = model.ae_encoder.predict(X_test)\n",
    "        ae_reconstructed_test = model.ae_decoder.predict(ae_bottleneck_test)\n",
    "        \n",
    "        _, _, z_test = model.encoder.predict(X_test)\n",
    "        vae_reconstructed_test = model.decoder.predict(z_test)\n",
    "        \n",
    "        # Compute combined reconstruction error for test set\n",
    "        ae_mse_test = np.mean(np.square(X_test - ae_reconstructed_test), axis=1)\n",
    "        vae_mse_test = np.mean(np.square(X_test - vae_reconstructed_test), axis=1)\n",
    "        combined_mse_test = 0.4 * ae_mse_test + 0.6 * vae_mse_test\n",
    "        \n",
    "        # Separate normal and anomaly in test set\n",
    "        if np.sum(y_test) > 0:  # If we have anomalies\n",
    "            anomaly_mse = combined_mse_test[y_test == 1]\n",
    "            sns.histplot(anomaly_mse, kde=True, color='red', alpha=0.6, label='Anomaly')\n",
    "    \n",
    "    plt.axvline(x=model.threshold, color='green', linestyle='--', \n",
    "                label=f'Threshold: {model.threshold:.6f}')\n",
    "    plt.title('Reconstruction Error Distribution')\n",
    "    plt.xlabel('Mean Squared Error')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{save_dir}/reconstruction_error_dist.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # If test data with labels is available, generate ROC and PR curves\n",
    "    if X_test is not None and y_test is not None and np.sum(y_test) > 0:\n",
    "        # Get anomaly scores for test data\n",
    "        _, _, anomaly_scores, _ = model.detect_anomalies(X_test)\n",
    "        \n",
    "        # ROC curve\n",
    "        fpr, tpr, _ = roc_curve(y_test, anomaly_scores)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig(f'{save_dir}/roc_curve.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Precision-Recall curve\n",
    "        precision, recall, _ = precision_recall_curve(y_test, anomaly_scores)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(recall, precision, color='blue', lw=2, label=f'PR curve (area = {pr_auc:.2f})')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curve')\n",
    "        plt.legend(loc=\"lower left\")\n",
    "        plt.savefig(f'{save_dir}/pr_curve.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Latent space visualization (2D projection if latent_dim > 2)\n",
    "        _, _, z = model.encoder.predict(X_test)\n",
    "        \n",
    "        if model.latent_dim >= 2:\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            if np.sum(y_test == 0) > 0:\n",
    "                plt.scatter(z[y_test == 0, 0], z[y_test == 0, 1], c='blue', alpha=0.5, label='Normal')\n",
    "            if np.sum(y_test == 1) > 0:\n",
    "                plt.scatter(z[y_test == 1, 0], z[y_test == 1, 1], c='red', alpha=0.5, label='Anomaly')\n",
    "            plt.title('Latent Space Visualization (First 2 Dimensions)')\n",
    "            plt.xlabel('Latent Dim 1')\n",
    "            plt.ylabel('Latent Dim 2')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(f'{save_dir}/latent_space.png')\n",
    "            plt.close()\n",
    "\n",
    "            # If latent dimension > 2, create a 3D plot as well\n",
    "            if model.latent_dim >= 3:\n",
    "                fig = plt.figure(figsize=(12, 10))\n",
    "                ax = fig.add_subplot(111, projection='3d')\n",
    "                if np.sum(y_test == 0) > 0:\n",
    "                    ax.scatter(z[y_test == 0, 0], z[y_test == 0, 1], z[y_test == 0, 2], \n",
    "                            c='blue', alpha=0.5, label='Normal')\n",
    "                if np.sum(y_test == 1) > 0:\n",
    "                    ax.scatter(z[y_test == 1, 0], z[y_test == 1, 1], z[y_test == 1, 2], \n",
    "                            c='red', alpha=0.5, label='Anomaly')\n",
    "                ax.set_title('Latent Space Visualization (First 3 Dimensions)')\n",
    "                ax.set_xlabel('Latent Dim 1')\n",
    "                ax.set_ylabel('Latent Dim 2')\n",
    "                ax.set_zlabel('Latent Dim 3')\n",
    "                ax.legend()\n",
    "                plt.savefig(f'{save_dir}/latent_space_3d.png')\n",
    "                plt.close()\n",
    "        \n",
    "                # Return metrics for reporting\n",
    "                return {\n",
    "                    'roc_auc': roc_auc,\n",
    "                    'pr_auc': pr_auc\n",
    "                }\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    # Load and prepare data \n",
    "    logger.info(\"Loading and preparing data...\")\n",
    "    \n",
    "    # TODO: Replace with your actual data loading logic\n",
    "    try:\n",
    "        df = pd.read_csv('your_dataset.csv')\n",
    "        features = df.drop(['label', 'id'], axis=1, errors='ignore')\n",
    "        \n",
    "        # If labels are available\n",
    "        if 'label' in df.columns:\n",
    "            labels = df['label'].values\n",
    "            normal_data = features[labels == 0].values\n",
    "            anomaly_data = features[labels == 1].values if np.sum(labels == 1) > 0 else None\n",
    "        else:\n",
    "            # Assume all training data is normal for unsupervised learning\n",
    "            normal_data = features.values\n",
    "            anomaly_data = None\n",
    "            labels = None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading data: {str(e)}\")\n",
    "        logger.info(\"Using synthetic data for demonstration...\")\n",
    "        \n",
    "        # Generate synthetic data for demonstration\n",
    "        n_features = 20\n",
    "        n_normal = 1000\n",
    "        n_anomalies = 50\n",
    "        \n",
    "        # Generate normal samples with a specific distribution\n",
    "        normal_data = np.random.normal(0, 1, size=(n_normal, n_features))\n",
    "        \n",
    "        # Generate anomalies with a different distribution\n",
    "        anomaly_data = np.random.normal(3, 2, size=(n_anomalies, n_features))\n",
    "        \n",
    "        # Create labels\n",
    "        labels = np.zeros(n_normal + n_anomalies)\n",
    "        labels[n_normal:] = 1\n",
    "        \n",
    "        # Combine data\n",
    "        all_data = np.vstack([normal_data, anomaly_data])\n",
    "    \n",
    "    # Scale data\n",
    "    scaler = MaxAbsScaler()\n",
    "    if anomaly_data is not None and labels is not None:\n",
    "        # Scale using only normal data to avoid anomaly influence\n",
    "        normal_data_scaled = scaler.fit_transform(normal_data)\n",
    "        all_data_scaled = scaler.transform(all_data)\n",
    "    else:\n",
    "        normal_data_scaled = scaler.fit_transform(normal_data)\n",
    "        all_data_scaled = normal_data_scaled\n",
    "        \n",
    "    # Split normal data for training and validation\n",
    "    X_train, X_val = train_test_split(normal_data_scaled, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Get dimensions\n",
    "    input_dim = X_train.shape[1]\n",
    "    \n",
    "    # Find optimal latent dimension\n",
    "    optimal_dim = find_optimal_latent_dim(X_train, X_val, input_dim)\n",
    "    \n",
    "    # Find optimal layer sizes based on input dimension\n",
    "    if input_dim <= 10:\n",
    "        layer_sizes = [32, 16]\n",
    "    elif input_dim <= 50:\n",
    "        layer_sizes = [64, 32, 16]\n",
    "    else:\n",
    "        layer_sizes = [128, 64, 32]\n",
    "    \n",
    "    # Create and train the model with optimal parameters\n",
    "    logger.info(f\"Creating model with latent_dim={optimal_dim}, layers={layer_sizes}\")\n",
    "    model = Layer1AutoencoderVAE(\n",
    "        input_dim=input_dim,\n",
    "        latent_dim=optimal_dim,\n",
    "        layer_sizes=layer_sizes,\n",
    "        beta=0.8  # KL weight factor\n",
    "    )\n",
    "    \n",
    "    # Perform cross-validation to ensure robust performance\n",
    "    n_splits = 5\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Initialize metrics tracking\n",
    "    val_losses = []\n",
    "    train_times = []\n",
    "    \n",
    "    # Main training with cross-validation\n",
    "    logger.info(f\"Starting {n_splits}-fold cross-validation...\")\n",
    "    \n",
    "    fold = 1\n",
    "    for train_idx, val_idx in kf.split(normal_data_scaled):\n",
    "        logger.info(f\"Training fold {fold}/{n_splits}\")\n",
    "        X_train_fold, X_val_fold = normal_data_scaled[train_idx], normal_data_scaled[val_idx]\n",
    "        \n",
    "        # Track training time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Train the model\n",
    "        history = model.train(\n",
    "            X_train_fold, \n",
    "            X_val_fold,\n",
    "            epochs=150,\n",
    "            batch_size=32\n",
    "        )\n",
    "        \n",
    "        # Record metrics\n",
    "        train_time = time.time() - start_time\n",
    "        best_val_loss = min(history.history['val_loss'])\n",
    "        \n",
    "        train_times.append(train_time)\n",
    "        val_losses.append(best_val_loss)\n",
    "        \n",
    "        logger.info(f\"Fold {fold} - Training time: {train_time:.2f}s, Best val loss: {best_val_loss:.6f}\")\n",
    "        fold += 1\n",
    "        \n",
    "        # Only do one fold for quick testing if needed\n",
    "        # break  # Uncomment to only do one fold\n",
    "    \n",
    "    # Average metrics\n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "    avg_train_time = np.mean(train_times)\n",
    "    \n",
    "    logger.info(f\"Cross-validation complete - Avg val loss: {avg_val_loss:.6f}, Avg train time: {avg_train_time:.2f}s\")\n",
    "    \n",
    "    # Final training on all normal data\n",
    "    logger.info(\"Training final model on all normal data...\")\n",
    "    history = model.train(\n",
    "        normal_data_scaled,\n",
    "        normal_data_scaled[:100],  # Small validation set for early stopping\n",
    "        epochs=200,\n",
    "        batch_size=32\n",
    "    )\n",
    "    \n",
    "    # Save the model\n",
    "    timestamp = model.save_model()\n",
    "    \n",
    "    # Generate evaluation plots\n",
    "    if anomaly_data is not None and labels is not None:\n",
    "        logger.info(\"Generating evaluation plots with labeled test data...\")\n",
    "        metrics = generate_evaluation_plots(model, normal_data_scaled, all_data_scaled, labels)\n",
    "        \n",
    "        # Log performance metrics\n",
    "        logger.info(f\"ROC AUC: {metrics['roc_auc']:.4f}\")\n",
    "        logger.info(f\"PR AUC: {metrics['pr_auc']:.4f}\")\n",
    "        \n",
    "        # Save metrics to report\n",
    "        with open(f'reports/layer1_metrics_{timestamp}.json', 'w') as f:\n",
    "            json.dump({\n",
    "                'roc_auc': float(metrics['roc_auc']),\n",
    "                'pr_auc': float(metrics['pr_auc']),\n",
    "                'avg_val_loss': float(avg_val_loss),\n",
    "                'avg_train_time': float(avg_train_time),\n",
    "                'input_dim': int(input_dim),\n",
    "                'latent_dim': int(optimal_dim),\n",
    "                'layer_sizes': layer_sizes,\n",
    "                'timestamp': timestamp\n",
    "            }, f, indent=4)\n",
    "    else:\n",
    "        logger.info(\"Generating basic evaluation plots...\")\n",
    "        generate_evaluation_plots(model, normal_data_scaled)\n",
    "    \n",
    "    logger.info(\"Layer 1 VAE model training and evaluation complete.\")\n",
    "    return model, timestamp\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
