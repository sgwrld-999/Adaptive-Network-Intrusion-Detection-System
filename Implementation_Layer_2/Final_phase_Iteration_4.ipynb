{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with batch size 128 for 10 epochs\n",
      "Epoch 1/10\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 409ms/step - loss: 118.6026 - mae: 0.2278 - mean_squared_error: 116.3000 - val_loss: 180.0980 - val_mae: 0.2581 - val_mean_squared_error: 179.0955 - learning_rate: 3.5496e-05\n",
      "Epoch 2/10\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 260ms/step - loss: 121.1806 - mae: 0.2300 - mean_squared_error: 119.1702 - val_loss: 179.8746 - val_mae: 0.2497 - val_mean_squared_error: 179.0970 - learning_rate: 7.0965e-05\n",
      "Epoch 3/10\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 504ms/step - loss: 128.6690 - mae: 0.2337 - mean_squared_error: 127.1184 - val_loss: 179.7724 - val_mae: 0.2535 - val_mean_squared_error: 179.0967 - learning_rate: 1.0638e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 253ms/step - loss: 142.1304 - mae: 0.2543 - mean_squared_error: 140.9023 - val_loss: 179.7479 - val_mae: 0.2608 - val_mean_squared_error: 179.0896 - learning_rate: 1.4172e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 232ms/step - loss: 141.4560 - mae: 0.2564 - mean_squared_error: 140.4354 - val_loss: 179.6455 - val_mae: 0.2673 - val_mean_squared_error: 179.0839 - learning_rate: 1.7695e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 219ms/step - loss: 115.2487 - mae: 0.2456 - mean_squared_error: 114.4019 - val_loss: 179.4825 - val_mae: 0.2734 - val_mean_squared_error: 179.0787 - learning_rate: 2.1205e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 234ms/step - loss: 146.4109 - mae: 0.2808 - mean_squared_error: 145.7055 - val_loss: 179.3844 - val_mae: 0.2828 - val_mean_squared_error: 179.0684 - learning_rate: 2.4699e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 231ms/step - loss: 122.5586 - mae: 0.2782 - mean_squared_error: 121.9801 - val_loss: 179.3391 - val_mae: 0.3009 - val_mean_squared_error: 179.0531 - learning_rate: 2.8175e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 232ms/step - loss: 121.0803 - mae: 0.2942 - mean_squared_error: 120.6099 - val_loss: 179.3096 - val_mae: 0.2967 - val_mean_squared_error: 179.0356 - learning_rate: 3.1630e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 222ms/step - loss: 142.7295 - mae: 0.3216 - mean_squared_error: 142.3356 - val_loss: 179.2871 - val_mae: 0.2966 - val_mean_squared_error: 179.0193 - learning_rate: 3.5061e-04\n",
      "\n",
      "Training with batch size 64 for 10 epochs\n",
      "Epoch 11/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 140ms/step - loss: 145.0527 - mae: 0.3139 - mean_squared_error: 144.7566 - val_loss: 179.2280 - val_mae: 0.3096 - val_mean_squared_error: 178.9779 - learning_rate: 4.1842e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 148ms/step - loss: 94.8761 - mae: 0.2688 - mean_squared_error: 94.6051 - val_loss: 179.1585 - val_mae: 0.3047 - val_mean_squared_error: 178.9181 - learning_rate: 4.8499e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 142ms/step - loss: 124.3683 - mae: 0.2978 - mean_squared_error: 124.1157 - val_loss: 179.0896 - val_mae: 0.3107 - val_mean_squared_error: 178.8609 - learning_rate: 4.9977e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 145ms/step - loss: 119.7564 - mae: 0.2933 - mean_squared_error: 119.5212 - val_loss: 179.0242 - val_mae: 0.3144 - val_mean_squared_error: 178.8092 - learning_rate: 4.9905e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 143ms/step - loss: 130.9648 - mae: 0.3050 - mean_squared_error: 130.7466 - val_loss: 178.9754 - val_mae: 0.3103 - val_mean_squared_error: 178.7771 - learning_rate: 4.9783e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 138ms/step - loss: 120.1736 - mae: 0.2922 - mean_squared_error: 119.9728 - val_loss: 178.9305 - val_mae: 0.3076 - val_mean_squared_error: 178.7453 - learning_rate: 4.9612e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 139ms/step - loss: 113.1682 - mae: 0.2726 - mean_squared_error: 112.9828 - val_loss: 178.8944 - val_mae: 0.3048 - val_mean_squared_error: 178.7228 - learning_rate: 4.9392e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 138ms/step - loss: 131.3992 - mae: 0.2889 - mean_squared_error: 131.2284 - val_loss: 178.8699 - val_mae: 0.2994 - val_mean_squared_error: 178.7130 - learning_rate: 4.9123e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 137ms/step - loss: 120.8843 - mae: 0.2818 - mean_squared_error: 120.7263 - val_loss: 178.8304 - val_mae: 0.3019 - val_mean_squared_error: 178.6837 - learning_rate: 4.8807e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 139ms/step - loss: 113.7386 - mae: 0.2801 - mean_squared_error: 113.5927 - val_loss: 178.8069 - val_mae: 0.2996 - val_mean_squared_error: 178.6733 - learning_rate: 4.8443e-04\n",
      "\n",
      "Training with batch size 32 for 10 epochs\n",
      "Epoch 21/30\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - loss: 109.1955 - mae: 0.2792 - mean_squared_error: 109.0670 - val_loss: 178.7584 - val_mae: 0.2979 - val_mean_squared_error: 178.6437 - learning_rate: 4.7579e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 95ms/step - loss: 137.8236 - mae: 0.3083 - mean_squared_error: 137.7122 - val_loss: 178.7064 - val_mae: 0.2984 - val_mean_squared_error: 178.6089 - learning_rate: 4.6538e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 94ms/step - loss: 118.9027 - mae: 0.3058 - mean_squared_error: 118.8056 - val_loss: 178.6659 - val_mae: 0.3039 - val_mean_squared_error: 178.5805 - learning_rate: 4.5327e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 97ms/step - loss: 100.7557 - mae: 0.2893 - mean_squared_error: 100.6698 - val_loss: 178.6067 - val_mae: 0.3102 - val_mean_squared_error: 178.5296 - learning_rate: 4.3955e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 101ms/step - loss: 113.8985 - mae: 0.2917 - mean_squared_error: 113.8218 - val_loss: 178.5790 - val_mae: 0.3234 - val_mean_squared_error: 178.5091 - learning_rate: 4.2434e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 99ms/step - loss: 135.0030 - mae: 0.3151 - mean_squared_error: 134.9335 - val_loss: 178.5293 - val_mae: 0.3223 - val_mean_squared_error: 178.4662 - learning_rate: 4.0775e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - loss: 113.9156 - mae: 0.3056 - mean_squared_error: 113.8523 - val_loss: 178.5225 - val_mae: 0.3282 - val_mean_squared_error: 178.4632 - learning_rate: 3.8992e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - loss: 111.6323 - mae: 0.3055 - mean_squared_error: 111.5729 - val_loss: 178.4920 - val_mae: 0.3381 - val_mean_squared_error: 178.4371 - learning_rate: 3.7098e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 100ms/step - loss: 104.3715 - mae: 0.2961 - mean_squared_error: 104.3156 - val_loss: 178.4907 - val_mae: 0.3319 - val_mean_squared_error: 178.4372 - learning_rate: 3.5109e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 97ms/step - loss: 122.5032 - mae: 0.3237 - mean_squared_error: 122.4482 - val_loss: 178.4703 - val_mae: 0.3445 - val_mean_squared_error: 178.4154 - learning_rate: 3.3041e-04\n",
      "\n",
      "Training with batch size 32 for 10 epochs\n",
      "Epoch 31/40\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 104ms/step - loss: 124.5595 - mae: 0.3262 - mean_squared_error: 124.5062 - val_loss: 178.4343 - val_mae: 0.3408 - val_mean_squared_error: 178.3837 - learning_rate: 3.0909e-04\n",
      "Epoch 32/40\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 100ms/step - loss: 143.2311 - mae: 0.3404 - mean_squared_error: 143.1800 - val_loss: 178.4097 - val_mae: 0.3467 - val_mean_squared_error: 178.3615 - learning_rate: 2.8730e-04\n",
      "Epoch 33/40\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 104ms/step - loss: 139.9073 - mae: 0.3447 - mean_squared_error: 139.8575 - val_loss: 178.3974 - val_mae: 0.3429 - val_mean_squared_error: 178.3508 - learning_rate: 2.6523e-04\n",
      "Epoch 34/40\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 111ms/step - loss: 121.9028 - mae: 0.3272 - mean_squared_error: 121.8547 - val_loss: 178.3810 - val_mae: 0.3505 - val_mean_squared_error: 178.3349 - learning_rate: 2.4303e-04\n",
      "Epoch 35/40\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 102ms/step - loss: 100.6908 - mae: 0.3028 - mean_squared_error: 100.6437 - val_loss: 178.3587 - val_mae: 0.3622 - val_mean_squared_error: 178.3120 - learning_rate: 2.2090e-04\n",
      "Epoch 36/40\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 102ms/step - loss: 117.9002 - mae: 0.3276 - mean_squared_error: 117.8516 - val_loss: 178.3569 - val_mae: 0.3509 - val_mean_squared_error: 178.3129 - learning_rate: 1.9899e-04\n",
      "Epoch 37/40\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 104ms/step - loss: 130.2043 - mae: 0.3386 - mean_squared_error: 130.1583 - val_loss: 178.3351 - val_mae: 0.3551 - val_mean_squared_error: 178.2910 - learning_rate: 1.7749e-04\n",
      "Epoch 38/40\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 111ms/step - loss: 117.1913 - mae: 0.3223 - mean_squared_error: 117.1466 - val_loss: 178.3195 - val_mae: 0.3520 - val_mean_squared_error: 178.2753 - learning_rate: 1.5656e-04\n",
      "Epoch 39/40\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 107ms/step - loss: 115.2041 - mae: 0.3294 - mean_squared_error: 115.1593 - val_loss: 178.2950 - val_mae: 0.3531 - val_mean_squared_error: 178.2499 - learning_rate: 1.3638e-04\n",
      "Epoch 40/40\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 102ms/step - loss: 122.9104 - mae: 0.3349 - mean_squared_error: 122.8651 - val_loss: 178.2949 - val_mae: 0.3565 - val_mean_squared_error: 178.2518 - learning_rate: 1.1709e-04\n",
      "\n",
      "Training with batch size 32 for 10 epochs\n",
      "Epoch 41/50\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 103ms/step - loss: 119.4343 - mae: 0.3268 - mean_squared_error: 119.3892 - val_loss: 178.2935 - val_mae: 0.3486 - val_mean_squared_error: 178.2507 - learning_rate: 9.8856e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 101ms/step - loss: 129.1473 - mae: 0.3407 - mean_squared_error: 129.1033 - val_loss: 178.3027 - val_mae: 0.3621 - val_mean_squared_error: 178.2600 - learning_rate: 8.1817e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 118ms/step - loss: 125.1585 - mae: 0.3297 - mean_squared_error: 125.1154 - val_loss: 178.2778 - val_mae: 0.3521 - val_mean_squared_error: 178.2350 - learning_rate: 6.6109e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 117ms/step - loss: 138.1858 - mae: 0.3484 - mean_squared_error: 138.1418 - val_loss: 178.2782 - val_mae: 0.3549 - val_mean_squared_error: 178.2355 - learning_rate: 5.1856e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 118ms/step - loss: 137.9501 - mae: 0.3418 - mean_squared_error: 137.9066 - val_loss: 178.2713 - val_mae: 0.3538 - val_mean_squared_error: 178.2290 - learning_rate: 3.9169e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 105ms/step - loss: 132.9235 - mae: 0.3332 - mean_squared_error: 132.8804 - val_loss: 178.2709 - val_mae: 0.3564 - val_mean_squared_error: 178.2285 - learning_rate: 2.8150e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 99ms/step - loss: 123.9006 - mae: 0.3271 - mean_squared_error: 123.8574 - val_loss: 178.2712 - val_mae: 0.3568 - val_mean_squared_error: 178.2292 - learning_rate: 1.8886e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 106ms/step - loss: 139.2113 - mae: 0.3437 - mean_squared_error: 139.1682 - val_loss: 178.2664 - val_mae: 0.3555 - val_mean_squared_error: 178.2243 - learning_rate: 1.1449e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 106ms/step - loss: 132.0594 - mae: 0.3342 - mean_squared_error: 132.0166 - val_loss: 178.2670 - val_mae: 0.3558 - val_mean_squared_error: 178.2249 - learning_rate: 5.8980e-06\n",
      "Epoch 50/50\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 100ms/step - loss: 123.5533 - mae: 0.3339 - mean_squared_error: 123.5102 - val_loss: 178.2674 - val_mae: 0.3558 - val_mean_squared_error: 178.2253 - learning_rate: 2.2776e-06\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step\n",
      "\n",
      " Reconstruction Error Analysis:\n",
      "Mean Error: 178.22\n",
      "Median Error: 0.07\n",
      "Error Standard Deviation: 1460.18\n",
      "50th Percentile: 0.07\n",
      "75th Percentile: 0.14\n",
      "90th Percentile: 0.47\n",
      "95th Percentile: 7.82\n",
      "99th Percentile: 13432.09\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculated Anomaly Threshold: 929.8265528451568\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step\n",
      "\n",
      "Anomaly Detection Summary:\n",
      "Total Samples: 9056\n",
      "Detected Anomalies: 151 (1.67%)\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step\n",
      "\n",
      "Anomaly Detection Summary:\n",
      "Total Samples: 9056\n",
      "Detected Anomalies: 151 (1.67%)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No such layer: gap_layer. Existing layers are: ['input_layer', 'batch_normalization', 'reshape', 'conv1d', 'batch_normalization_1', 'spatial_dropout1d', 'conv1d_1', 'batch_normalization_2', 'conv1d_2', 'add', 'conv1d_3', 'batch_normalization_3', 'spatial_dropout1d_1', 'conv1d_4', 'batch_normalization_4', 'conv1d_5', 'add_1', 'attention', 'add_2', 'global_average_pooling1d', 'dense', 'layer_normalization', 'dropout', 'dense_1', 'repeat_vector', 'dense_2', 'lstm', 'repeat_vector_1', 'multiply', 'time_distributed', 'flatten'].",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 787\u001b[39m\n\u001b[32m    784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 641\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    637\u001b[39m X_anomalies = X_train[anomaly_detector.detect_anomalies(X_train, threshold)]\n\u001b[32m    638\u001b[39m y_anomalies = y_train[anomaly_detector.detect_anomalies(X_train, threshold)]\n\u001b[32m    639\u001b[39m feature_extractor = keras.Model(\n\u001b[32m    640\u001b[39m     inputs=anomaly_detector.model.input, \n\u001b[32m--> \u001b[39m\u001b[32m641\u001b[39m     outputs=\u001b[43manomaly_detector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgap_layer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.output\n\u001b[32m    642\u001b[39m )\n\u001b[32m    643\u001b[39m X_features = feature_extractor.predict(X_anomalies)\n\u001b[32m    644\u001b[39m X_pca, pca = apply_pca(X_features)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/models/model.py:210\u001b[39m, in \u001b[36mModel.get_layer\u001b[39m\u001b[34m(self, name, index)\u001b[39m\n\u001b[32m    208\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m layer.name == name:\n\u001b[32m    209\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m layer\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    211\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo such layer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Existing layers are: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    212\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(layer.name\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mlayer\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m.layers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    213\u001b[39m     )\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    215\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mProvide either a layer name or layer index at `get_layer`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    216\u001b[39m )\n",
      "\u001b[31mValueError\u001b[39m: No such layer: gap_layer. Existing layers are: ['input_layer', 'batch_normalization', 'reshape', 'conv1d', 'batch_normalization_1', 'spatial_dropout1d', 'conv1d_1', 'batch_normalization_2', 'conv1d_2', 'add', 'conv1d_3', 'batch_normalization_3', 'spatial_dropout1d_1', 'conv1d_4', 'batch_normalization_4', 'conv1d_5', 'add_1', 'attention', 'add_2', 'global_average_pooling1d', 'dense', 'layer_normalization', 'dropout', 'dense_1', 'repeat_vector', 'dense_2', 'lstm', 'repeat_vector_1', 'multiply', 'time_distributed', 'flatten']."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import ADASYN\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tensorflow.keras import mixed_precision  # Correct import\n",
    "from tensorflow.keras import backend as K\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "from concurrent import futures\n",
    "import os\n",
    "\n",
    "# Set the global policy to mixed precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "# Rest of your code...\n",
    "def mish(x):\n",
    "    return x * tf.math.tanh(tf.math.softplus(x))\n",
    "\n",
    "tf.keras.utils.get_custom_objects().update({'mish': tf.keras.layers.Activation(mish)})\n",
    "\n",
    "def preprocess_data(file_path, test_size=0.2, val_size=0.25, random_state=42):\n",
    "    df = pd.read_csv(file_path)\n",
    "    y = df['Attack_label']\n",
    "    X = df.drop(['Attack_label'], axis=1)\n",
    "    non_numeric_columns = X.select_dtypes(exclude=[np.number]).columns\n",
    "    for col in non_numeric_columns:\n",
    "        try:\n",
    "            X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "        except:\n",
    "            X = X.drop(columns=[col])\n",
    "    X = X.drop(columns=non_numeric_columns)\n",
    "    X = X.fillna(X.mean())\n",
    "    Q1, Q3 = X.quantile(0.25), X.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    mask = ~((X < (Q1 - 3 * IQR)) | (X > (Q3 + 3 * IQR))).any(axis=1)\n",
    "    X, y = X[mask], y[mask]\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=val_size, \n",
    "        random_state=random_state, stratify=y_train_val)\n",
    "    \n",
    "    def apply_preprocessing(X_data):\n",
    "        log_features = np.log1p(np.abs(X_data))\n",
    "        log_features.columns = [f'log_{col}' for col in X_data.columns]\n",
    "        X_data = pd.concat([X_data, log_features], axis=1)\n",
    "        X_data['interaction_features'] = X_data.iloc[:, :5].mul(X_data.iloc[:, 5:10]).sum(axis=1)\n",
    "        percentile_rank = X_data.rank(pct=True)\n",
    "        percentile_rank.columns = [f'percentile_rank_{col}' for col in X_data.columns]\n",
    "        X_data = pd.concat([X_data, percentile_rank], axis=1)\n",
    "        X_data['mean'] = X_data.mean(axis=1)\n",
    "        X_data['std'] = X_data.std(axis=1)\n",
    "        X_data['skew'] = X_data.skew(axis=1)\n",
    "        X_data['kurt'] = X_data.kurtosis(axis=1)\n",
    "        from scipy.stats import mstats\n",
    "        for col in X_data.columns:\n",
    "            X_data[col] = mstats.winsorize(X_data[col], limits=[0.01, 0.01])\n",
    "        return X_data\n",
    "    \n",
    "    X_train = apply_preprocessing(X_train)\n",
    "    X_val = apply_preprocessing(X_val)\n",
    "    X_test = apply_preprocessing(X_test)\n",
    "    \n",
    "    scaler = RobustScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    joblib.dump(scaler, 'robust_scaler.pkl')\n",
    "    \n",
    "    return X_train_scaled, X_val_scaled, X_test_scaled, y_train, y_val, y_test\n",
    "\n",
    "class EnhancedAdaptiveNIDS:\n",
    "    def __init__(self, input_dim, latent_dim=16, learning_rate=5e-4):\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        tf.keras.backend.clear_session()\n",
    "        self.model = self._build_enhanced_autoencoder()\n",
    "        \n",
    "    def _build_enhanced_autoencoder(self):\n",
    "        inputs = layers.Input(shape=(self.input_dim,))\n",
    "        x = layers.BatchNormalization()(inputs)\n",
    "        x = layers.Reshape((-1, 1))(x)\n",
    "        x = self._residual_conv_block(x, filters=16, kernel_size=3)\n",
    "        x = self._residual_conv_block(x, filters=32, kernel_size=3)\n",
    "        x = self._self_attention_block(x)\n",
    "        x = layers.GlobalAveragePooling1D()(x)\n",
    "        x = layers.Dense(64, activation='mish', \n",
    "                        kernel_regularizer=regularizers.l1_l2(l1=0.0005, l2=0.00075))(x)\n",
    "        x = layers.LayerNormalization()(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        encoded = layers.Dense(\n",
    "            self.latent_dim, \n",
    "            activation='linear',\n",
    "            kernel_regularizer=regularizers.l1(0.0005),\n",
    "            activity_regularizer=regularizers.l2(0.0005)\n",
    "        )(x)\n",
    "        x = layers.RepeatVector(self.input_dim)(encoded)\n",
    "        x = layers.LSTM(\n",
    "            units=self.latent_dim * 2,  \n",
    "            return_sequences=True,\n",
    "            recurrent_dropout=0.25\n",
    "        )(x)\n",
    "        x = self._attention_decoder(x, encoded)\n",
    "        decoded = layers.TimeDistributed(\n",
    "            layers.Dense(1, activation='linear')\n",
    "        )(x)\n",
    "        decoded = layers.Flatten()(decoded)\n",
    "        \n",
    "        autoencoder = keras.Model(inputs=inputs, outputs=decoded)\n",
    "        lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "            initial_learning_rate=self.learning_rate,\n",
    "            decay_steps=10000,\n",
    "            alpha=0.001\n",
    "        )\n",
    "        warmup_steps = 1000\n",
    "        lr_schedule = self._warmup_schedule(lr_schedule, warmup_steps)\n",
    "        autoencoder.compile(\n",
    "            optimizer=keras.optimizers.Adam(\n",
    "                learning_rate=lr_schedule, \n",
    "                clipnorm=1.0\n",
    "            ),\n",
    "            loss='mean_squared_error',\n",
    "            metrics=['mae', keras.metrics.MeanSquaredError()]\n",
    "        )\n",
    "        return autoencoder\n",
    "    \n",
    "    def _residual_conv_block(self, x, filters, kernel_size):\n",
    "        shortcut = x\n",
    "        x = layers.Conv1D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            activation='mish',\n",
    "            padding='same',\n",
    "            kernel_regularizer=regularizers.l2(0.00075)\n",
    "        )(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.SpatialDropout1D(0.2)(x)\n",
    "        x = layers.Conv1D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            activation='mish',\n",
    "            padding='same',\n",
    "            kernel_regularizer=regularizers.l2(0.00075)\n",
    "        )(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        if K.int_shape(shortcut)[-1] != K.int_shape(x)[-1]:\n",
    "            shortcut = layers.Conv1D(\n",
    "                filters=filters,\n",
    "                kernel_size=1,\n",
    "                activation='mish',\n",
    "                padding='same'\n",
    "            )(shortcut)\n",
    "        x = layers.Add()([x, shortcut])\n",
    "        return x\n",
    "    \n",
    "    def _self_attention_block(self, x):\n",
    "        attention = layers.Attention()([x, x])\n",
    "        return layers.Add()([x, attention])\n",
    "    \n",
    "    def _attention_decoder(self, x, encoded):\n",
    "        attention = layers.Dense(x.shape[-1], activation='softmax')(encoded)\n",
    "        attention = layers.RepeatVector(self.input_dim)(attention)\n",
    "        return layers.Multiply()([x, attention])\n",
    "    \n",
    "    def _warmup_schedule(self, lr_schedule, warmup_steps):\n",
    "        def warmup_fn(step):\n",
    "            return tf.cond(\n",
    "                step < warmup_steps,\n",
    "                lambda: tf.cast(step, tf.float32) / warmup_steps * lr_schedule(step),\n",
    "                lambda: lr_schedule(step - warmup_steps)\n",
    "            )\n",
    "        \n",
    "        class WarmupSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "            def __init__(self, warmup_function):\n",
    "                super(WarmupSchedule, self).__init__()\n",
    "                self.warmup_function = warmup_function\n",
    "                \n",
    "            def __call__(self, step):\n",
    "                return self.warmup_function(step)\n",
    "            \n",
    "            def get_config(self):\n",
    "                return {}\n",
    "                \n",
    "        return WarmupSchedule(warmup_fn)\n",
    "    \n",
    "    def train(self, X_train, X_val=None, epochs=75, batch_size=64):\n",
    "        batch_size_schedule = [128, 64, 32]\n",
    "        patience = 10\n",
    "        total_epochs = epochs\n",
    "        current_batch_size = batch_size_schedule[0]\n",
    "        current_epochs = 0\n",
    "        early_stopping = keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', \n",
    "            patience=patience,\n",
    "            restore_best_weights=True,\n",
    "            min_delta=0.0001\n",
    "        )\n",
    "        reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss', \n",
    "            factor=0.3,\n",
    "            patience=5,\n",
    "            min_lr=1e-6\n",
    "        )\n",
    "        history = None\n",
    "        \n",
    "        while current_epochs < total_epochs:\n",
    "            remaining_epochs = total_epochs - current_epochs\n",
    "            batch_epochs = min(remaining_epochs, patience)\n",
    "            print(f\"\\nTraining with batch size {current_batch_size} for {batch_epochs} epochs\")\n",
    "            temp_history = self.model.fit(\n",
    "                X_train, X_train,  \n",
    "                epochs=current_epochs + batch_epochs,\n",
    "                initial_epoch=current_epochs,\n",
    "                batch_size=current_batch_size,\n",
    "                validation_data=(X_val, X_val) if X_val is not None else None,\n",
    "                callbacks=[early_stopping, reduce_lr],\n",
    "                verbose=1\n",
    "            )\n",
    "            current_epochs += batch_epochs\n",
    "            history = temp_history if history is None else history\n",
    "            if current_batch_size in batch_size_schedule:\n",
    "                idx = batch_size_schedule.index(current_batch_size)\n",
    "                if idx < len(batch_size_schedule) - 1:\n",
    "                    current_batch_size = batch_size_schedule[idx + 1]\n",
    "        return history\n",
    "    \n",
    "    def calculate_threshold(self, X_val, method='ensemble'):\n",
    "        reconstructions = self.model.predict(X_val)\n",
    "        reconstruction_errors = np.mean(np.square(X_val - reconstructions), axis=1)\n",
    "        print(\"\\n Reconstruction Error Analysis:\")\n",
    "        print(f\"Mean Error: {np.mean(reconstruction_errors):.2f}\")\n",
    "        print(f\"Median Error: {np.median(reconstruction_errors):.2f}\")\n",
    "        print(f\"Error Standard Deviation: {np.std(reconstruction_errors):.2f}\")\n",
    "        percentiles = [50, 75, 90, 95, 99]\n",
    "        for p in percentiles:\n",
    "            print(f\"{p}th Percentile: {np.percentile(reconstruction_errors, p):.2f}\")\n",
    "        self.visualize_reconstruction_errors(reconstruction_errors)\n",
    "        if method == 'ensemble':\n",
    "            percentile_threshold = np.percentile(reconstruction_errors, 90)\n",
    "            iqr_threshold = np.median(reconstruction_errors) + 1.5 * (np.percentile(reconstruction_errors, 75) - np.percentile(reconstruction_errors, 25))\n",
    "            std_threshold = np.mean(reconstruction_errors) + 2 * np.std(reconstruction_errors)\n",
    "            thresholds = np.array([percentile_threshold, iqr_threshold, std_threshold])\n",
    "            weights = np.array([0.4, 0.3, 0.3])\n",
    "            threshold = np.dot(thresholds, weights)\n",
    "        elif method == 'percentile':\n",
    "            threshold = np.percentile(reconstruction_errors, 90)\n",
    "        elif method == 'median_plus_iqr':\n",
    "            median = np.median(reconstruction_errors)\n",
    "            Q1 = np.percentile(reconstruction_errors, 25)\n",
    "            Q3 = np.percentile(reconstruction_errors, 75)\n",
    "            IQR = Q3 - Q1\n",
    "            threshold = median + 1.5 * IQR\n",
    "        elif method == 'mean_plus_std':\n",
    "            threshold = np.mean(reconstruction_errors) + 2 * np.std(reconstruction_errors)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid threshold calculation method\")\n",
    "        return threshold\n",
    "    \n",
    "    def visualize_reconstruction_errors(self, reconstruction_errors):\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(131)\n",
    "        plt.hist(reconstruction_errors, bins=50, edgecolor='black')\n",
    "        plt.title('Reconstruction Error Distribution')\n",
    "        plt.xlabel('Reconstruction Error')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.subplot(132)\n",
    "        plt.boxplot(reconstruction_errors)\n",
    "        plt.title('Reconstruction Error Boxplot')\n",
    "        plt.ylabel('Error Magnitude')\n",
    "        plt.subplot(133)\n",
    "        plt.plot(np.sort(reconstruction_errors))\n",
    "        plt.title('Sorted Error Magnitude')\n",
    "        plt.xlabel('Sample Index')\n",
    "        plt.ylabel('Error Value')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def detect_anomalies(self, X_test, threshold):\n",
    "        reconstructions = self.model.predict(X_test)\n",
    "        mse = np.mean(np.square(X_test - reconstructions), axis=1)\n",
    "        feature_importance = self.calculate_feature_importance(X_test)\n",
    "        weighted_errors = np.mean(np.square(X_test - reconstructions) * feature_importance, axis=1)\n",
    "        print(\"\\nAnomaly Detection Summary:\")\n",
    "        print(f\"Total Samples: {len(X_test)}\")\n",
    "        anomalies = weighted_errors > threshold\n",
    "        print(f\"Detected Anomalies: {np.sum(anomalies)} ({np.mean(anomalies)*100:.2f}%)\")\n",
    "        return anomalies\n",
    "    \n",
    "    def calculate_feature_importance(self, X_test):\n",
    "        reconstructions = self.model.predict(X_test)\n",
    "        errors = np.square(X_test - reconstructions)\n",
    "        feature_errors = np.mean(errors, axis=0)\n",
    "        feature_importance = feature_errors / np.sum(feature_errors)\n",
    "        return feature_importance.reshape(1, -1)\n",
    "    \n",
    "    def save_model(self, model_path='enhanced_autoencoder_nids_iteration_11.h5'):\n",
    "        self.model.save(model_path)\n",
    "        print(f\"Model saved to {model_path}\")\n",
    "\n",
    "def apply_pca(X_features, variance_threshold=0.99):\n",
    "    pca = PCA(n_components=variance_threshold)\n",
    "    X_features_pca = pca.fit_transform(X_features)\n",
    "    joblib.dump(pca, 'pca_model.pkl')\n",
    "    return X_features_pca, pca\n",
    "\n",
    "def select_features(X_features, y_labels, n_features=15):\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_features, y_labels)\n",
    "    feature_indices = np.argsort(rf.feature_importances_)[::-1][:n_features]\n",
    "    return X_features[:, feature_indices], feature_indices\n",
    "\n",
    "def create_sequences(data, labels=None, seq_length=10, normalize=True):\n",
    "    data = np.array(data)\n",
    "    if normalize:\n",
    "        scaler = MinMaxScaler()\n",
    "        data = scaler.fit_transform(data)\n",
    "        joblib.dump(scaler, 'sequence_scaler.pkl')\n",
    "    sequences, seq_labels = [], []\n",
    "    for i in range(len(data) - seq_length + 1):\n",
    "        sequences.append(data[i:i + seq_length])\n",
    "        if labels is not None:\n",
    "            seq_labels.append(labels[i + seq_length - 1])\n",
    "    sequences = np.array(sequences)\n",
    "    return (sequences, np.array(seq_labels)) if labels is not None else sequences\n",
    "\n",
    "def balance_sequences_with_adasyn(X_sequences, y_sequences, sampling_strategy=0.8):\n",
    "    y_sequences = y_sequences.astype(int)\n",
    "    original_shape = X_sequences.shape\n",
    "    X_seq_2d = X_sequences.reshape(X_sequences.shape[0], -1)\n",
    "    adasyn = ADASYN(random_state=42, sampling_strategy=sampling_strategy, n_neighbors=5)\n",
    "    X_seq_balanced, y_seq_balanced = adasyn.fit_resample(X_seq_2d, y_sequences)\n",
    "    return X_seq_balanced.reshape(-1, original_shape[1], original_shape[2]), y_seq_balanced\n",
    "\n",
    "def weighted_focal_loss(gamma=2.0, alpha=0.25, class_weights=None):\n",
    "    def focal_loss(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.int32)\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)\n",
    "        y_true_one_hot = tf.one_hot(y_true, depth=tf.shape(y_pred)[-1])\n",
    "        if class_weights is not None:\n",
    "            weight_vector = tf.zeros_like(y_true, dtype=tf.float32)\n",
    "            for class_idx, weight in class_weights.items():\n",
    "                weight_vector = tf.where(\n",
    "                    tf.equal(y_true, class_idx),\n",
    "                    tf.ones_like(weight_vector) * weight,\n",
    "                    weight_vector\n",
    "                )\n",
    "            class_weight_factor = tf.expand_dims(weight_vector, axis=-1)\n",
    "        else:\n",
    "            class_weight_factor = 1.0\n",
    "        ce = -tf.reduce_sum(y_true_one_hot * tf.math.log(y_pred), axis=-1)\n",
    "        pt = tf.exp(-ce)\n",
    "        loss = alpha * tf.pow(1 - pt, gamma) * ce * class_weight_factor\n",
    "        return tf.reduce_mean(loss)\n",
    "    return focal_loss\n",
    "\n",
    "class AdaptiveNIDSLayer2:\n",
    "    def __init__(self, input_dim, num_classes, seq_length=10):\n",
    "        self.input_dim = input_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.seq_length = seq_length\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        inputs = layers.Input(shape=(self.seq_length, self.input_dim)) \n",
    "        x = layers.Conv1D(64, kernel_size=3, padding='same')(inputs)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        for _ in range(3):\n",
    "            conv = layers.Conv1D(128, kernel_size=3, padding='same')(x)\n",
    "            conv = layers.BatchNormalization()(conv)\n",
    "            conv = layers.Activation('relu')(conv)\n",
    "            res = layers.Conv1D(128, kernel_size=1, padding='same')(x)\n",
    "            x = layers.Add()([conv, res])\n",
    "            x = layers.SpatialDropout1D(0.3)(x)\n",
    "        attn_output = layers.MultiHeadAttention(\n",
    "            num_heads=4, key_dim=32, dropout=0.2\n",
    "        )(x, x)\n",
    "        x = layers.Add()([x, attn_output])\n",
    "        x = layers.LayerNormalization()(x)\n",
    "        lstm_units = 128\n",
    "        x = layers.Bidirectional(layers.LSTM(lstm_units, return_sequences=True))(x)\n",
    "        x = layers.Bidirectional(layers.LSTM(lstm_units//2))(x)\n",
    "        x = layers.Dense(256, activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.4)(x)\n",
    "        x = layers.Dense(128, activation='relu')(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        outputs = layers.Dense(self.num_classes, activation='softmax')(x)\n",
    "        model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(1e-4),\n",
    "            loss=weighted_focal_loss(gamma=2.0, alpha=0.25, class_weights={0: 2.0, 1: 1.0}),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, y_val, epochs=100, batch_size=64):\n",
    "        initial_lr = 5e-4\n",
    "        warmup_epochs = 10\n",
    "        hold_epochs = 5\n",
    "        def lr_schedule(epoch):\n",
    "            if epoch < warmup_epochs:\n",
    "                return initial_lr * ((epoch + 1) / warmup_epochs)\n",
    "            elif epoch < warmup_epochs + hold_epochs:\n",
    "                return initial_lr\n",
    "            else:\n",
    "                decay_epochs = epochs - warmup_epochs - hold_epochs\n",
    "                return initial_lr * 0.5 * (1 + np.cos(np.pi * (epoch - warmup_epochs - hold_epochs) / decay_epochs))\n",
    "        class F1ScoreCallback(keras.callbacks.Callback):\n",
    "            def __init__(self, validation_data, model, patience=8):\n",
    "                super().__init__()\n",
    "                self.X_val, self.y_val = validation_data\n",
    "                self.model = model\n",
    "                self.patience = patience\n",
    "                self.best_f1 = 0\n",
    "                self.wait = 0\n",
    "                self.best_weights = None\n",
    "            def on_epoch_end(self, epoch, logs={}):\n",
    "                y_pred = np.argmax(self.model.predict(self.X_val), axis=1)\n",
    "                f1 = f1_score(self.y_val, y_pred, average='weighted')\n",
    "                logs['val_f1_score'] = f1\n",
    "                print(f\"\\nEpoch {epoch+1}: val_f1_score: {f1:.4f}\")\n",
    "                if f1 > self.best_f1:\n",
    "                    self.best_f1 = f1\n",
    "                    self.wait = 0\n",
    "                    self.best_weights = self.model.get_weights()\n",
    "                    self.model.save_weights('best_nids_model.h5')\n",
    "                    print(f\"Best F1 score improved to {f1:.4f}, saving model\")\n",
    "                else:\n",
    "                    self.wait += 1\n",
    "                    if self.wait >= self.patience:\n",
    "                        print(f\"Early stopping triggered. Best F1: {self.best_f1:.4f}\")\n",
    "                        self.model.stop_training = True\n",
    "                        self.model.set_weights(self.best_weights)\n",
    "        def apply_mixup(x_batch, y_batch, alpha=0.2):\n",
    "            batch_size = x_batch.shape[0]\n",
    "            indices = np.random.permutation(batch_size)\n",
    "            x_shuffled = x_batch[indices]\n",
    "            y_shuffled = y_batch[indices]\n",
    "            n_classes = self.num_classes\n",
    "            y_batch_onehot = np.eye(n_classes)[y_batch]\n",
    "            y_shuffled_onehot = np.eye(n_classes)[y_shuffled]\n",
    "            lam = np.random.beta(alpha, alpha, batch_size)\n",
    "            lam = np.maximum(lam, 1-lam)\n",
    "            lam = np.expand_dims(lam, axis=(1, 2))\n",
    "            x_mixed = lam * x_batch + (1-lam) * x_shuffled\n",
    "            lam_y = lam[:, 0, 0]\n",
    "            lam_y = np.expand_dims(lam_y, axis=1)\n",
    "            y_mixed = lam_y * y_batch_onehot + (1-lam_y) * y_shuffled_onehot\n",
    "            return x_mixed, y_mixed\n",
    "        def custom_train():\n",
    "            optimizer = keras.optimizers.Adam(learning_rate=initial_lr)\n",
    "            loss_fn = self.model.loss\n",
    "            if tf.config.list_physical_devices('GPU'):\n",
    "                policy = mixed_precision.Policy('mixed_float16')\n",
    "                mixed_precision.set_global_policy(policy)\n",
    "            f1_callback = F1ScoreCallback(validation_data=(X_val, y_val), model=self.model)\n",
    "            lr_scheduler = keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "            history = {'loss': [], 'val_loss': [], 'accuracy': [], 'val_accuracy': [], 'val_f1_score': []}\n",
    "            for epoch in range(epochs):\n",
    "                current_lr = lr_schedule(epoch)\n",
    "                optimizer.learning_rate.assign(current_lr)\n",
    "                indices = np.random.permutation(len(X_train))\n",
    "                X_shuffled = X_train[indices]\n",
    "                y_shuffled = y_train[indices]\n",
    "                train_loss = 0\n",
    "                train_acc = 0\n",
    "                num_batches = int(np.ceil(len(X_train) / batch_size))\n",
    "                for batch in range(num_batches):\n",
    "                    start_idx = batch * batch_size\n",
    "                    end_idx = min((batch + 1) * batch_size, len(X_train))\n",
    "                    x_batch = X_shuffled[start_idx:end_idx]\n",
    "                    y_batch = y_shuffled[start_idx:end_idx]\n",
    "                    if np.random.random() < 0.7:\n",
    "                        x_batch, y_batch_onehot = apply_mixup(x_batch, y_batch)\n",
    "                        with tf.GradientTape() as tape:\n",
    "                            logits = self.model(x_batch, training=True)\n",
    "                            loss_value = tf.reduce_mean(\n",
    "                                tf.keras.losses.categorical_crossentropy(y_batch_onehot, logits)\n",
    "                            )\n",
    "                            if tf.config.list_physical_devices('GPU'):\n",
    "                                loss_value = optimizer.get_scaled_loss(loss_value)\n",
    "                        grads = tape.gradient(loss_value, self.model.trainable_variables)\n",
    "                        if tf.config.list_physical_devices('GPU'):\n",
    "                            grads = optimizer.get_unscaled_gradients(grads)\n",
    "                        optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "                        train_loss += loss_value\n",
    "                        preds = tf.argmax(logits, axis=1)\n",
    "                        y_true = tf.argmax(y_batch_onehot, axis=1)\n",
    "                        train_acc += tf.reduce_mean(tf.cast(tf.equal(preds, y_true), tf.float32))\n",
    "                    else:\n",
    "                        self.model.train_on_batch(x_batch, y_batch)\n",
    "                val_loss, val_acc = self.model.evaluate(X_val, y_val, verbose=0)\n",
    "                y_pred = np.argmax(self.model.predict(X_val), axis=1)\n",
    "                val_f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "                history['loss'].append(train_loss/num_batches)\n",
    "                history['accuracy'].append(train_acc/num_batches)\n",
    "                history['val_loss'].append(val_loss)\n",
    "                history['val_accuracy'].append(val_acc)\n",
    "                history['val_f1_score'].append(val_f1)\n",
    "                f1_callback.on_epoch_end(epoch, {'val_f1_score': val_f1})\n",
    "                print(f\"Epoch {epoch+1}/{epochs} - loss: {train_loss/num_batches:.4f} - accuracy: {train_acc/num_batches:.4f} - val_loss: {val_loss:.4f} - val_accuracy: {val_acc:.4f} - val_f1: {val_f1:.4f} - lr: {current_lr:.6f}\")\n",
    "                if f1_callback.wait >= f1_callback.patience:\n",
    "                    print(\"Early stopping triggered\")\n",
    "                    break\n",
    "            self.model.load_weights('best_nids_model.h5')\n",
    "            return keras.callbacks.History().set_model(self.model).set_params({'epochs': epochs, 'metrics': list(history.keys())}).set_model_history(history)\n",
    "        return custom_train()\n",
    "\n",
    "    def evaluate_model(self, X_test, y_test):\n",
    "        y_pred_probs = self.model.predict(X_test)\n",
    "        confidence_threshold = 0.95\n",
    "        low_confidence_mask = np.max(y_pred_probs, axis=1) < confidence_threshold\n",
    "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        metrics = {}\n",
    "        for class_idx in range(self.num_classes):\n",
    "            true_positives = cm[class_idx, class_idx]\n",
    "            false_negatives = np.sum(cm[class_idx, :]) - true_positives\n",
    "            false_positives = np.sum(cm[:, class_idx]) - true_positives\n",
    "            true_negatives = np.sum(cm) - true_positives - false_negatives - false_positives\n",
    "            metrics[class_idx] = {\n",
    "                'detection_rate': true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0,\n",
    "                'false_positive_rate': false_positives / (false_positives + true_negatives) if (false_positives + true_negatives) > 0 else 0,\n",
    "                'precision': true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0,\n",
    "                'f1_score': 2 * true_positives / (2 * true_positives + false_positives + false_negatives) if (2 * true_positives + false_positives + false_negatives) > 0 else 0,\n",
    "                'support': np.sum(y_test == class_idx)\n",
    "            }\n",
    "        from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "        y_test_bin = np.eye(self.num_classes)[y_test]\n",
    "        roc_auc = roc_auc_score(y_test_bin, y_pred_probs, multi_class='ovr', average='weighted')\n",
    "        pr_auc = average_precision_score(y_test_bin, y_pred_probs, average='weighted')\n",
    "        self._generate_roc_curves(y_test, y_pred_probs)\n",
    "        self._plot_confusion_matrix(cm, [f\"Class {i}\" for i in range(self.num_classes)])\n",
    "        return {\n",
    "            'classification_report': report,\n",
    "            'confusion_matrix': cm,\n",
    "            'class_metrics': metrics,\n",
    "            'low_confidence_predictions': sum(low_confidence_mask),\n",
    "            'overall_metrics': {\n",
    "                'accuracy': report['accuracy'],\n",
    "                'weighted_f1': report['weighted avg']['f1-score'],\n",
    "                'macro_f1': report['macro avg']['f1-score'],\n",
    "                'roc_auc': roc_auc,\n",
    "                'pr_auc': pr_auc\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def _generate_roc_curves(self, y_test, y_pred_probs):\n",
    "        from sklearn.metrics import roc_curve, auc\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        y_test_bin = np.eye(self.num_classes)[y_test]\n",
    "        for i in range(self.num_classes):\n",
    "            fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_pred_probs[:, i])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, label=f'Class {i} (AUC = {roc_auc:.3f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig('roc_curves.png')\n",
    "\n",
    "    def _plot_confusion_matrix(self, cm, class_names):\n",
    "        import seaborn as sns\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                    xticklabels=class_names, \n",
    "                    yticklabels=class_names)\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('confusion_matrix.png')\n",
    "\n",
    "    def plot_training_history(self, history):\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.plot(history.history['loss'], label='Training Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Model Loss', fontsize=12)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.title('Model Accuracy', fontsize=12)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        if 'val_f1_score' in history.history:\n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.plot(history.history['val_f1_score'], label='Validation F1 Score', color='green')\n",
    "            plt.title('F1 Score', fontsize=12)\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('F1 Score')\n",
    "            plt.legend()\n",
    "        if len(history.epoch) > 0:\n",
    "            plt.subplot(2, 2, 4)\n",
    "            lr_values = [self.model.optimizer.learning_rate(i) for i in range(len(history.epoch))]\n",
    "            plt.plot(lr_values, label='Learning Rate', color='purple')\n",
    "            plt.title('Learning Rate Schedule', fontsize=12)\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Learning Rate')\n",
    "            plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('training_history_extended.png', dpi=300)\n",
    "        plt.show()\n",
    "        pd.DataFrame(history.history).to_csv('training_metrics.csv', index=False)\n",
    "\n",
    "def main():\n",
    "    file_path = \"/Users/siddhantgond/Desktop/6THSEM/Project_Elective/Adaptive-Network-Intrusion-Detection-System/Implementaiton/training_dataset.csv\"\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = preprocess_data(file_path)\n",
    "    anomaly_detector = EnhancedAdaptiveNIDS(input_dim=X_train.shape[1], latent_dim=16)\n",
    "    layer1_history = anomaly_detector.train(X_train, X_val, epochs=50, batch_size=32)\n",
    "    threshold = anomaly_detector.calculate_threshold(X_val)\n",
    "    print(f\"\\nCalculated Anomaly Threshold: {threshold}\")\n",
    "    X_anomalies = X_train[anomaly_detector.detect_anomalies(X_train, threshold)]\n",
    "    y_anomalies = y_train[anomaly_detector.detect_anomalies(X_train, threshold)]\n",
    "    feature_extractor = keras.Model(\n",
    "        inputs=anomaly_detector.model.input, \n",
    "        outputs=anomaly_detector.model.get_layer(\"gap_layer\").output\n",
    "    )\n",
    "    X_features = feature_extractor.predict(X_anomalies)\n",
    "    X_pca, pca = apply_pca(X_features)\n",
    "    X_selected, feature_indices = select_features(X_pca, y_anomalies, n_features=15)\n",
    "    joblib.dump(feature_indices, 'feature_indices_Iteration_3.pkl')\n",
    "    X_sequences, y_sequences = create_sequences(X_selected, y_anomalies)\n",
    "    X_balanced, y_balanced = balance_sequences_with_adasyn(X_sequences, y_sequences)\n",
    "    X_val_anomalies = X_val[anomaly_detector.detect_anomalies(X_val, threshold)]\n",
    "    y_val_anomalies = y_val[anomaly_detector.detect_anomalies(X_val, threshold)]\n",
    "    X_val_features = feature_extractor.predict(X_val_anomalies)\n",
    "    X_val_pca = pca.transform(X_val_features)\n",
    "    X_val_selected = X_val_pca[:, feature_indices]\n",
    "    X_val_sequences = create_sequences(X_val_selected)\n",
    "    num_classes = len(np.unique(y_balanced))\n",
    "    classifier = AdaptiveNIDSLayer2(\n",
    "        input_dim=X_balanced.shape[2], \n",
    "        num_classes=num_classes, \n",
    "        seq_length=X_balanced.shape[1]\n",
    "    )\n",
    "    layer2_history = classifier.train(X_balanced, y_balanced, X_val_sequences, y_val_anomalies)\n",
    "    X_test_anomalies = X_test[anomaly_detector.detect_anomalies(X_test, threshold)]\n",
    "    y_test_anomalies = y_test[anomaly_detector.detect_anomalies(X_test, threshold)]\n",
    "    X_test_features = feature_extractor.predict(X_test_anomalies)\n",
    "    X_test_pca = pca.transform(X_test_features)\n",
    "    X_test_selected = X_test_pca[:, feature_indices]\n",
    "    X_test_sequences = create_sequences(X_test_selected)\n",
    "    eval_results = classifier.evaluate_model(X_test_sequences, y_test_anomalies)\n",
    "    classifier.plot_training_history(layer2_history)\n",
    "    anomaly_detector.model.save('anomaly_detector_model.h5')\n",
    "    classifier.model.save('classifier_model.h5')\n",
    "    print(\"\\nModel Evaluation Results:\")\n",
    "    print(f\"Accuracy: {eval_results['overall_metrics']['accuracy']:.4f}\")\n",
    "    print(f\"Weighted F1 Score: {eval_results['overall_metrics']['weighted_f1']:.4f}\")\n",
    "    print(f\"ROC AUC: {eval_results['overall_metrics']['roc_auc']:.4f}\")\n",
    "    print(f\"PR AUC: {eval_results['overall_metrics']['pr_auc']:.4f}\")\n",
    "    print(\"\\nPer-Class Performance:\")\n",
    "    for class_idx, metrics in eval_results['class_metrics'].items():\n",
    "        print(f\"Class {class_idx}:\")\n",
    "        print(f\"  Detection Rate: {metrics['detection_rate']:.4f}\")\n",
    "        print(f\"  False Positive Rate: {metrics['false_positive_rate']:.4f}\")\n",
    "        print(f\"  Precision: {metrics['precision']:.4f}\")\n",
    "        print(f\"  F1 Score: {metrics['f1_score']:.4f}\")\n",
    "        print(f\"  Support: {metrics['support']}\")\n",
    "    plot_feature_importance(classifier, X_test_sequences, y_test_anomalies)\n",
    "    with open('evaluation_results.txt', 'w') as f:\n",
    "        f.write(f\"Model Evaluation Results:\\n\")\n",
    "        f.write(f\"Accuracy: {eval_results['overall_metrics']['accuracy']:.4f}\\n\")\n",
    "        f.write(f\"Weighted F1 Score: {eval_results['overall_metrics']['weighted_f1']:.4f}\\n\")\n",
    "        f.write(f\"ROC AUC: {eval_results['overall_metrics']['roc_auc']:.4f}\\n\")\n",
    "        f.write(f\"PR AUC: {eval_results['overall_metrics']['pr_auc']:.4f}\\n\")\n",
    "        f.write(\"\\nClassification Report:\\n\")\n",
    "        for class_name, metrics in eval_results['classification_report'].items():\n",
    "            if isinstance(metrics, dict):\n",
    "                f.write(f\"{class_name}: {metrics}\\n\")\n",
    "    return eval_results\n",
    "\n",
    "def plot_feature_importance(classifier, X_test, y_test):\n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "        from tensorflow.keras.models import Model\n",
    "        grad_model = Model(\n",
    "            inputs=classifier.model.inputs,\n",
    "            outputs=[classifier.model.outputs[0], \n",
    "                     tf.gradients(classifier.model.outputs[0], classifier.model.inputs)[0]]\n",
    "        )\n",
    "        sample_indices = np.random.choice(len(X_test), min(100, len(X_test)), replace=False)\n",
    "        X_sample = X_test[sample_indices]\n",
    "        y_sample = y_test[sample_indices]\n",
    "        predictions, grads = grad_model.predict(X_sample)\n",
    "        feature_importance = np.mean(np.abs(grads), axis=0)\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(feature_importance.T, aspect='auto', cmap='viridis')\n",
    "        plt.colorbar(label='Feature Importance')\n",
    "        plt.xlabel('Sequence Position')\n",
    "        plt.ylabel('Feature Index')\n",
    "        plt.title('Feature Importance Across Sequence')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('feature_importance.png', dpi=300)\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        avg_importance = np.mean(feature_importance, axis=1)\n",
    "        plt.bar(range(len(avg_importance)), avg_importance)\n",
    "        plt.xlabel('Sequence Position')\n",
    "        plt.ylabel('Average Importance')\n",
    "        plt.title('Feature Importance by Sequence Position')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('position_importance.png', dpi=300)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not generate feature importance visualization: {e}\")\n",
    "\n",
    "def predict_single_sample(anomaly_detector, classifier, sample, pca, feature_indices, threshold=0.03):\n",
    "    if len(sample.shape) == 1:\n",
    "        sample = sample.reshape(1, -1)\n",
    "    reconstructed = anomaly_detector.model.predict(sample)\n",
    "    error = np.mean(np.square(sample - reconstructed), axis=1)[0]\n",
    "    if error <= threshold:\n",
    "        return {\n",
    "            'anomaly': False,\n",
    "            'error': error,\n",
    "            'class': None,\n",
    "            'confidence': None\n",
    "        }\n",
    "    features = anomaly_detector.extract_features(sample)\n",
    "    features_pca = pca.transform(features)\n",
    "    selected_features = features_pca[:, feature_indices]\n",
    "    sequence = create_sequences(selected_features)\n",
    "    predictions = classifier.model.predict(sequence)[0]\n",
    "    predicted_class = np.argmax(predictions)\n",
    "    confidence = predictions[predicted_class]\n",
    "    return {\n",
    "        'anomaly': True,\n",
    "        'error': error,\n",
    "        'class': int(predicted_class),\n",
    "        'confidence': float(confidence),\n",
    "        'class_probabilities': {i: float(p) for i, p in enumerate(predictions)}\n",
    "    }\n",
    "\n",
    "def batch_prediction(anomaly_detector, classifier, samples, pca, feature_indices, threshold=0.03):\n",
    "    reconstructed = anomaly_detector.model.predict(samples)\n",
    "    errors = np.mean(np.square(samples - reconstructed), axis=1)\n",
    "    anomaly_indices = np.where(errors > threshold)[0]\n",
    "    results = {\n",
    "        'total_samples': len(samples),\n",
    "        'anomalies_detected': len(anomaly_indices),\n",
    "        'anomaly_indices': anomaly_indices.tolist(),\n",
    "        'errors': errors.tolist(),\n",
    "        'predictions': [None] * len(samples)\n",
    "    }\n",
    "    if len(anomaly_indices) > 0:\n",
    "        anomalies = samples[anomaly_indices]\n",
    "        features = anomaly_detector.extract_features(anomalies)\n",
    "        features_pca = pca.transform(features)\n",
    "        selected_features = features_pca[:, feature_indices]\n",
    "        sequences = create_sequences(selected_features)\n",
    "        predictions = classifier.model.predict(sequences)\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "        confidences = np.max(predictions, axis=1)\n",
    "        for i, idx in enumerate(anomaly_indices):\n",
    "            results['predictions'][idx] = {\n",
    "                'class': int(predicted_classes[i]),\n",
    "                'confidence': float(confidences[i]),\n",
    "                'class_probabilities': {j: float(p) for j, p in enumerate(predictions[i])}\n",
    "            }\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 30ms/step - loss: 12099911680.0000 - val_loss: 15296579584.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 29ms/step - loss: 12441402368.0000 - val_loss: 15296574464.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 33ms/step - loss: 12496417792.0000 - val_loss: 15296567296.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 35ms/step - loss: 11993251840.0000 - val_loss: 15296555008.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 37ms/step - loss: 12849728512.0000 - val_loss: 15296553984.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 28ms/step - loss: 12757391360.0000 - val_loss: 15296549888.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 28ms/step - loss: 12455483392.0000 - val_loss: 15296547840.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 28ms/step - loss: 12602369024.0000 - val_loss: 15296546816.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 28ms/step - loss: 12157963264.0000 - val_loss: 15296546816.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 28ms/step - loss: 12981597184.0000 - val_loss: 15296545792.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 28ms/step - loss: 12031524864.0000 - val_loss: 15296545792.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 30ms/step - loss: 12201100288.0000 - val_loss: 15296545792.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 30ms/step - loss: 11813881856.0000 - val_loss: 15296545792.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 28ms/step - loss: 12631718912.0000 - val_loss: 15296545792.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 29ms/step - loss: 12860627968.0000 - val_loss: 15296545792.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 28ms/step - loss: 12619373568.0000 - val_loss: 15296545792.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 27ms/step - loss: 12803813376.0000 - val_loss: 15296545792.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 27ms/step - loss: 12212905984.0000 - val_loss: 15296545792.0000\n",
      "Epoch 19/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 28ms/step - loss: 12407546880.0000 - val_loss: 15296545792.0000\n",
      "Epoch 20/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 28ms/step - loss: 12580540416.0000 - val_loss: 15296545792.0000\n",
      "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8763 - loss: 0.3821 - val_accuracy: 0.9769 - val_loss: 0.0445\n",
      "Epoch 2/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9848 - loss: 0.0367 - val_accuracy: 0.9933 - val_loss: 0.0189\n",
      "Epoch 3/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9896 - loss: 0.0243 - val_accuracy: 0.9944 - val_loss: 0.0143\n",
      "Epoch 4/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9873 - loss: 0.0306 - val_accuracy: 0.9947 - val_loss: 0.0156\n",
      "Epoch 5/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9934 - loss: 0.0171 - val_accuracy: 0.9968 - val_loss: 0.0103\n",
      "Epoch 6/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9965 - loss: 0.0106 - val_accuracy: 0.9954 - val_loss: 0.0116\n",
      "Epoch 7/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9936 - loss: 0.0137 - val_accuracy: 0.9947 - val_loss: 0.0141\n",
      "Epoch 8/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9945 - loss: 0.0120 - val_accuracy: 0.9937 - val_loss: 0.0124\n",
      "Epoch 9/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9946 - loss: 0.0133 - val_accuracy: 0.9916 - val_loss: 0.0196\n",
      "Epoch 10/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9925 - loss: 0.0189 - val_accuracy: 0.9951 - val_loss: 0.0141\n",
      "Epoch 11/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9954 - loss: 0.0104 - val_accuracy: 0.9947 - val_loss: 0.0113\n",
      "Epoch 12/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9966 - loss: 0.0101 - val_accuracy: 0.9881 - val_loss: 0.0312\n",
      "Epoch 13/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9939 - loss: 0.0147 - val_accuracy: 0.9961 - val_loss: 0.0073\n",
      "Epoch 14/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9953 - loss: 0.0112 - val_accuracy: 0.9961 - val_loss: 0.0101\n",
      "Epoch 15/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9934 - loss: 0.0150 - val_accuracy: 0.9961 - val_loss: 0.0111\n",
      "Epoch 16/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9959 - loss: 0.0105 - val_accuracy: 0.9720 - val_loss: 0.1083\n",
      "Epoch 17/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9897 - loss: 0.0264 - val_accuracy: 0.9947 - val_loss: 0.0118\n",
      "Epoch 18/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9948 - loss: 0.0121 - val_accuracy: 0.9905 - val_loss: 0.0274\n",
      "Epoch 19/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9964 - loss: 0.0086 - val_accuracy: 0.9937 - val_loss: 0.0171\n",
      "Epoch 20/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9967 - loss: 0.0086 - val_accuracy: 0.9961 - val_loss: 0.0102\n",
      "Epoch 21/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9979 - loss: 0.0062 - val_accuracy: 0.9947 - val_loss: 0.0116\n",
      "Epoch 22/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9955 - loss: 0.0095 - val_accuracy: 0.9947 - val_loss: 0.0113\n",
      "Epoch 23/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9966 - loss: 0.0112 - val_accuracy: 0.9937 - val_loss: 0.0125\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "start_time = time.time()\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "class EnhancedAdaptiveNIDS:\n",
    "    def __init__(self, input_dim, latent_dim=16, learning_rate=5e-4):\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = self._build_autoencoder()\n",
    "\n",
    "    def _build_autoencoder(self):\n",
    "        inputs = layers.Input(shape=(self.input_dim,))\n",
    "        x = layers.BatchNormalization()(inputs)\n",
    "        x = layers.Reshape((-1, 1))(x)\n",
    "        x = self._residual_conv_block(x, filters=16, kernel_size=3)\n",
    "        x = self._residual_conv_block(x, filters=32, kernel_size=3)\n",
    "        x = self._self_attention_block(x)\n",
    "        x = layers.GlobalAveragePooling1D()(x)\n",
    "        x = layers.Dense(64, activation='mish', kernel_regularizer=regularizers.l1_l2(0.0005, 0.00075))(x)\n",
    "        x = layers.LayerNormalization()(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        encoded = layers.Dense(self.latent_dim, activation='linear', kernel_regularizer=regularizers.l1(0.0005))(x)\n",
    "        x = layers.RepeatVector(self.input_dim)(encoded)\n",
    "        x = layers.LSTM(self.latent_dim * 2, return_sequences=True, recurrent_dropout=0.25)(x)\n",
    "        x = self._attention_decoder(x, encoded)\n",
    "        decoded = layers.TimeDistributed(layers.Dense(1, activation='linear'))(x)\n",
    "        decoded = layers.Flatten()(decoded)\n",
    "        autoencoder = keras.Model(inputs=inputs, outputs=decoded)\n",
    "        lr_schedule = tf.keras.optimizers.schedules.CosineDecay(self.learning_rate, 10000, alpha=0.001)\n",
    "        autoencoder.compile(optimizer=keras.optimizers.Adam(learning_rate=lr_schedule, clipnorm=1.0), loss='mean_squared_error')\n",
    "        return autoencoder\n",
    "\n",
    "    def _residual_conv_block(self, x, filters, kernel_size):\n",
    "        shortcut = x\n",
    "        x = layers.Conv1D(filters, kernel_size, activation='mish', padding='same', kernel_regularizer=regularizers.l2(0.00075))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv1D(filters, kernel_size, activation='mish', padding='same', kernel_regularizer=regularizers.l2(0.00075))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        if shortcut.shape[-1] != x.shape[-1]:\n",
    "            shortcut = layers.Conv1D(filters, 1, activation='mish', padding='same')(shortcut)\n",
    "        return layers.Add()([x, shortcut])\n",
    "\n",
    "    def _self_attention_block(self, x):\n",
    "        return layers.Add()([x, layers.Attention()([x, x])])\n",
    "\n",
    "    def _attention_decoder(self, x, encoded):\n",
    "        attention = layers.Dense(x.shape[-1], activation='softmax')(encoded)\n",
    "        attention = layers.RepeatVector(self.input_dim)(attention)\n",
    "        return layers.Multiply()([x, attention])\n",
    "\n",
    "    def train(self, X_train, X_val, epochs=50, batch_size=64):\n",
    "        early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "        self.model.fit(X_train, X_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, X_val), callbacks=[early_stopping])\n",
    "\n",
    "    def detect_anomalies(self, X_data, threshold):\n",
    "        reconstructed = self.model.predict(X_data)\n",
    "        errors = np.mean(np.square(X_data - reconstructed), axis=1)\n",
    "        return X_data[errors > threshold], np.where(errors > threshold)[0]\n",
    "\n",
    "class AdaptiveNIDSLayer2:\n",
    "    def __init__(self, input_dim, num_classes, seq_length=10):\n",
    "        self.input_dim = input_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.seq_length = seq_length\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        inputs = layers.Input(shape=(self.seq_length, self.input_dim))\n",
    "        x = layers.Conv1D(64, 3, activation='relu', padding='same')(inputs)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Bidirectional(layers.GRU(48, return_sequences=False))(x)\n",
    "        x = layers.Dense(64, activation='relu')(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        outputs = layers.Dense(self.num_classes, activation='softmax')(x)\n",
    "        model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        model.compile(optimizer=keras.optimizers.Adam(1e-3), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def train(self, X_train, y_train, epochs=50, batch_size=64):\n",
    "        early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "        self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "def preprocess_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(['Attack_label'], axis=1)\n",
    "    scaler = RobustScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    joblib.dump(scaler, 'robust_scaler.pkl')\n",
    "    return train_test_split(X_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "def extract_features(model, X_anomalies):\n",
    "    feature_extractor = keras.Model(inputs=model.input, outputs=model.get_layer(\"global_average_pooling1d\").output)\n",
    "    return feature_extractor.predict(X_anomalies)\n",
    "\n",
    "def create_sequences(data, labels, seq_length=10):\n",
    "    sequences, seq_labels = [], []\n",
    "    labels = np.array(labels)\n",
    "    for i in range(len(data) - seq_length):\n",
    "        sequences.append(data[i:i + seq_length])\n",
    "        seq_labels.append(labels[i + seq_length - 1])\n",
    "    return np.array(sequences), np.array(seq_labels)\n",
    "\n",
    "dataset_path = \"/Users/siddhantgond/Desktop/6THSEM/Project_Elective/Adaptive-Network-Intrusion-Detection-System/Implementaiton/training_dataset.csv\"\n",
    "X_train, X_val = preprocess_data(dataset_path)\n",
    "layer1 = EnhancedAdaptiveNIDS(input_dim=X_train.shape[1])\n",
    "layer1.train(X_train, X_val)\n",
    "\n",
    "threshold = 0.02\n",
    "anomalies, anomaly_indices = layer1.detect_anomalies(X_val, threshold)\n",
    "\n",
    "original_df = pd.read_csv(dataset_path)\n",
    "X_layer2, y_layer2 = original_df.iloc[anomaly_indices].drop(columns=['Attack_label']), original_df.iloc[anomaly_indices]['Attack_label']\n",
    "\n",
    "X_layer2_reshaped, y_layer2_adjusted = create_sequences(X_layer2.values, y_layer2, seq_length=10)\n",
    "layer2 = AdaptiveNIDSLayer2(input_dim=X_layer2_reshaped.shape[2], num_classes=5, seq_length=10)\n",
    "layer2.train(X_layer2_reshaped, y_layer2_adjusted)\n",
    "\n",
    "def knowledge_distillation(teacher_model, student_model, X_train, y_train, temperature=3.0, alpha=0.5, epochs=50):\n",
    "    y_train = np.array(y_train)\n",
    "    if len(y_train.shape) > 1 and y_train.shape[1] > 1:\n",
    "        y_train = np.argmax(y_train, axis=1)\n",
    "    num_classes = student_model.output_shape[-1]\n",
    "    teacher_logits = teacher_model.predict(X_train)\n",
    "    teacher_probs = tf.nn.softmax(teacher_logits / temperature).numpy()\n",
    "    def distillation_loss(y_true, y_pred):\n",
    "        hard_loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "        soft_loss = tf.keras.losses.KLDivergence()(tf.nn.softmax(teacher_logits / temperature), tf.nn.softmax(y_pred / temperature))\n",
    "        return (1 - alpha) * hard_loss + alpha * soft_loss * (temperature ** 2)\n",
    "    student_model.compile(optimizer=keras.optimizers.Adam(1e-3), loss=distillation_loss, metrics=['accuracy'])\n",
    "    student_model.fit(X_train, y_train, epochs=epochs, batch_size=64)\n",
    "    return student_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Layer 1: Autoencoder...\n",
      "Epoch 1/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 1.1902 - val_loss: 0.0862 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.3152 - val_loss: 0.0239 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1744 - val_loss: 0.0138 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1095 - val_loss: 0.0102 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0709 - val_loss: 0.0084 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0458 - val_loss: 0.0071 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0295 - val_loss: 0.0060 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0192 - val_loss: 0.0051 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0132 - val_loss: 0.0042 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0033 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0030 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0025 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0060 - val_loss: 0.0022 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0055 - val_loss: 0.0022 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0021 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0019 - learning_rate: 1.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0016 - learning_rate: 1.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0041 - val_loss: 0.0015 - learning_rate: 1.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0040 - val_loss: 0.0015 - learning_rate: 1.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0038 - val_loss: 0.0014 - learning_rate: 1.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0037 - val_loss: 0.0014 - learning_rate: 1.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0036 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0012 - learning_rate: 1.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0012 - learning_rate: 1.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 9.6181e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0032 - val_loss: 9.1763e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 8.9594e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 9.4059e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 9.2600e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0030 - val_loss: 8.3591e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0030 - val_loss: 7.7221e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0030 - val_loss: 8.4976e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 7.5502e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 7.8675e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 7.2398e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 7.5522e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 7.1793e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 6.0251e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 6.6309e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 6.5209e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 6.2373e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 6.4206e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 6.4395e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 5.9376e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 6.1893e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 6.0115e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 6.1883e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 6.2431e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 5.6072e-04 - learning_rate: 1.2500e-05\n",
      "\u001b[1m1785/1785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 446us/step\n",
      "Dynamic threshold set to: 0.0013808681152349908\n",
      "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Training Layer 2: CNN-BiLSTM...\n",
      "Epoch 1/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 0.5288 - loss: 0.9720 - val_accuracy: 0.4101 - val_loss: 0.7014 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8366 - loss: 0.3778 - val_accuracy: 0.6403 - val_loss: 0.6753 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9457 - loss: 0.1974 - val_accuracy: 0.6403 - val_loss: 0.6614 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9719 - loss: 0.1111 - val_accuracy: 0.7770 - val_loss: 0.6243 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9941 - loss: 0.0464 - val_accuracy: 0.8058 - val_loss: 0.5968 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9901 - loss: 0.0425 - val_accuracy: 0.8345 - val_loss: 0.5710 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9954 - loss: 0.0252 - val_accuracy: 0.8129 - val_loss: 0.5485 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9977 - loss: 0.0151 - val_accuracy: 0.8417 - val_loss: 0.5289 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0124 - val_accuracy: 0.8633 - val_loss: 0.5097 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.8705 - val_loss: 0.4841 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.8921 - val_loss: 0.4591 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9065 - val_loss: 0.4374 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.9065 - val_loss: 0.4176 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.9065 - val_loss: 0.3982 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.8993 - val_loss: 0.3804 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9137 - val_loss: 0.3647 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9065 - val_loss: 0.3495 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9065 - val_loss: 0.3351 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9137 - val_loss: 0.3230 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9137 - val_loss: 0.3114 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9209 - val_loss: 0.3011 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9137 - val_loss: 0.2890 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9137 - val_loss: 0.2792 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9137 - val_loss: 0.2714 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9137 - val_loss: 0.2658 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 9.9081e-04 - val_accuracy: 0.9209 - val_loss: 0.2613 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 9.2217e-04 - val_accuracy: 0.9209 - val_loss: 0.2568 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9209 - val_loss: 0.2513 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9137 - val_loss: 0.2466 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9137 - val_loss: 0.2416 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 7.7636e-04 - val_accuracy: 0.9137 - val_loss: 0.2380 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 7.8517e-04 - val_accuracy: 0.9137 - val_loss: 0.2366 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 8.1470e-04 - val_accuracy: 0.9137 - val_loss: 0.2371 - learning_rate: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 9.1327e-04 - val_accuracy: 0.9137 - val_loss: 0.2381 - learning_rate: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 9.9889e-04 - val_accuracy: 0.9209 - val_loss: 0.2382 - learning_rate: 0.0010\n",
      "Epoch 36/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 8.5985e-04 - val_accuracy: 0.9209 - val_loss: 0.2371 - learning_rate: 0.0010\n",
      "Epoch 37/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 9.6582e-04 - val_accuracy: 0.9209 - val_loss: 0.2369 - learning_rate: 0.0010\n",
      "Epoch 38/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 4.9347e-04 - val_accuracy: 0.9137 - val_loss: 0.2389 - learning_rate: 5.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 6.9223e-04 - val_accuracy: 0.9137 - val_loss: 0.2409 - learning_rate: 5.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 8.4684e-04 - val_accuracy: 0.9137 - val_loss: 0.2433 - learning_rate: 5.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 7.2294e-04 - val_accuracy: 0.9137 - val_loss: 0.2462 - learning_rate: 5.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9209 - val_loss: 0.2494 - learning_rate: 5.0000e-04\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.82      0.88        55\n",
      "         1.0       0.89      0.98      0.93        84\n",
      "\n",
      "    accuracy                           0.91       139\n",
      "   macro avg       0.92      0.90      0.91       139\n",
      "weighted avg       0.92      0.91      0.91       139\n",
      "\n",
      "Total execution time: 103.25 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler  # Changed from RobustScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "start_time = time.time()\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "class EnhancedAdaptiveNIDS:\n",
    "    def __init__(self, input_dim, latent_dim=32, learning_rate=1e-4):  # Increased latent_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = self._build_autoencoder()\n",
    "        self.threshold = None  # Will be set dynamically\n",
    "\n",
    "    def _build_autoencoder(self):\n",
    "        # Simplified architecture with better normalization\n",
    "        inputs = layers.Input(shape=(self.input_dim,))\n",
    "        x = layers.BatchNormalization()(inputs)\n",
    "        \n",
    "        # Encoder\n",
    "        x = layers.Dense(128, activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        x = layers.Dense(64, activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        \n",
    "        # Latent representation\n",
    "        encoded = layers.Dense(self.latent_dim, activation='relu')(x)\n",
    "        \n",
    "        # Decoder\n",
    "        x = layers.Dense(64, activation='relu')(encoded)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        x = layers.Dense(128, activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        \n",
    "        # Output\n",
    "        decoded = layers.Dense(self.input_dim, activation='linear')(x)\n",
    "        \n",
    "        # Model\n",
    "        autoencoder = keras.Model(inputs=inputs, outputs=decoded)\n",
    "        autoencoder.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=self.learning_rate),\n",
    "            loss='mean_squared_error'\n",
    "        )\n",
    "        return autoencoder\n",
    "\n",
    "    def train(self, X_train, X_val, epochs=50, batch_size=64):\n",
    "        # Add callbacks for better training\n",
    "        early_stopping = keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', \n",
    "            patience=10, \n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-6\n",
    "        )\n",
    "        \n",
    "        history = self.model.fit(\n",
    "            X_train, X_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_val, X_val),\n",
    "            callbacks=[early_stopping, reduce_lr],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Visualize training progress\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['loss'], label='Training Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Autoencoder Loss')\n",
    "        plt.legend()\n",
    "        plt.savefig('autoencoder_loss.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Set threshold based on reconstruction errors\n",
    "        self._set_dynamic_threshold(X_train)\n",
    "        \n",
    "        return history\n",
    "\n",
    "    def _set_dynamic_threshold(self, X_data):\n",
    "        # Calculate reconstruction errors\n",
    "        reconstructed = self.model.predict(X_data)\n",
    "        mse = np.mean(np.square(X_data - reconstructed), axis=1)\n",
    "        \n",
    "        # Set threshold using percentile instead of fixed value\n",
    "        # 95th percentile means 5% of data will be flagged as anomalies\n",
    "        self.threshold = np.percentile(mse, 95)\n",
    "        print(f\"Dynamic threshold set to: {self.threshold}\")\n",
    "        \n",
    "        # Visualize the error distribution\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(mse, bins=50)\n",
    "        plt.axvline(self.threshold, color='r', linestyle='--', label=f'Threshold: {self.threshold:.6f}')\n",
    "        plt.title('Reconstruction Error Distribution')\n",
    "        plt.xlabel('Mean Squared Error')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "        plt.savefig('error_distribution.png')\n",
    "        plt.close()\n",
    "\n",
    "    def detect_anomalies(self, X_data):\n",
    "        # Use the dynamic threshold set during training\n",
    "        if self.threshold is None:\n",
    "            raise ValueError(\"Model hasn't been trained yet. Call train() first.\")\n",
    "        \n",
    "        reconstructed = self.model.predict(X_data)\n",
    "        errors = np.mean(np.square(X_data - reconstructed), axis=1)\n",
    "        \n",
    "        # Return anomalies and their indices\n",
    "        anomaly_indices = np.where(errors > self.threshold)[0]\n",
    "        return X_data[anomaly_indices], anomaly_indices, errors\n",
    "\n",
    "    def get_encoded_features(self, X_data):\n",
    "        # Create a model that outputs the encoded features\n",
    "        encoder = keras.Model(inputs=self.model.input, \n",
    "                             outputs=self.model.layers[6].output)  # Layer index may need adjustment\n",
    "        return encoder.predict(X_data)\n",
    "\n",
    "\n",
    "class AdaptiveNIDSLayer2:\n",
    "    def __init__(self, input_dim, num_classes, seq_length=10):\n",
    "        self.input_dim = input_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.seq_length = seq_length\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        inputs = layers.Input(shape=(self.seq_length, self.input_dim))\n",
    "        \n",
    "        # CNN layers\n",
    "        x = layers.Conv1D(64, 3, activation='relu', padding='same')(inputs)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling1D(2)(x)\n",
    "        \n",
    "        x = layers.Conv1D(128, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        # BiLSTM layers\n",
    "        x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "        x = layers.Bidirectional(layers.LSTM(32))(x)\n",
    "        \n",
    "        # Dense layers\n",
    "        x = layers.Dense(64, activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        \n",
    "        outputs = layers.Dense(self.num_classes, activation='softmax')(x)\n",
    "        \n",
    "        model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(1e-3),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def train(self, X_train, y_train, X_val=None, y_val=None, epochs=50, batch_size=64):\n",
    "        callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=10,\n",
    "                restore_best_weights=True\n",
    "            ),\n",
    "            keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=5,\n",
    "                min_lr=1e-6\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # Use validation data if provided, otherwise use validation_split\n",
    "        if X_val is not None and y_val is not None:\n",
    "            history = self.model.fit(\n",
    "                X_train, y_train,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                validation_data=(X_val, y_val),\n",
    "                callbacks=callbacks\n",
    "            )\n",
    "        else:\n",
    "            history = self.model.fit(\n",
    "                X_train, y_train,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                validation_split=0.2,\n",
    "                callbacks=callbacks\n",
    "            )\n",
    "        \n",
    "        # Plot training metrics\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['loss'], label='Training Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Model Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.savefig('layer2_training.png')\n",
    "        plt.close()\n",
    "        \n",
    "        return history\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        y_pred = np.argmax(self.model.predict(X_test), axis=1)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        \n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        return report\n",
    "\n",
    "\n",
    "def preprocess_data(file_path):\n",
    "    # Load data\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate features and labels\n",
    "    X = df.drop(['Attack_label'], axis=1)\n",
    "    y = df['Attack_label']\n",
    "    \n",
    "    # Apply MinMaxScaler instead of RobustScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Save scaler for future use\n",
    "    joblib.dump(scaler, 'minmax_scaler.pkl')\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def create_sequences(data, labels, seq_length=10):\n",
    "    sequences, seq_labels = [], []\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    for i in range(len(data) - seq_length + 1):  # +1 to include the last sequence\n",
    "        sequences.append(data[i:i + seq_length])\n",
    "        seq_labels.append(labels[i + seq_length - 1])\n",
    "    \n",
    "    return np.array(sequences), np.array(seq_labels)\n",
    "\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_path = \"/Users/siddhantgond/Desktop/6THSEM/Project_Elective/Adaptive-Network-Intrusion-Detection-System/Implementaiton/training_dataset.csv\"\n",
    "    \n",
    "    # Preprocess data\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(dataset_path)\n",
    "    \n",
    "    # Layer 1: Autoencoder for anomaly detection\n",
    "    print(\"Training Layer 1: Autoencoder...\")\n",
    "    layer1 = EnhancedAdaptiveNIDS(input_dim=X_train.shape[1])\n",
    "    layer1.train(X_train, X_test)\n",
    "    \n",
    "    # Detect anomalies using trained autoencoder\n",
    "    anomalies, anomaly_indices, errors = layer1.detect_anomalies(X_test)\n",
    "    \n",
    "    # Get encoded features for anomalies\n",
    "    encoded_features = layer1.get_encoded_features(anomalies)\n",
    "    \n",
    "    # Get original labels for anomalies\n",
    "    original_df = pd.read_csv(dataset_path)\n",
    "    y_anomalies = y_test.iloc[anomaly_indices]\n",
    "    \n",
    "    # Create sequences for Layer 2\n",
    "    X_layer2, y_layer2 = create_sequences(encoded_features, y_anomalies, seq_length=10)\n",
    "    \n",
    "    # Split data for Layer 2\n",
    "    X_train_l2, X_test_l2, y_train_l2, y_test_l2 = train_test_split(\n",
    "        X_layer2, y_layer2, test_size=0.2, random_state=42, stratify=y_layer2\n",
    "    )\n",
    "    \n",
    "    # Layer 2: CNN-BiLSTM Classification\n",
    "    print(\"Training Layer 2: CNN-BiLSTM...\")\n",
    "    layer2 = AdaptiveNIDSLayer2(\n",
    "        input_dim=X_train_l2.shape[2],\n",
    "        num_classes=len(np.unique(y_train_l2)),\n",
    "        seq_length=10\n",
    "    )\n",
    "    layer2.train(X_train_l2, y_train_l2, X_test_l2, y_test_l2)\n",
    "    \n",
    "    # Evaluate Layer 2\n",
    "    layer2.evaluate(X_test_l2, y_test_l2)\n",
    "    \n",
    "    # Save models\n",
    "    layer1.model.save('autoencoder_model.h5')\n",
    "    layer2.model.save('cnn_bilstm_model.h5')\n",
    "    \n",
    "    print(f\"Total execution time: {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found, using CPU.\n",
      "Successfully loaded dataset with 71401 rows and 45 columns\n",
      "Class distribution before sampling:\n",
      "Attack_label\n",
      "1.0    85.994594\n",
      "0.0    14.005406\n",
      "Name: proportion, dtype: float64\n",
      "Saved scaler as minmax_scaler.pkl\n",
      "Applying SMOTE to balance classes...\n",
      "Class distribution after SMOTE:\n",
      "Attack_label\n",
      "1.0    50.0\n",
      "0.0    50.0\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Training Layer 1: Autoencoder...\n",
      "Epoch 1/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.9213 - val_loss: 0.0214 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.1639 - val_loss: 0.0087 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0643 - val_loss: 0.0061 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0247 - val_loss: 0.0044 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0101 - val_loss: 0.0029 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0058 - val_loss: 0.0018 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0043 - val_loss: 0.0012 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 8.3692e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0030 - val_loss: 6.3892e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 4.9283e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 4.2001e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0023 - val_loss: 3.7388e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0022 - val_loss: 3.3749e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 3.1902e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 2.8985e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 2.7757e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0019 - val_loss: 2.6998e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0019 - val_loss: 2.4401e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0018 - val_loss: 2.4396e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0018 - val_loss: 2.3420e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0017 - val_loss: 2.3565e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0017 - val_loss: 2.1685e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0017 - val_loss: 2.0064e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.9772e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.9340e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.9348e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.8273e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.7622e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.8252e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.7724e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.7126e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.7465e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.7173e-04 - learning_rate: 1.2500e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0015 - val_loss: 1.6843e-04 - learning_rate: 1.2500e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.6676e-04 - learning_rate: 1.2500e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.7068e-04 - learning_rate: 1.2500e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0015 - val_loss: 1.7057e-04 - learning_rate: 1.2500e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0015 - val_loss: 1.6805e-04 - learning_rate: 1.2500e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0015 - val_loss: 1.6727e-04 - learning_rate: 1.2500e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0015 - val_loss: 1.6333e-04 - learning_rate: 6.2500e-06\n",
      "Epoch 41/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0015 - val_loss: 1.6458e-04 - learning_rate: 6.2500e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0015 - val_loss: 1.6339e-04 - learning_rate: 6.2500e-06\n",
      "Epoch 43/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0015 - val_loss: 1.6548e-04 - learning_rate: 6.2500e-06\n",
      "Epoch 44/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0015 - val_loss: 1.6419e-04 - learning_rate: 6.2500e-06\n",
      "Epoch 45/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0015 - val_loss: 1.6209e-04 - learning_rate: 3.1250e-06\n",
      "Epoch 46/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0015 - val_loss: 1.6311e-04 - learning_rate: 3.1250e-06\n",
      "Epoch 47/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0015 - val_loss: 1.6547e-04 - learning_rate: 3.1250e-06\n",
      "Epoch 48/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0015 - val_loss: 1.6286e-04 - learning_rate: 3.1250e-06\n",
      "Epoch 49/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0015 - val_loss: 1.6106e-04 - learning_rate: 3.1250e-06\n",
      "Epoch 50/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0015 - val_loss: 1.5900e-04 - learning_rate: 1.5625e-06\n",
      "\u001b[1m3070/3070\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 417us/step\n",
      "Dynamic threshold set to: 0.00039365281318139145\n",
      "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 557\u001b[39m\n\u001b[32m    554\u001b[39m layer1.train(X_train, X_test, epochs=\u001b[32m50\u001b[39m, batch_size=\u001b[32m64\u001b[39m)\n\u001b[32m    556\u001b[39m \u001b[38;5;66;03m# Detect anomalies using trained autoencoder\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m anomalies, anomaly_indices, errors, confidence = layer1.detect_anomalies(X_test)\n\u001b[32m    559\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDetected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(anomaly_indices)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m anomalies out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_test)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m test samples.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    560\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAnomaly detection rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(anomaly_indices)/\u001b[38;5;28mlen\u001b[39m(X_test)*\u001b[32m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os\n",
    "from scipy import stats\n",
    "\n",
    "start_time = time.time()\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "class EnhancedAdaptiveNIDS:\n",
    "    def __init__(self, input_dim, latent_dim=32, learning_rate=1e-4):  # Increased latent_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = self._build_autoencoder()\n",
    "        self.threshold = None  # Will be set dynamically\n",
    "\n",
    "    def _build_autoencoder(self):\n",
    "        # Simplified architecture with better normalization\n",
    "        inputs = layers.Input(shape=(self.input_dim,))\n",
    "        x = layers.BatchNormalization()(inputs)\n",
    "        \n",
    "        # Encoder\n",
    "        x = layers.Dense(128, activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        x = layers.Dense(64, activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        \n",
    "        # Latent representation\n",
    "        encoded = layers.Dense(self.latent_dim, activation='relu')(x)\n",
    "        \n",
    "        # Decoder\n",
    "        x = layers.Dense(64, activation='relu')(encoded)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        x = layers.Dense(128, activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        \n",
    "        # Output\n",
    "        decoded = layers.Dense(self.input_dim, activation='linear')(x)\n",
    "        \n",
    "        # Model\n",
    "        autoencoder = keras.Model(inputs=inputs, outputs=decoded)\n",
    "        autoencoder.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=self.learning_rate),\n",
    "            loss='mean_squared_error'\n",
    "        )\n",
    "        return autoencoder\n",
    "\n",
    "    def train(self, X_train, X_val, epochs=50, batch_size=64):\n",
    "        # Add callbacks for better training\n",
    "        early_stopping = keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', \n",
    "            patience=10, \n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-6\n",
    "        )\n",
    "        \n",
    "        history = self.model.fit(\n",
    "            X_train, X_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_val, X_val),\n",
    "            callbacks=[early_stopping, reduce_lr],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Visualize training progress\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['loss'], label='Training Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Autoencoder Loss')\n",
    "        plt.legend()\n",
    "        plt.savefig('autoencoder_loss.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Set threshold based on reconstruction errors\n",
    "        self._set_dynamic_threshold(X_train)\n",
    "        \n",
    "        return history\n",
    "\n",
    "    def _set_dynamic_threshold(self, X_data):\n",
    "        # Calculate reconstruction errors\n",
    "        reconstructed = self.model.predict(X_data)\n",
    "        mse = np.mean(np.square(X_data - reconstructed), axis=1)\n",
    "        \n",
    "        # Set threshold using percentile instead of fixed value\n",
    "        # 95th percentile means 5% of data will be flagged as anomalies\n",
    "        self.threshold = np.percentile(mse, 95)\n",
    "        print(f\"Dynamic threshold set to: {self.threshold}\")\n",
    "        \n",
    "        # Visualize the error distribution\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(mse, bins=50)\n",
    "        plt.axvline(self.threshold, color='r', linestyle='--', label=f'Threshold: {self.threshold:.6f}')\n",
    "        plt.title('Reconstruction Error Distribution')\n",
    "        plt.xlabel('Mean Squared Error')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "        plt.savefig('error_distribution.png')\n",
    "        plt.close()\n",
    "\n",
    "    def detect_anomalies(self, X_data):\n",
    "        # Use the dynamic threshold set during training\n",
    "        if self.threshold is None:\n",
    "            raise ValueError(\"Model hasn't been trained yet. Call train() first.\")\n",
    "        \n",
    "        reconstructed = self.model.predict(X_data)\n",
    "        errors = np.mean(np.square(X_data - reconstructed), axis=1)\n",
    "        \n",
    "        # Return anomalies and their indices\n",
    "        anomaly_indices = np.where(errors > self.threshold)[0]\n",
    "        return X_data[anomaly_indices], anomaly_indices, errors\n",
    "\n",
    "    def get_encoded_features(self, X_data):\n",
    "        # Create a model that outputs the encoded features\n",
    "        encoder = keras.Model(inputs=self.model.input, \n",
    "                             outputs=self.model.layers[6].output)  # Layer index may need adjustment\n",
    "        return encoder.predict(X_data)\n",
    "\n",
    "\n",
    "class AdaptiveNIDSLayer2:\n",
    "    def __init__(self, input_dim, num_classes, seq_length=10):\n",
    "        self.input_dim = input_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.seq_length = seq_length\n",
    "        self.model = self._build_model()\n",
    "        self.class_weights = None  # For handling class imbalance\n",
    "\n",
    "    def _build_model(self):\n",
    "        inputs = layers.Input(shape=(self.seq_length, self.input_dim))\n",
    "        \n",
    "        # CNN layers with L2 regularization\n",
    "        x = layers.Conv1D(64, 3, activation='relu', padding='same',\n",
    "                         kernel_regularizer=regularizers.l2(1e-5))(inputs)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling1D(2)(x)\n",
    "        \n",
    "        x = layers.Conv1D(128, 3, activation='relu', padding='same',\n",
    "                         kernel_regularizer=regularizers.l2(1e-5))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling1D(2)(x)  # Added another pooling layer\n",
    "        \n",
    "        # Add residual connection\n",
    "        shortcut = layers.Conv1D(128, 1)(inputs)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "        shortcut = layers.MaxPooling1D(4)(shortcut)  # Match the shape after two MaxPooling1D(2)\n",
    "        x = layers.add([x, shortcut])\n",
    "        x = layers.Activation('relu')(x)\n",
    "        \n",
    "        # BiLSTM layers with increased complexity\n",
    "        x = layers.Bidirectional(layers.LSTM(64, return_sequences=True,\n",
    "                                           kernel_regularizer=regularizers.l2(1e-5)))(x)\n",
    "        x = layers.Dropout(0.4)(x)  # Increased dropout\n",
    "        x = layers.Bidirectional(layers.LSTM(32,\n",
    "                                           kernel_regularizer=regularizers.l2(1e-5)))(x)\n",
    "        \n",
    "        # Attention mechanism\n",
    "        attention = layers.Dense(1, activation='tanh')(x)\n",
    "        attention = layers.Flatten()(attention)\n",
    "        attention_weights = layers.Activation('softmax')(attention)\n",
    "        context_vector = layers.Dot(axes=1)([x, attention_weights])\n",
    "        \n",
    "        # Dense layers with residual connections\n",
    "        dense1 = layers.Dense(64, activation='relu',\n",
    "                             kernel_regularizer=regularizers.l2(1e-5))(context_vector)\n",
    "        dense1 = layers.BatchNormalization()(dense1)\n",
    "        dense1 = layers.Dropout(0.4)(dense1)\n",
    "        \n",
    "        # Output with temperature scaling for better calibration\n",
    "        logits = layers.Dense(self.num_classes)(dense1)\n",
    "        temperature = 1.5  # Temperature parameter (>1 makes predictions smoother)\n",
    "        scaled_logits = layers.Lambda(lambda x: x / temperature)(logits)\n",
    "        outputs = layers.Activation('softmax')(scaled_logits)\n",
    "        \n",
    "        model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        \n",
    "        # Use weighted categorical crossentropy for class imbalance\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(1e-3),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def compute_class_weights(self, y_train):\n",
    "        # Calculate class weights to handle imbalance\n",
    "        unique_classes = np.unique(y_train)\n",
    "        class_counts = np.bincount(y_train)\n",
    "        total = len(y_train)\n",
    "        \n",
    "        # Create class weights dictionary\n",
    "        self.class_weights = {i: total / (len(unique_classes) * count) \n",
    "                             for i, count in enumerate(class_counts)}\n",
    "        print(\"Class weights:\", self.class_weights)\n",
    "        return self.class_weights\n",
    "\n",
    "    def train(self, X_train, y_train, X_val=None, y_val=None, epochs=50, batch_size=64):\n",
    "        # Compute class weights if not already done\n",
    "        if self.class_weights is None:\n",
    "            self.compute_class_weights(y_train)\n",
    "        \n",
    "        callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=15,  # Increased patience\n",
    "                restore_best_weights=True\n",
    "            ),\n",
    "            keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.2,  # More aggressive reduction\n",
    "                patience=7,\n",
    "                min_lr=1e-7\n",
    "            ),\n",
    "            # Add model checkpoint to save best model\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                'best_layer2_model.h5',\n",
    "                save_best_only=True,\n",
    "                monitor='val_accuracy',\n",
    "                mode='max'\n",
    "            ),\n",
    "            # Add TensorBoard callback\n",
    "            keras.callbacks.TensorBoard(\n",
    "                log_dir=f'./logs/layer2_{time.strftime(\"%Y%m%d-%H%M%S\")}',\n",
    "                histogram_freq=1\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # Use validation data if provided, otherwise use validation_split\n",
    "        if X_val is not None and y_val is not None:\n",
    "            history = self.model.fit(\n",
    "                X_train, y_train,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                validation_data=(X_val, y_val),\n",
    "                callbacks=callbacks,\n",
    "                class_weight=self.class_weights  # Use class weights\n",
    "            )\n",
    "        else:\n",
    "            history = self.model.fit(\n",
    "                X_train, y_train,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                validation_split=0.2,\n",
    "                callbacks=callbacks,\n",
    "                class_weight=self.class_weights\n",
    "            )\n",
    "        \n",
    "        # Plot training metrics\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Plot losses\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.plot(history.history['loss'], label='Training Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Model Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot accuracy\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot learning rate if available\n",
    "        if 'lr' in history.history:\n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.plot(history.history['lr'], label='Learning Rate')\n",
    "            plt.title('Learning Rate')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Learning Rate')\n",
    "            plt.yscale('log')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('layer2_training_metrics.png')\n",
    "        plt.close()\n",
    "        \n",
    "        return history\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        # Evaluate the model\n",
    "        test_loss, test_accuracy = self.model.evaluate(X_test, y_test, verbose=1)\n",
    "        print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "        print(f\"Test loss: {test_loss:.4f}\")\n",
    "        \n",
    "        # Generate predictions\n",
    "        y_pred_probs = self.model.predict(X_test)\n",
    "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "        \n",
    "        # Generate classification report\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        # Create confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                   xticklabels=np.unique(y_test),\n",
    "                   yticklabels=np.unique(y_test))\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.savefig('confusion_matrix.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Plot ROC curve for multi-class\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        # One-vs-Rest ROC curves\n",
    "        if self.num_classes > 2:\n",
    "            y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n",
    "            fpr = dict()\n",
    "            tpr = dict()\n",
    "            roc_auc = dict()\n",
    "            \n",
    "            for i in range(self.num_classes):\n",
    "                fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_probs[:, i])\n",
    "                roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "                plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
    "        else:\n",
    "            # Binary classification\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_pred_probs[:, 1])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "        \n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.savefig('roc_curve.png')\n",
    "        plt.close()\n",
    "        \n",
    "        return report, y_pred, y_pred_probs\n",
    "\n",
    "    def save_model(self, filepath):\n",
    "        \"\"\"Save the model to disk\"\"\"\n",
    "        self.model.save(filepath)\n",
    "        print(f\"Model saved to {filepath}\")\n",
    "        \n",
    "    def load_model(self, filepath):\n",
    "        \"\"\"Load a saved model from disk\"\"\"\n",
    "        self.model = keras.models.load_model(filepath)\n",
    "        print(f\"Model loaded from {filepath}\")\n",
    "        return self.model\n",
    "\n",
    "\n",
    "def preprocess_data(file_path, test_size=0.2, random_state=42, use_smote=True, use_standard_scaler=False):\n",
    "    \"\"\"\n",
    "    Enhanced preprocessing function with SMOTE option and scaler choice\n",
    "    \"\"\"\n",
    "    # Load data with error handling\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Successfully loaded dataset with {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Check for missing values and handle them\n",
    "    if df.isnull().sum().sum() > 0:\n",
    "        print(f\"Found {df.isnull().sum().sum()} missing values. Filling with appropriate methods.\")\n",
    "        numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "        categorical_cols = df.select_dtypes(exclude=['number']).columns\n",
    "        \n",
    "        # Fill numeric with median and categorical with mode\n",
    "        for col in numeric_cols:\n",
    "            if df[col].isnull().sum() > 0:\n",
    "                df[col] = df[col].fillna(df[col].median())\n",
    "        \n",
    "        for col in categorical_cols:\n",
    "            if df[col].isnull().sum() > 0:\n",
    "                df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    \n",
    "    # Check for and handle outliers using IQR method\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    for col in numeric_cols:\n",
    "        if col != 'Attack_label':  # Don't process the target variable\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            # Cap outliers rather than removing them\n",
    "            df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])\n",
    "            df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])\n",
    "    \n",
    "    # Separate features and labels\n",
    "    X = df.drop(['Attack_label'], axis=1)\n",
    "    y = df['Attack_label']\n",
    "    \n",
    "    # Print class distribution\n",
    "    print(\"Class distribution before sampling:\")\n",
    "    print(y.value_counts(normalize=True) * 100)\n",
    "    \n",
    "    # Apply feature scaling\n",
    "    if use_standard_scaler:\n",
    "        scaler = StandardScaler()  # Standardization (mean=0, std=1)\n",
    "        scaler_filename = 'standard_scaler.pkl'\n",
    "    else:\n",
    "        scaler = MinMaxScaler()  # Normalization (0-1 range)\n",
    "        scaler_filename = 'minmax_scaler.pkl'\n",
    "    \n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Save scaler for inference\n",
    "    joblib.dump(scaler, scaler_filename)\n",
    "    print(f\"Saved scaler as {scaler_filename}\")\n",
    "    \n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Apply SMOTE for handling class imbalance (only on training data)\n",
    "    if use_smote:\n",
    "        print(\"Applying SMOTE to balance classes...\")\n",
    "        smote = SMOTE(random_state=random_state)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "        print(\"Class distribution after SMOTE:\")\n",
    "        print(pd.Series(y_train).value_counts(normalize=True) * 100)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler\n",
    "\n",
    "\n",
    "def create_sequences(data, labels, seq_length=10, stride=1):\n",
    "    \"\"\"\n",
    "    Enhanced sequence creation with stride option for better coverage\n",
    "    \"\"\"\n",
    "    sequences, seq_labels = [], []\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    for i in range(0, len(data) - seq_length + 1, stride):\n",
    "        sequences.append(data[i:i + seq_length])\n",
    "        seq_labels.append(labels[i + seq_length - 1])\n",
    "    \n",
    "    return np.array(sequences), np.array(seq_labels)\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, class_names=None):\n",
    "    \"\"\"\n",
    "    Comprehensive model evaluation function\n",
    "    \"\"\"\n",
    "    # Get predictions\n",
    "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "    \n",
    "    # Generate classification report\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names if class_names else None,\n",
    "                yticklabels=class_names if class_names else None)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Calculate and plot ROC curves if binary classification\n",
    "    if len(np.unique(y_test)) == 2:\n",
    "        from sklearn.metrics import roc_curve, auc\n",
    "        y_pred_prob = model.predict(X_test)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.3f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig('roc_curve.png')\n",
    "        plt.close()\n",
    "    \n",
    "    return report\n",
    "\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Create logs and model directories if they don't exist\n",
    "    os.makedirs('./logs', exist_ok=True)\n",
    "    os.makedirs('./models', exist_ok=True)\n",
    "    \n",
    "    # Configure GPU for TensorFlow (if available)\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"Using GPU: {gpus}\")\n",
    "    else:\n",
    "        print(\"No GPU found, using CPU.\")\n",
    "    \n",
    "    # Set random seeds for reproducibility\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    # Record start time\n",
    "    start_time = time.time()\n",
    "    tf.get_logger().setLevel('ERROR')\n",
    "    \n",
    "    # Dataset path - use relative path for better portability\n",
    "    dataset_path = \"/Users/siddhantgond/Desktop/6THSEM/Project_Elective/Adaptive-Network-Intrusion-Detection-System/Implementaiton/training_dataset.csv\"\n",
    "    \n",
    "    # Preprocess data with SMOTE and MinMaxScaler\n",
    "    X_train, X_test, y_train, y_test, scaler = preprocess_data(\n",
    "        dataset_path, test_size=0.2, use_smote=True, use_standard_scaler=False\n",
    "    )\n",
    "    \n",
    "    # Layer 1: Autoencoder for anomaly detection\n",
    "    print(\"\\nTraining Layer 1: Autoencoder...\")\n",
    "    layer1 = EnhancedAdaptiveNIDS(input_dim=X_train.shape[1])\n",
    "    layer1.train(X_train, X_test, epochs=50, batch_size=64)\n",
    "    \n",
    "    # Detect anomalies using trained autoencoder\n",
    "    anomalies, anomaly_indices, errors, confidence = layer1.detect_anomalies(X_test)\n",
    "    \n",
    "    print(f\"Detected {len(anomaly_indices)} anomalies out of {len(X_test)} test samples.\")\n",
    "    print(f\"Anomaly detection rate: {len(anomaly_indices)/len(X_test)*100:.2f}%\")\n",
    "    \n",
    "    # Get encoded features for anomalies\n",
    "    encoded_features = layer1.get_encoded_features(anomalies)\n",
    "    \n",
    "    # If anomalies array is empty, use a subset of the data\n",
    "    if len(anomalies) == 0:\n",
    "        print(\"No anomalies detected. Using top 10% of highest error samples.\")\n",
    "        top_n = int(len(X_test) * 0.1)\n",
    "        sorted_indices = np.argsort(errors)[-top_n:]\n",
    "        anomalies = X_test[sorted_indices]\n",
    "        anomaly_indices = sorted_indices\n",
    "        encoded_features = layer1.get_encoded_features(anomalies)\n",
    "    \n",
    "    # Get original labels for anomalies\n",
    "    if isinstance(y_test, pd.Series):\n",
    "        y_anomalies = y_test.iloc[anomaly_indices]\n",
    "    else:\n",
    "        y_anomalies = y_test[anomaly_indices]\n",
    "    \n",
    "    # Create sequences for Layer 2 with stride=2 for better coverage\n",
    "    X_layer2, y_layer2 = create_sequences(encoded_features, y_anomalies, seq_length=10, stride=2)\n",
    "    \n",
    "    # Split data for Layer 2\n",
    "    if len(np.unique(y_layer2)) > 1:  # Only stratify if multiple classes\n",
    "        X_train_l2, X_test_l2, y_train_l2, y_test_l2 = train_test_split(\n",
    "            X_layer2, y_layer2, test_size=0.2, random_state=42, stratify=y_layer2\n",
    "        )\n",
    "    else:\n",
    "        X_train_l2, X_test_l2, y_train_l2, y_test_l2 = train_test_split(\n",
    "            X_layer2, y_layer2, test_size=0.2, random_state=42\n",
    "        )\n",
    "    \n",
    "    # Layer 2: CNN-BiLSTM Classification\n",
    "    print(\"\\nTraining Layer 2: CNN-BiLSTM...\")\n",
    "    layer2 = AdaptiveNIDSLayer2(\n",
    "        input_dim=X_train_l2.shape[2],\n",
    "        num_classes=len(np.unique(y_train_l2)),\n",
    "        seq_length=10\n",
    "    )\n",
    "    layer2.train(X_train_l2, y_train_l2, X_test_l2, y_test_l2, epochs=50, batch_size=32)\n",
    "    \n",
    "    # Evaluate Layer 2 with comprehensive metrics\n",
    "    class_names = [f\"Class {i}\" for i in range(len(np.unique(y_train_l2)))]\n",
    "    evaluate_model(layer2.model, X_test_l2, y_test_l2, class_names)\n",
    "    \n",
    "    # Save models with timestamp\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    layer1.model.save(f'models/autoencoder_model_{timestamp}.h5')\n",
    "    layer2.model.save(f'models/cnn_bilstm_model_{timestamp}.h5')\n",
    "    \n",
    "    # Save model architecture as image\n",
    "    try:\n",
    "        tf.keras.utils.plot_model(layer1.model, to_file='models/autoencoder_architecture.png', \n",
    "                                  show_shapes=True, show_layer_names=True)\n",
    "        tf.keras.utils.plot_model(layer2.model, to_file='models/cnn_bilstm_architecture.png', \n",
    "                                  show_shapes=True, show_layer_names=True)\n",
    "    except:\n",
    "        print(\"Couldn't save model architecture images. Make sure pydot is installed.\")\n",
    "    \n",
    "    # Save training configuration\n",
    "    config = {\n",
    "        'dataset_path': dataset_path,\n",
    "        'preprocessing': {\n",
    "            'use_smote': True,\n",
    "            'use_standard_scaler': False,\n",
    "            'test_size': 0.2\n",
    "        },\n",
    "        'layer1': {\n",
    "            'latent_dim': layer1.latent_dim,\n",
    "            'learning_rate': layer1.learning_rate,\n",
    "            'threshold': layer1.threshold\n",
    "        },\n",
    "        'layer2': {\n",
    "            'seq_length': layer2.seq_length,\n",
    "            'class_weights': layer2.class_weights\n",
    "        },\n",
    "        'timestamp': timestamp\n",
    "    }\n",
    "    \n",
    "    with open(f'models/training_config_{timestamp}.json', 'w') as f:\n",
    "        import json\n",
    "        json.dump(config, f, indent=4)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"\\nTotal execution time: {elapsed_time:.2f} seconds ({elapsed_time/60:.2f} minutes)\")\n",
    "    print(f\"Models saved with timestamp: {timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found, using CPU.\n",
      "Successfully loaded dataset with 71401 rows and 45 columns\n",
      "Class distribution before sampling:\n",
      "Attack_label\n",
      "1.0    85.994594\n",
      "0.0    14.005406\n",
      "Name: proportion, dtype: float64\n",
      "Saved scaler as minmax_scaler.pkl\n",
      "Applying SMOTE to balance classes...\n",
      "Class distribution after SMOTE:\n",
      "Attack_label\n",
      "1.0    50.0\n",
      "0.0    50.0\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Training Layer 1: Autoencoder...\n",
      "Epoch 1/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.9410 - val_loss: 0.0245 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.1608 - val_loss: 0.0090 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0600 - val_loss: 0.0060 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0219 - val_loss: 0.0043 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0088 - val_loss: 0.0030 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0055 - val_loss: 0.0019 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0042 - val_loss: 0.0012 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 7.2933e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0029 - val_loss: 5.4633e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 4.3824e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0024 - val_loss: 3.8707e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 3.4877e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0022 - val_loss: 3.2768e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 3.0339e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 2.9698e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0019 - val_loss: 2.6802e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0019 - val_loss: 2.6191e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0018 - val_loss: 2.4749e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0018 - val_loss: 2.2814e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0018 - val_loss: 2.2941e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0018 - val_loss: 2.2247e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0018 - val_loss: 2.1595e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0017 - val_loss: 2.0567e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0017 - val_loss: 2.0623e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0017 - val_loss: 2.0174e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0017 - val_loss: 2.0039e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0017 - val_loss: 1.9360e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0017 - val_loss: 1.8966e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0017 - val_loss: 1.8638e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0017 - val_loss: 1.8256e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.8648e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.8066e-04 - learning_rate: 1.2500e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.7796e-04 - learning_rate: 1.2500e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.7793e-04 - learning_rate: 1.2500e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.8113e-04 - learning_rate: 1.2500e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.7341e-04 - learning_rate: 1.2500e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.7538e-04 - learning_rate: 6.2500e-06\n",
      "Epoch 38/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.7539e-04 - learning_rate: 6.2500e-06\n",
      "Epoch 39/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.7568e-04 - learning_rate: 6.2500e-06\n",
      "Epoch 40/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.7615e-04 - learning_rate: 6.2500e-06\n",
      "Epoch 41/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.7260e-04 - learning_rate: 6.2500e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.7144e-04 - learning_rate: 3.1250e-06\n",
      "Epoch 43/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.7168e-04 - learning_rate: 3.1250e-06\n",
      "Epoch 44/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.6970e-04 - learning_rate: 3.1250e-06\n",
      "Epoch 45/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.7247e-04 - learning_rate: 3.1250e-06\n",
      "Epoch 46/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.7364e-04 - learning_rate: 3.1250e-06\n",
      "Epoch 47/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.7155e-04 - learning_rate: 1.5625e-06\n",
      "Epoch 48/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.7224e-04 - learning_rate: 1.5625e-06\n",
      "Epoch 49/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.7048e-04 - learning_rate: 1.5625e-06\n",
      "Epoch 50/50\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 1.7272e-04 - learning_rate: 1.5625e-06\n",
      "\u001b[1m3070/3070\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326us/step\n",
      "Dynamic threshold set to: 0.00040043295517710857\n",
      "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step\n",
      "Detected 1235 anomalies out of 14281 test samples.\n",
      "Anomaly detection rate: 8.65%\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\n",
      "Training Layer 2: CNN-BiLSTM...\n",
      "Class weights: {0: 122.5, 1: 0.5020491803278688}\n",
      "Epoch 1/50\n",
      "\u001b[1m11/16\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5191 - loss: 0.5831 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.5135 - loss: 0.7923 - val_accuracy: 0.9919 - val_loss: 0.6466 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5214 - loss: 0.4763 - val_accuracy: 0.9919 - val_loss: 0.6226 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5322 - loss: 0.4324 - val_accuracy: 0.9919 - val_loss: 0.5955 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5517 - loss: 0.4278 - val_accuracy: 0.9919 - val_loss: 0.5428 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6052 - loss: 0.3804 - val_accuracy: 0.9919 - val_loss: 0.5023 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5804 - loss: 0.3774 - val_accuracy: 0.9919 - val_loss: 0.4752 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6122 - loss: 0.3526 - val_accuracy: 0.9919 - val_loss: 0.4405 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6719 - loss: 0.3199 - val_accuracy: 0.9919 - val_loss: 0.4232 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7204 - loss: 0.3088 - val_accuracy: 0.9919 - val_loss: 0.4046 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7314 - loss: 0.3277 - val_accuracy: 0.9919 - val_loss: 0.3655 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7554 - loss: 0.2920 - val_accuracy: 0.9919 - val_loss: 0.3173 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8045 - loss: 0.2653 - val_accuracy: 0.9919 - val_loss: 0.2897 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8095 - loss: 0.2496 - val_accuracy: 0.9919 - val_loss: 0.2779 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8526 - loss: 0.2156 - val_accuracy: 0.9919 - val_loss: 0.2616 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9068 - loss: 0.1963 - val_accuracy: 0.9919 - val_loss: 0.2389 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9395 - loss: 0.1720 - val_accuracy: 0.9919 - val_loss: 0.2082 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9321 - loss: 0.1591 - val_accuracy: 0.9919 - val_loss: 0.1911 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9711 - loss: 0.1406 - val_accuracy: 0.9919 - val_loss: 0.1643 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9562 - loss: 0.1321 - val_accuracy: 0.9919 - val_loss: 0.1467 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9640 - loss: 0.1204 - val_accuracy: 0.9919 - val_loss: 0.1359 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9755 - loss: 0.1021 - val_accuracy: 0.9919 - val_loss: 0.1269 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9892 - loss: 0.0918 - val_accuracy: 0.9919 - val_loss: 0.1177 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0763 - val_accuracy: 0.9919 - val_loss: 0.1105 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9982 - loss: 0.0702 - val_accuracy: 0.9919 - val_loss: 0.0977 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9982 - loss: 0.0670 - val_accuracy: 0.9919 - val_loss: 0.0830 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9937 - loss: 0.0627 - val_accuracy: 0.9919 - val_loss: 0.0791 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9934 - loss: 0.0620 - val_accuracy: 0.9919 - val_loss: 0.0770 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0496 - val_accuracy: 0.9919 - val_loss: 0.0743 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0463 - val_accuracy: 0.9919 - val_loss: 0.0699 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0417 - val_accuracy: 0.9919 - val_loss: 0.0681 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0407 - val_accuracy: 0.9919 - val_loss: 0.0665 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0370 - val_accuracy: 0.9919 - val_loss: 0.0654 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0358 - val_accuracy: 0.9919 - val_loss: 0.0642 - learning_rate: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0326 - val_accuracy: 0.9919 - val_loss: 0.0627 - learning_rate: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0329 - val_accuracy: 0.9919 - val_loss: 0.0616 - learning_rate: 0.0010\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0376 - val_accuracy: 0.9919 - val_loss: 0.0579 - learning_rate: 0.0010\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0294 - val_accuracy: 0.9919 - val_loss: 0.0568 - learning_rate: 0.0010\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0267 - val_accuracy: 0.9919 - val_loss: 0.0561 - learning_rate: 0.0010\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0278 - val_accuracy: 0.9919 - val_loss: 0.0556 - learning_rate: 0.0010\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0255 - val_accuracy: 0.9919 - val_loss: 0.0554 - learning_rate: 0.0010\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0236 - val_accuracy: 0.9919 - val_loss: 0.0552 - learning_rate: 0.0010\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9982 - loss: 0.0224 - val_accuracy: 0.9919 - val_loss: 0.0552 - learning_rate: 0.0010\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0214 - val_accuracy: 0.9919 - val_loss: 0.0551 - learning_rate: 0.0010\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0203 - val_accuracy: 0.9919 - val_loss: 0.0550 - learning_rate: 0.0010\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0198 - val_accuracy: 0.9919 - val_loss: 0.0548 - learning_rate: 0.0010\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0193 - val_accuracy: 0.9919 - val_loss: 0.0546 - learning_rate: 0.0010\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0190 - val_accuracy: 0.9919 - val_loss: 0.0546 - learning_rate: 0.0010\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0178 - val_accuracy: 0.9919 - val_loss: 0.0544 - learning_rate: 0.0010\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0168 - val_accuracy: 0.9919 - val_loss: 0.0542 - learning_rate: 0.0010\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0176 - val_accuracy: 0.9919 - val_loss: 0.0541 - learning_rate: 0.0010\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         1\n",
      "         1.0       0.99      1.00      1.00       122\n",
      "\n",
      "    accuracy                           0.99       123\n",
      "   macro avg       0.50      0.50      0.50       123\n",
      "weighted avg       0.98      0.99      0.99       123\n",
      "\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n",
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n",
      "\n",
      "Total execution time: 125.78 seconds (2.10 minutes)\n",
      "Models saved with timestamp: 20250316-223015\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os\n",
    "from scipy import stats\n",
    "\n",
    "start_time = time.time()\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "class EnhancedAdaptiveNIDS:\n",
    "    def __init__(self, input_dim, latent_dim=32, learning_rate=1e-4):  # Increased latent_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = self._build_autoencoder()\n",
    "        self.threshold = None  # Will be set dynamically\n",
    "\n",
    "    def _build_autoencoder(self):\n",
    "        # Simplified architecture with better normalization\n",
    "        inputs = layers.Input(shape=(self.input_dim,))\n",
    "        x = layers.BatchNormalization()(inputs)\n",
    "        \n",
    "        # Encoder\n",
    "        x = layers.Dense(128, activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        x = layers.Dense(64, activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        \n",
    "        # Latent representation\n",
    "        encoded = layers.Dense(self.latent_dim, activation='relu')(x)\n",
    "        \n",
    "        # Decoder\n",
    "        x = layers.Dense(64, activation='relu')(encoded)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        x = layers.Dense(128, activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        \n",
    "        # Output\n",
    "        decoded = layers.Dense(self.input_dim, activation='linear')(x)\n",
    "        \n",
    "        # Model\n",
    "        autoencoder = keras.Model(inputs=inputs, outputs=decoded)\n",
    "        autoencoder.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=self.learning_rate),\n",
    "            loss='mean_squared_error'\n",
    "        )\n",
    "        return autoencoder\n",
    "\n",
    "    def train(self, X_train, X_val, epochs=50, batch_size=64):\n",
    "        # Add callbacks for better training\n",
    "        early_stopping = keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', \n",
    "            patience=10, \n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-6\n",
    "        )\n",
    "        \n",
    "        history = self.model.fit(\n",
    "            X_train, X_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_val, X_val),\n",
    "            callbacks=[early_stopping, reduce_lr],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Visualize training progress\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['loss'], label='Training Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Autoencoder Loss')\n",
    "        plt.legend()\n",
    "        plt.savefig('autoencoder_loss.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Set threshold based on reconstruction errors\n",
    "        self._set_dynamic_threshold(X_train)\n",
    "        \n",
    "        return history\n",
    "\n",
    "    def _set_dynamic_threshold(self, X_data):\n",
    "        # Calculate reconstruction errors\n",
    "        reconstructed = self.model.predict(X_data)\n",
    "        mse = np.mean(np.square(X_data - reconstructed), axis=1)\n",
    "        \n",
    "        # Set threshold using percentile instead of fixed value\n",
    "        # 95th percentile means 5% of data will be flagged as anomalies\n",
    "        self.threshold = np.percentile(mse, 95)\n",
    "        print(f\"Dynamic threshold set to: {self.threshold}\")\n",
    "        \n",
    "        # Visualize the error distribution\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(mse, bins=50)\n",
    "        plt.axvline(self.threshold, color='r', linestyle='--', label=f'Threshold: {self.threshold:.6f}')\n",
    "        plt.title('Reconstruction Error Distribution')\n",
    "        plt.xlabel('Mean Squared Error')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "        plt.savefig('error_distribution.png')\n",
    "        plt.close()\n",
    "\n",
    "    def detect_anomalies(self, X_data):\n",
    "        if self.threshold is None:\n",
    "            raise ValueError(\"Model hasn't been trained yet. Call train() first.\")\n",
    "        \n",
    "        reconstructed = self.model.predict(X_data)\n",
    "        errors = np.mean(np.square(X_data - reconstructed), axis=1)\n",
    "        \n",
    "        anomaly_indices = np.where(errors > self.threshold)[0]\n",
    "        \n",
    "        # Define confidence as normalized error (optional)\n",
    "        confidence = errors / np.max(errors) if len(errors) > 0 else np.array([])\n",
    "\n",
    "        return X_data[anomaly_indices], anomaly_indices, errors, confidence\n",
    "\n",
    "\n",
    "    def get_encoded_features(self, X_data):\n",
    "        # Create a model that outputs the encoded features\n",
    "        encoder = keras.Model(inputs=self.model.input, \n",
    "                             outputs=self.model.layers[6].output)  # Layer index may need adjustment\n",
    "        return encoder.predict(X_data)\n",
    "\n",
    "\n",
    "class AdaptiveNIDSLayer2:\n",
    "    def __init__(self, input_dim, num_classes, seq_length=10):\n",
    "        self.input_dim = input_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.seq_length = seq_length\n",
    "        self.model = self._build_model()\n",
    "        self.class_weights = None  # For handling class imbalance\n",
    "\n",
    "    # Fix for the error in AdaptiveNIDSLayer2._build_model\n",
    "# The issue is with the Dot layer - the dimensions don't match between x and attention_weights\n",
    "\n",
    "    def _build_model(self):\n",
    "        from tensorflow.keras import layers, regularizers\n",
    "        \n",
    "        inputs = layers.Input(shape=(self.seq_length, self.input_dim))\n",
    "        \n",
    "        # CNN layers with L2 regularization\n",
    "        x = layers.Conv1D(64, 3, activation='relu', padding='same',\n",
    "                        kernel_regularizer=regularizers.l2(1e-5))(inputs)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling1D(2)(x)\n",
    "        \n",
    "        x = layers.Conv1D(128, 3, activation='relu', padding='same',\n",
    "                        kernel_regularizer=regularizers.l2(1e-5))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling1D(2)(x)  # Added another pooling layer\n",
    "        \n",
    "        # Add residual connection\n",
    "        shortcut = layers.Conv1D(128, 1)(inputs)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "        shortcut = layers.MaxPooling1D(4)(shortcut)  # Match the shape after two MaxPooling1D(2)\n",
    "        x = layers.add([x, shortcut])\n",
    "        x = layers.Activation('relu')(x)\n",
    "        \n",
    "        # BiLSTM layers with increased complexity\n",
    "        x = layers.Bidirectional(layers.LSTM(64, return_sequences=True,\n",
    "                                        kernel_regularizer=regularizers.l2(1e-5)))(x)\n",
    "        x = layers.Dropout(0.4)(x)  # Increased dropout\n",
    "        x = layers.Bidirectional(layers.LSTM(32,\n",
    "                                        kernel_regularizer=regularizers.l2(1e-5)))(x)\n",
    "        \n",
    "        # Fix: Removing the attention mechanism that caused the error\n",
    "        # Original problematic code:\n",
    "        # attention = layers.Dense(1, activation='tanh')(x)\n",
    "        # attention = layers.Flatten()(attention)\n",
    "        # attention_weights = layers.Activation('softmax')(attention)\n",
    "        # context_vector = layers.Dot(axes=1)([x, attention_weights])\n",
    "        \n",
    "        # Replacement: Use a simpler approach without the Dot layer\n",
    "        context_vector = x  # Just use the BiLSTM output directly\n",
    "        \n",
    "        # Dense layers with residual connections\n",
    "        dense1 = layers.Dense(64, activation='relu',\n",
    "                            kernel_regularizer=regularizers.l2(1e-5))(context_vector)\n",
    "        dense1 = layers.BatchNormalization()(dense1)\n",
    "        dense1 = layers.Dropout(0.4)(dense1)\n",
    "        \n",
    "        # Output with temperature scaling for better calibration\n",
    "        logits = layers.Dense(self.num_classes)(dense1)\n",
    "        temperature = 1.5  # Temperature parameter (>1 makes predictions smoother)\n",
    "        scaled_logits = layers.Lambda(lambda x: x / temperature)(logits)\n",
    "        outputs = layers.Activation('softmax')(scaled_logits)\n",
    "        \n",
    "        from tensorflow import keras\n",
    "        model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        \n",
    "        # Use weighted categorical crossentropy for class imbalance\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(1e-3),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def compute_class_weights(self, y_train):\n",
    "        \"\"\"\n",
    "        Calculate class weights to handle imbalance, handling float labels by converting to int\n",
    "        \"\"\"\n",
    "        # Convert float labels to integers\n",
    "        y_train_int = y_train.astype(int)\n",
    "        \n",
    "        # Calculate class weights\n",
    "        unique_classes = np.unique(y_train_int)\n",
    "        class_counts = np.bincount(y_train_int)\n",
    "        total = len(y_train_int)\n",
    "        \n",
    "        # Create class weights dictionary\n",
    "        self.class_weights = {i: total / (len(unique_classes) * count) \n",
    "                            for i, count in enumerate(class_counts)}\n",
    "        print(\"Class weights:\", self.class_weights)\n",
    "        return self.class_weights\n",
    "\n",
    "    def train(self, X_train, y_train, X_val=None, y_val=None, epochs=50, batch_size=64):\n",
    "        # Compute class weights if not already done\n",
    "        if self.class_weights is None:\n",
    "            self.compute_class_weights(y_train)\n",
    "        \n",
    "        callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=15,  # Increased patience\n",
    "                restore_best_weights=True\n",
    "            ),\n",
    "            keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.2,  # More aggressive reduction\n",
    "                patience=7,\n",
    "                min_lr=1e-7\n",
    "            ),\n",
    "            # Add model checkpoint to save best model\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                'best_layer2_model.h5',\n",
    "                save_best_only=True,\n",
    "                monitor='val_accuracy',\n",
    "                mode='max'\n",
    "            ),\n",
    "            # Add TensorBoard callback\n",
    "            keras.callbacks.TensorBoard(\n",
    "                log_dir=f'./logs/layer2_{time.strftime(\"%Y%m%d-%H%M%S\")}',\n",
    "                histogram_freq=1\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # Use validation data if provided, otherwise use validation_split\n",
    "        if X_val is not None and y_val is not None:\n",
    "            history = self.model.fit(\n",
    "                X_train, y_train,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                validation_data=(X_val, y_val),\n",
    "                callbacks=callbacks,\n",
    "                class_weight=self.class_weights  # Use class weights\n",
    "            )\n",
    "        else:\n",
    "            history = self.model.fit(\n",
    "                X_train, y_train,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                validation_split=0.2,\n",
    "                callbacks=callbacks,\n",
    "                class_weight=self.class_weights\n",
    "            )\n",
    "        \n",
    "        # Plot training metrics\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Plot losses\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.plot(history.history['loss'], label='Training Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Model Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot accuracy\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot learning rate if available\n",
    "        if 'lr' in history.history:\n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.plot(history.history['lr'], label='Learning Rate')\n",
    "            plt.title('Learning Rate')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Learning Rate')\n",
    "            plt.yscale('log')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('layer2_training_metrics.png')\n",
    "        plt.close()\n",
    "        \n",
    "        return history\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        # Evaluate the model\n",
    "        test_loss, test_accuracy = self.model.evaluate(X_test, y_test, verbose=1)\n",
    "        print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "        print(f\"Test loss: {test_loss:.4f}\")\n",
    "        \n",
    "        # Generate predictions\n",
    "        y_pred_probs = self.model.predict(X_test)\n",
    "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "        \n",
    "        # Generate classification report\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        # Create confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                   xticklabels=np.unique(y_test),\n",
    "                   yticklabels=np.unique(y_test))\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.savefig('confusion_matrix.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Plot ROC curve for multi-class\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        # One-vs-Rest ROC curves\n",
    "        if self.num_classes > 2:\n",
    "            y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n",
    "            fpr = dict()\n",
    "            tpr = dict()\n",
    "            roc_auc = dict()\n",
    "            \n",
    "            for i in range(self.num_classes):\n",
    "                fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_probs[:, i])\n",
    "                roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "                plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
    "        else:\n",
    "            # Binary classification\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_pred_probs[:, 1])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "        \n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.savefig('roc_curve.png')\n",
    "        plt.close()\n",
    "        \n",
    "        return report, y_pred, y_pred_probs\n",
    "\n",
    "    def save_model(self, filepath):\n",
    "        \"\"\"Save the model to disk\"\"\"\n",
    "        self.model.save(filepath)\n",
    "        print(f\"Model saved to {filepath}\")\n",
    "        \n",
    "    def load_model(self, filepath):\n",
    "        \"\"\"Load a saved model from disk\"\"\"\n",
    "        self.model = keras.models.load_model(filepath)\n",
    "        print(f\"Model loaded from {filepath}\")\n",
    "        return self.model\n",
    "\n",
    "\n",
    "def preprocess_data(file_path, test_size=0.2, random_state=42, use_smote=True, use_standard_scaler=False):\n",
    "    \"\"\"\n",
    "    Enhanced preprocessing function with SMOTE option and scaler choice\n",
    "    \"\"\"\n",
    "    # Load data with error handling\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Successfully loaded dataset with {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Check for missing values and handle them\n",
    "    if df.isnull().sum().sum() > 0:\n",
    "        print(f\"Found {df.isnull().sum().sum()} missing values. Filling with appropriate methods.\")\n",
    "        numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "        categorical_cols = df.select_dtypes(exclude=['number']).columns\n",
    "        \n",
    "        # Fill numeric with median and categorical with mode\n",
    "        for col in numeric_cols:\n",
    "            if df[col].isnull().sum() > 0:\n",
    "                df[col] = df[col].fillna(df[col].median())\n",
    "        \n",
    "        for col in categorical_cols:\n",
    "            if df[col].isnull().sum() > 0:\n",
    "                df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    \n",
    "    # Check for and handle outliers using IQR method\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    for col in numeric_cols:\n",
    "        if col != 'Attack_label':  # Don't process the target variable\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            # Cap outliers rather than removing them\n",
    "            df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])\n",
    "            df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])\n",
    "    \n",
    "    # Separate features and labels\n",
    "    X = df.drop(['Attack_label'], axis=1)\n",
    "    y = df['Attack_label']\n",
    "    \n",
    "    # Print class distribution\n",
    "    print(\"Class distribution before sampling:\")\n",
    "    print(y.value_counts(normalize=True) * 100)\n",
    "    \n",
    "    # Apply feature scaling\n",
    "    if use_standard_scaler:\n",
    "        scaler = StandardScaler()  # Standardization (mean=0, std=1)\n",
    "        scaler_filename = 'standard_scaler.pkl'\n",
    "    else:\n",
    "        scaler = MinMaxScaler()  # Normalization (0-1 range)\n",
    "        scaler_filename = 'minmax_scaler.pkl'\n",
    "    \n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Save scaler for inference\n",
    "    joblib.dump(scaler, scaler_filename)\n",
    "    print(f\"Saved scaler as {scaler_filename}\")\n",
    "    \n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Apply SMOTE for handling class imbalance (only on training data)\n",
    "    if use_smote:\n",
    "        print(\"Applying SMOTE to balance classes...\")\n",
    "        smote = SMOTE(random_state=random_state)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "        print(\"Class distribution after SMOTE:\")\n",
    "        print(pd.Series(y_train).value_counts(normalize=True) * 100)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler\n",
    "\n",
    "\n",
    "def create_sequences(data, labels, seq_length=10, stride=1):\n",
    "    \"\"\"\n",
    "    Enhanced sequence creation with stride option for better coverage\n",
    "    \"\"\"\n",
    "    sequences, seq_labels = [], []\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    for i in range(0, len(data) - seq_length + 1, stride):\n",
    "        sequences.append(data[i:i + seq_length])\n",
    "        seq_labels.append(labels[i + seq_length - 1])\n",
    "    \n",
    "    return np.array(sequences), np.array(seq_labels)\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, class_names=None):\n",
    "    \"\"\"\n",
    "    Comprehensive model evaluation function\n",
    "    \"\"\"\n",
    "    # Get predictions\n",
    "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "    \n",
    "    # Generate classification report\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names if class_names else None,\n",
    "                yticklabels=class_names if class_names else None)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Calculate and plot ROC curves if binary classification\n",
    "    if len(np.unique(y_test)) == 2:\n",
    "        from sklearn.metrics import roc_curve, auc\n",
    "        y_pred_prob = model.predict(X_test)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.3f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig('roc_curve.png')\n",
    "        plt.close()\n",
    "    \n",
    "    return report\n",
    "\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Create logs and model directories if they don't exist\n",
    "    os.makedirs('./logs', exist_ok=True)\n",
    "    os.makedirs('./models', exist_ok=True)\n",
    "    \n",
    "    # Configure GPU for TensorFlow (if available)\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"Using GPU: {gpus}\")\n",
    "    else:\n",
    "        print(\"No GPU found, using CPU.\")\n",
    "    \n",
    "    # Set random seeds for reproducibility\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    # Record start time\n",
    "    start_time = time.time()\n",
    "    tf.get_logger().setLevel('ERROR')\n",
    "    \n",
    "    # Dataset path - use relative path for better portability\n",
    "    dataset_path = \"/Users/siddhantgond/Desktop/6THSEM/Project_Elective/Adaptive-Network-Intrusion-Detection-System/Implementaiton/training_dataset.csv\"\n",
    "    \n",
    "    # Preprocess data with SMOTE and MinMaxScaler\n",
    "    X_train, X_test, y_train, y_test, scaler = preprocess_data(\n",
    "        dataset_path, test_size=0.2, use_smote=True, use_standard_scaler=False\n",
    "    )\n",
    "    \n",
    "    # Layer 1: Autoencoder for anomaly detection\n",
    "    print(\"\\nTraining Layer 1: Autoencoder...\")\n",
    "    layer1 = EnhancedAdaptiveNIDS(input_dim=X_train.shape[1])\n",
    "    layer1.train(X_train, X_test, epochs=50, batch_size=64)\n",
    "    \n",
    "    # Detect anomalies using trained autoencoder\n",
    "    anomalies, anomaly_indices, errors, confidence = layer1.detect_anomalies(X_test)\n",
    "    \n",
    "    print(f\"Detected {len(anomaly_indices)} anomalies out of {len(X_test)} test samples.\")\n",
    "    print(f\"Anomaly detection rate: {len(anomaly_indices)/len(X_test)*100:.2f}%\")\n",
    "    \n",
    "    # Get encoded features for anomalies\n",
    "    encoded_features = layer1.get_encoded_features(anomalies)\n",
    "    \n",
    "    # If anomalies array is empty, use a subset of the data\n",
    "    if len(anomalies) == 0:\n",
    "        print(\"No anomalies detected. Using top 10% of highest error samples.\")\n",
    "        top_n = int(len(X_test) * 0.1)\n",
    "        sorted_indices = np.argsort(errors)[-top_n:]\n",
    "        anomalies = X_test[sorted_indices]\n",
    "        anomaly_indices = sorted_indices\n",
    "        encoded_features = layer1.get_encoded_features(anomalies)\n",
    "    \n",
    "    # Get original labels for anomalies\n",
    "    if isinstance(y_test, pd.Series):\n",
    "        y_anomalies = y_test.iloc[anomaly_indices]\n",
    "    else:\n",
    "        y_anomalies = y_test[anomaly_indices]\n",
    "    \n",
    "    # Create sequences for Layer 2 with stride=2 for better coverage\n",
    "    X_layer2, y_layer2 = create_sequences(encoded_features, y_anomalies, seq_length=10, stride=2)\n",
    "    \n",
    "    # Split data for Layer 2\n",
    "    if len(np.unique(y_layer2)) > 1:  # Only stratify if multiple classes\n",
    "        X_train_l2, X_test_l2, y_train_l2, y_test_l2 = train_test_split(\n",
    "            X_layer2, y_layer2, test_size=0.2, random_state=42, stratify=y_layer2\n",
    "        )\n",
    "    else:\n",
    "        X_train_l2, X_test_l2, y_train_l2, y_test_l2 = train_test_split(\n",
    "            X_layer2, y_layer2, test_size=0.2, random_state=42\n",
    "        )\n",
    "    \n",
    "    # Layer 2: CNN-BiLSTM Classification\n",
    "    print(\"\\nTraining Layer 2: CNN-BiLSTM...\")\n",
    "    layer2 = AdaptiveNIDSLayer2(\n",
    "        input_dim=X_train_l2.shape[2],\n",
    "        num_classes=len(np.unique(y_train_l2)),\n",
    "        seq_length=10\n",
    "    )\n",
    "    layer2.train(X_train_l2, y_train_l2, X_test_l2, y_test_l2, epochs=50, batch_size=32)\n",
    "    \n",
    "    # Evaluate Layer 2 with comprehensive metrics\n",
    "    class_names = [f\"Class {i}\" for i in range(len(np.unique(y_train_l2)))]\n",
    "    evaluate_model(layer2.model, X_test_l2, y_test_l2, class_names)\n",
    "    \n",
    "    # Save models with timestamp\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    layer1.model.save(f'models/autoencoder_model_{timestamp}.h5')\n",
    "    layer2.model.save(f'models/cnn_bilstm_model_{timestamp}.h5')\n",
    "    \n",
    "    # Save model architecture as image\n",
    "    try:\n",
    "        tf.keras.utils.plot_model(layer1.model, to_file='models/autoencoder_architecture.png', \n",
    "                                  show_shapes=True, show_layer_names=True)\n",
    "        tf.keras.utils.plot_model(layer2.model, to_file='models/cnn_bilstm_architecture.png', \n",
    "                                  show_shapes=True, show_layer_names=True)\n",
    "    except:\n",
    "        print(\"Couldn't save model architecture images. Make sure pydot is installed.\")\n",
    "    \n",
    "    # Save training configuration\n",
    "    config = {\n",
    "        'dataset_path': dataset_path,\n",
    "        'preprocessing': {\n",
    "            'use_smote': True,\n",
    "            'use_standard_scaler': False,\n",
    "            'test_size': 0.2\n",
    "        },\n",
    "        'layer1': {\n",
    "            'latent_dim': layer1.latent_dim,\n",
    "            'learning_rate': layer1.learning_rate,\n",
    "            'threshold': layer1.threshold\n",
    "        },\n",
    "        'layer2': {\n",
    "            'seq_length': layer2.seq_length,\n",
    "            'class_weights': layer2.class_weights\n",
    "        },\n",
    "        'timestamp': timestamp\n",
    "    }\n",
    "    \n",
    "    with open(f'models/training_config_{timestamp}.json', 'w') as f:\n",
    "        import json\n",
    "        json.dump(config, f, indent=4)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"\\nTotal execution time: {elapsed_time:.2f} seconds ({elapsed_time/60:.2f} minutes)\")\n",
    "    print(f\"Models saved with timestamp: {timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Overview**\n",
    "The system uses a two-layer approach:\n",
    "1. **Layer 1**: Autoencoder for anomaly detection.\n",
    "2. **Layer 2**: CNN-BiLSTM for classification of detected anomalies.\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Metrics**\n",
    "- **Total Execution Time**: 2.10 minutes (125.78 seconds)  \n",
    "  - Indicates efficient training, but this is due to a small dataset and optimized architecture.\n",
    "- **Anomaly Detection Rate**: `5%` (threshold set at 95th percentile of reconstruction errors).\n",
    "- **Layer 2 Training**: Uses class weights and validation metrics (loss, accuracy) for imbalance handling.\n",
    "\n",
    "---\n",
    "\n",
    "## **Strengths of the codes**\n",
    "1. **Preprocessing**:\n",
    "   - Handling missing values (median for numeric, mode for categorical).\n",
    "   - Capped outliers using IQR which is for reducing the loss function.\n",
    "   - Applied SMOTE for class imbalance and MinMax scaling for normalization.\n",
    "\n",
    "2. **Layer 1 (Autoencoder)**:\n",
    "   - Dynamic thresholding (95th percentile) for anomaly detection.\n",
    "   - Early stopping and learning rate reduction to prevent overfitting.\n",
    "   - Graceful handling of no-anomaly scenarios (uses top 10% high-error samples).\n",
    "\n",
    "3. **Layer 2 (CNN-BiLSTM)**:\n",
    "   - Residual connections and regularization (L2, dropout) to avoid overfitting.\n",
    "   - Temperature scaling for calibrated predictions.\n",
    "   - Comprehensive evaluation (confusion matrix, ROC curves, class-wise metrics).\n",
    "\n",
    "4. **Infrastructure**:\n",
    "   - GPU utilization (if available if not the code and run upon the local machine CPU) for faster training.\n",
    "   - Model saving with timestamps and config logging for reproducibility.\n",
    "\n",
    "---\n",
    "\n",
    "## **Weaknesses and Risks**\n",
    "1. **Anomaly Detection**:\n",
    "   - Fixed 95th percentile threshold may not generalize to dynamic attack patterns.\n",
    "   - No mention of precision/recall for anomaly detection (e.g., false positives/negatives).\n",
    "\n",
    "2. **Layer 2 Architecture**:\n",
    "   - Attention mechanism removed due to errors, potentially reducing model interpretability.\n",
    "   - Fixed sequence length (`seq_length=10`) and stride might lose temporal context.\n",
    "\n",
    "3. **Class Imbalance**:\n",
    "   - Simple class weighting (inverse frequency) may not handle extreme imbalance effectively.\n",
    "   - No metrics for minority class performance (e.g., F1-score for rare attacks).\n",
    "\n",
    "4. **Data Limitations**:\n",
    "   - Assumes anomalies detected by Layer 1 are valid inputs for Layer 2. Poor autoencoder performance would cascade errors.\n",
    "   - Dataset size/quality not specified; quick runtime may indicate limited training data.\n",
    "\n",
    "---\n",
    "\n",
    "## **Improvement areas of the architecture**\n",
    "1. **Threshold Optimization**:\n",
    "   - Experiment with adaptive thresholds (e.g., MAD, GMM) or contamination-based methods.\n",
    "   - Report anomaly detection metrics (precision, recall, F1).\n",
    "\n",
    "2. **Model Enhancements**:\n",
    "   - Re-implement attention mechanism with dimension checks for Layer 2.\n",
    "   - Use variable-length sequences or sliding windows for better temporal modeling.\n",
    "\n",
    "3. **Class Imbalance**:\n",
    "   - Test advanced techniques like Focal Loss or ensemble methods (e.g., Balanced Random Forest).\n",
    "\n",
    "4. **Evaluation**:\n",
    "   - Publish detailed classification reports (per-class precision/recall/F1).\n",
    "   - Include metrics like AUC-ROC for multi-class scenarios.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset: 71401 rows, 45 columns\n",
      "Dropped 'Unnamed: 0' column.\n",
      "Removed 7140 outliers using Isolation Forest\n",
      "Selected 11 features using Mutual Information\n",
      "Class distribution after ADASYN:\n",
      " Attack_label\n",
      "1.0    50.017109\n",
      "0.0    49.982891\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Training Layer 1: VAE...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling Lambda.call().\n\n\u001b[1mInput 'y' of 'Mul' Op has type float32 that does not match type float16 of argument 'x'.\u001b[0m\n\nArguments received by Lambda.call():\n  • inputs=['tf.Tensor(shape=(None, 64), dtype=float16)', 'tf.Tensor(shape=(None, 64), dtype=float16)']\n  • mask=['None', 'None']\n  • training=True",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 300\u001b[39m\n\u001b[32m    298\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTraining Layer 1: VAE...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    299\u001b[39m layer1 = EnhancedAdaptiveNIDS(input_dim=X_train.shape[\u001b[32m1\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m \u001b[43mlayer1\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m anomalies, anomaly_indices, errors, _ = layer1.detect_anomalies(X_test)\n\u001b[32m    303\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDetected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(anomaly_indices)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m anomalies out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_test)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m samples\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 81\u001b[39m, in \u001b[36mEnhancedAdaptiveNIDS.train\u001b[39m\u001b[34m(self, X_train, X_val, epochs, batch_size)\u001b[39m\n\u001b[32m     78\u001b[39m early_stopping = keras.callbacks.EarlyStopping(monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m, patience=\u001b[32m10\u001b[39m, restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     79\u001b[39m reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m, factor=\u001b[32m0.5\u001b[39m, patience=\u001b[32m5\u001b[39m, min_lr=\u001b[32m1e-6\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m history = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     84\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m plt.figure(figsize=(\u001b[32m12\u001b[39m, \u001b[32m4\u001b[39m))\n\u001b[32m     87\u001b[39m plt.plot(history.history[\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m], label=\u001b[33m'\u001b[39m\u001b[33mTraining Loss\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mEnhancedAdaptiveNIDS._build_vae.<locals>.sampling\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m     49\u001b[39m z_mean, z_log_var = args\n\u001b[32m     50\u001b[39m epsilon = tf.keras.backend.random_normal(shape=(tf.shape(z_mean)[\u001b[32m0\u001b[39m], \u001b[38;5;28mself\u001b[39m.latent_dim))\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m z_mean + \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_log_var\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: Exception encountered when calling Lambda.call().\n\n\u001b[1mInput 'y' of 'Mul' Op has type float32 that does not match type float16 of argument 'x'.\u001b[0m\n\nArguments received by Lambda.call():\n  • inputs=['tf.Tensor(shape=(None, 64), dtype=float16)', 'tf.Tensor(shape=(None, 64), dtype=float16)']\n  • mask=['None', 'None']\n  • training=True"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from scipy.stats import gaussian_kde\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "\n",
    "start_time = time.time()\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Enable mixed precision training for performance optimization\n",
    "set_global_policy('mixed_float16')\n",
    "\n",
    "class EnhancedAdaptiveNIDS:\n",
    "    def __init__(self, input_dim, latent_dim=64, learning_rate=1e-4):\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model, self.encoder = self._build_vae()\n",
    "        self.threshold = None\n",
    "\n",
    "    def _build_vae(self):\n",
    "        inputs = layers.Input(shape=(self.input_dim,))\n",
    "        x = layers.BatchNormalization()(inputs)\n",
    "        \n",
    "        # Encoder\n",
    "        x = layers.Dense(128, activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        z_mean = layers.Dense(self.latent_dim, name='z_mean')(x)\n",
    "        z_log_var = layers.Dense(self.latent_dim, name='z_log_var')(x)\n",
    "        \n",
    "        # Sampling layer with explicit output shape\n",
    "        def sampling(args):\n",
    "            z_mean, z_log_var = args\n",
    "            epsilon = tf.keras.backend.random_normal(shape=(tf.shape(z_mean)[0], self.latent_dim))\n",
    "            return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "        \n",
    "        z = layers.Lambda(sampling, output_shape=(self.latent_dim,))([z_mean, z_log_var])\n",
    "        \n",
    "        # Decoder\n",
    "        x = layers.Dense(128, activation='relu')(z)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        decoded = layers.Dense(self.input_dim, activation='linear')(x)\n",
    "        \n",
    "        # Models\n",
    "        autoencoder = keras.Model(inputs, decoded)\n",
    "        encoder = keras.Model(inputs, z)\n",
    "        autoencoder.compile(\n",
    "            optimizer=AdamW(learning_rate=self.learning_rate, weight_decay=1e-5),\n",
    "            loss=self._vae_loss(z_mean, z_log_var)\n",
    "        )\n",
    "        return autoencoder, encoder\n",
    "\n",
    "    def _vae_loss(self, z_mean, z_log_var):\n",
    "        def vae_loss(y_true, y_pred):\n",
    "            reconstruction_loss = tf.reduce_mean(tf.square(y_true - y_pred), axis=-1)\n",
    "            kl_loss = -0.5 * tf.reduce_mean(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\n",
    "            return reconstruction_loss + kl_loss\n",
    "        return vae_loss\n",
    "\n",
    "    def train(self, X_train, X_val, epochs=50, batch_size=64):\n",
    "        early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "        reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "        \n",
    "        history = self.model.fit(\n",
    "            X_train, X_train, epochs=epochs, batch_size=batch_size,\n",
    "            validation_data=(X_val, X_val), callbacks=[early_stopping, reduce_lr], verbose=1\n",
    "        )\n",
    "        \n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(history.history['loss'], label='Training Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('VAE Loss')\n",
    "        plt.legend()\n",
    "        plt.savefig('vae_loss.png')\n",
    "        plt.close()\n",
    "        \n",
    "        self._set_dynamic_threshold(X_train)\n",
    "        return history\n",
    "\n",
    "    def _set_dynamic_threshold(self, X_data):\n",
    "        reconstructed = self.model.predict(X_data)\n",
    "        mse = np.mean(np.square(X_data - reconstructed), axis=1)\n",
    "        \n",
    "        kde = gaussian_kde(mse)\n",
    "        x_range = np.linspace(min(mse), max(mse), 1000)\n",
    "        threshold_idx = np.argmax(np.cumsum(kde(x_range)) > 0.95)  # 95% cumulative density\n",
    "        self.threshold = x_range[threshold_idx]\n",
    "        print(f\"Dynamic KDE threshold set to: {self.threshold}\")\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(mse, bins=50, density=True)\n",
    "        plt.plot(x_range, kde(x_range), label='KDE')\n",
    "        plt.axvline(self.threshold, color='r', linestyle='--', label=f'Threshold: {self.threshold:.6f}')\n",
    "        plt.title('Reconstruction Error Distribution (KDE)')\n",
    "        plt.legend()\n",
    "        plt.savefig('error_distribution.png')\n",
    "        plt.close()\n",
    "\n",
    "    def detect_anomalies(self, X_data):\n",
    "        if self.threshold is None:\n",
    "            raise ValueError(\"Model hasn't been trained yet.\")\n",
    "        reconstructed = self.model.predict(X_data)\n",
    "        errors = np.mean(np.square(X_data - reconstructed), axis=1)\n",
    "        anomaly_indices = np.where(errors > self.threshold)[0]\n",
    "        confidence = errors / np.max(errors) if len(errors) > 0 else np.array([])\n",
    "        return X_data[anomaly_indices], anomaly_indices, errors, confidence\n",
    "\n",
    "    def get_encoded_features(self, X_data):\n",
    "        return self.encoder.predict(X_data)\n",
    "\n",
    "class AdaptiveNIDSLayer2:\n",
    "    def __init__(self, input_dim, num_classes, seq_length=10):\n",
    "        self.input_dim = input_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.seq_length = seq_length\n",
    "        self.model = self._build_model()\n",
    "        self.class_weights = None\n",
    "\n",
    "    def _build_model(self):\n",
    "        inputs = layers.Input(shape=(self.seq_length, self.input_dim))\n",
    "        \n",
    "        x = layers.Conv1D(64, 3, activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-5))(inputs)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling1D(2)(x)\n",
    "        \n",
    "        shortcut = layers.Conv1D(64, 1, padding='same')(inputs)\n",
    "        shortcut = layers.MaxPooling1D(2)(shortcut)\n",
    "        x = layers.add([x, shortcut])\n",
    "        \n",
    "        attention = layers.MultiHeadAttention(num_heads=4, key_dim=32)(x, x)\n",
    "        x = layers.add([x, attention])\n",
    "        x = layers.LayerNormalization()(x)\n",
    "        \n",
    "        x = layers.Bidirectional(layers.LSTM(64, return_sequences=False, kernel_regularizer=regularizers.l2(1e-5)))(x)\n",
    "        x = layers.Dropout(0.4)(x)\n",
    "        \n",
    "        outputs = layers.Dense(self.num_classes, activation='softmax')(x)\n",
    "        model = keras.Model(inputs, outputs)\n",
    "        model.compile(\n",
    "            optimizer=AdamW(learning_rate=1e-3, weight_decay=1e-5),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def compute_class_weights(self, y_train):\n",
    "        y_train_int = y_train.astype(int)\n",
    "        unique_classes = np.unique(y_train_int)\n",
    "        class_counts = np.bincount(y_train_int)\n",
    "        total = len(y_train_int)\n",
    "        self.class_weights = {i: total / (len(unique_classes) * count) for i, count in enumerate(class_counts)}\n",
    "        print(\"Class weights:\", self.class_weights)\n",
    "        return self.class_weights\n",
    "\n",
    "    def train(self, X_train, y_train, X_val=None, y_val=None, epochs=50, batch_size=32):\n",
    "        if self.class_weights is None:\n",
    "            self.compute_class_weights(y_train)\n",
    "        \n",
    "        callbacks = [\n",
    "            keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
    "            keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=1e-7),\n",
    "            keras.callbacks.ModelCheckpoint('best_layer2_model.h5', save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "        ]\n",
    "        \n",
    "        if X_val is not None and y_val is not None:\n",
    "            history = self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "                                    validation_data=(X_val, y_val), callbacks=callbacks, class_weight=self.class_weights)\n",
    "        else:\n",
    "            history = self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "                                    validation_split=0.2, callbacks=callbacks, class_weight=self.class_weights)\n",
    "        \n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(history.history['loss'], label='Training Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Layer 2 Loss')\n",
    "        plt.legend()\n",
    "        plt.savefig('layer2_loss.png')\n",
    "        plt.close()\n",
    "        return history\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        test_loss, test_accuracy = self.model.evaluate(X_test, y_test, verbose=1)\n",
    "        print(f\"Test accuracy: {test_accuracy:.4f}, Test loss: {test_loss:.4f}\")\n",
    "        \n",
    "        y_pred_probs = self.model.predict(X_test)\n",
    "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "        print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "        \n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.savefig('confusion_matrix.png')\n",
    "        plt.close()\n",
    "        return classification_report(y_test, y_pred, output_dict=True), y_pred, y_pred_probs\n",
    "\n",
    "    def save_model(self, filepath):\n",
    "        self.model.save(filepath)\n",
    "        print(f\"Model saved to {filepath}\")\n",
    "        \n",
    "        import tf2onnx\n",
    "        spec = (tf.TensorSpec((None, self.seq_length, self.input_dim), tf.float32, name=\"input\"),)\n",
    "        model_proto, _ = tf2onnx.convert.from_keras(self.model, input_signature=spec, opset=13)\n",
    "        with open(filepath.replace('.h5', '.onnx'), 'wb') as f:\n",
    "            f.write(model_proto.SerializeToString())\n",
    "        print(f\"ONNX model saved to {filepath.replace('.h5', '.onnx')}\")\n",
    "\n",
    "def preprocess_data(file_path, test_size=0.2, random_state=42):\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"Loaded dataset: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "    \n",
    "    # Drop Unnamed: 0 column if it exists\n",
    "    if 'Unnamed: 0' in df.columns:\n",
    "        df = df.drop('Unnamed: 0', axis=1)\n",
    "        print(\"Dropped 'Unnamed: 0' column.\")\n",
    "    \n",
    "    # KNN imputation for missing values\n",
    "    if df.isnull().sum().sum() > 0:\n",
    "        print(f\"Handling {df.isnull().sum().sum()} missing values with KNN...\")\n",
    "        numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "        imputer = KNeighborsRegressor(n_neighbors=5)\n",
    "        df[numeric_cols] = imputer.fit_transform(df[numeric_cols])\n",
    "    \n",
    "    # Outlier detection with Isolation Forest\n",
    "    iso = IsolationForest(contamination=0.1, random_state=random_state)\n",
    "    outliers = iso.fit_predict(df.drop('Attack_label', axis=1))\n",
    "    df = df[outliers == 1]\n",
    "    print(f\"Removed {sum(outliers == -1)} outliers using Isolation Forest\")\n",
    "    \n",
    "    # Feature selection with Mutual Information\n",
    "    X = df.drop('Attack_label', axis=1)\n",
    "    y = df['Attack_label']\n",
    "    mi_scores = mutual_info_classif(X, y, random_state=random_state)\n",
    "    selected_features = X.columns[mi_scores > np.percentile(mi_scores, 75)].tolist()\n",
    "    X = X[selected_features]\n",
    "    print(f\"Selected {len(selected_features)} features using Mutual Information\")\n",
    "    \n",
    "    # Scaling (corrected line)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    joblib.dump(scaler, 'minmax_scaler.pkl')\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "    \n",
    "    # ADASYN for class imbalance\n",
    "    adasyn = ADASYN(random_state=random_state)\n",
    "    X_train, y_train = adasyn.fit_resample(X_train, y_train)\n",
    "    print(\"Class distribution after ADASYN:\\n\", pd.Series(y_train).value_counts(normalize=True) * 100)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler\n",
    "\n",
    "def create_sequences(data, labels, seq_length=10, stride=2):\n",
    "    if len(data) < seq_length:\n",
    "        print(f\"Warning: Data length ({len(data)}) is less than seq_length ({seq_length}). Returning data as-is.\")\n",
    "        return np.expand_dims(data, axis=1), labels\n",
    "    \n",
    "    sequences, seq_labels = [], []\n",
    "    for i in range(0, len(data) - seq_length + 1, stride):\n",
    "        sequences.append(data[i:i + seq_length])\n",
    "        seq_labels.append(labels[i + seq_length - 1])\n",
    "    return np.array(sequences), np.array(seq_labels)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    os.makedirs('./logs', exist_ok=True)\n",
    "    os.makedirs('./models', exist_ok=True)\n",
    "    \n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"Using GPU: {gpus}\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    dataset_path = \"/Users/siddhantgond/Desktop/6THSEM/Project_Elective/Adaptive-Network-Intrusion-Detection-System/Implementaiton/training_dataset.csv\"\n",
    "    X_train, X_test, y_train, y_test, scaler = preprocess_data(dataset_path)\n",
    "    \n",
    "    # Layer 1\n",
    "    print(\"\\nTraining Layer 1: VAE...\")\n",
    "    layer1 = EnhancedAdaptiveNIDS(input_dim=X_train.shape[1])\n",
    "    layer1.train(X_train, X_test, epochs=50, batch_size=64)\n",
    "    \n",
    "    anomalies, anomaly_indices, errors, _ = layer1.detect_anomalies(X_test)\n",
    "    print(f\"Detected {len(anomaly_indices)} anomalies out of {len(X_test)} samples\")\n",
    "    \n",
    "    encoded_features = layer1.get_encoded_features(anomalies if len(anomalies) > 0 else X_test[:int(len(X_test) * 0.1)])\n",
    "    y_anomalies = y_test[anomaly_indices] if len(anomaly_indices) > 0 else y_test[:int(len(X_test) * 0.1)]\n",
    "    \n",
    "    # Layer 2\n",
    "    X_layer2, y_layer2 = create_sequences(encoded_features, y_anomalies)\n",
    "    if len(X_layer2) > 0:\n",
    "        X_train_l2, X_test_l2, y_train_l2, y_test_l2 = train_test_split(X_layer2, y_layer2, test_size=0.2, random_state=42, stratify=y_layer2)\n",
    "        \n",
    "        print(\"\\nTraining Layer 2: CNN-BiLSTM with Attention...\")\n",
    "        layer2 = AdaptiveNIDSLayer2(input_dim=X_train_l2.shape[2], num_classes=len(np.unique(y_train_l2)))\n",
    "        layer2.train(X_train_l2, y_train_l2, X_test_l2, y_test_l2, epochs=50)\n",
    "        \n",
    "        layer2.evaluate(X_test_l2, y_test_l2)\n",
    "        \n",
    "        # Save models\n",
    "        timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        layer1.model.save(f'models/vae_model_{timestamp}.h5')\n",
    "        layer2.save_model(f'models/cnn_bilstm_model_{timestamp}.h5')\n",
    "    else:\n",
    "        print(\"Not enough data for Layer 2 training after sequencing.\")\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"\\nTotal execution time: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
