{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Forward to Layer 2 Implementation  \n",
    "\n",
    "The implementation of Layer 1 (Anomaly Detection & Feature Extraction) is now complete. However, for further modifications and validation, we require more dataset variations or additional traffic patterns. Constructing these datasets will take some time.  \n",
    "\n",
    "In the meantime, I'm now proceeding with the **implementation of Layer 2 (Attack Classification & Adaptive Learning)**.  \n",
    "\n",
    "### Key Next Steps:\n",
    "- **Dataset Construction:** Since Layer 2 relies on anomalous samples detected by Layer 1, we will integrate the Layer 1 code with the Layer 2 pipeline.  \n",
    "- **Feature Extraction:** Extracting CNN-enhanced features from Layer 1 to improve classification performance.  \n",
    "- **Attack Classification Model:** Implementing a CNN-BiLSTM model with Knowledge Distillation for efficient and scalable attack classification.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and preprocessing dataset\n",
    "def preprocess_data(file_path, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Load and preprocess dataset for ANIDS.\n",
    "    - Applies robust scaling\n",
    "    - Removes outliers using IQR\n",
    "    - Splits data into training & validation sets\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(['Attack_label'], axis=1)\n",
    "    \n",
    "    # Outlier removal using IQR\n",
    "    Q1, Q3 = X.quantile(0.25), X.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    X = X[~((X < (Q1 - 3 * IQR)) | (X > (Q3 + 3 * IQR))).any(axis=1)]\n",
    "    \n",
    "    # Scaling\n",
    "    scaler = RobustScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    joblib.dump(scaler, 'robust_scaler.pkl')\n",
    "\n",
    "    return train_test_split(X_scaled, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# Load dataset\n",
    "X_train, X_val = preprocess_data(\"/Users/siddhantgond/Desktop/6THSEM/Project_Elective/Adaptive-Network-Intrusion-Detection-System/Implementaiton/training_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - loss: 0.2358 - val_loss: 0.2136\n",
      "Epoch 2/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.2126 - val_loss: 0.1941\n",
      "Epoch 3/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.1943 - val_loss: 0.1774\n",
      "Epoch 4/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.1811 - val_loss: 0.1633\n",
      "Epoch 5/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1642 - val_loss: 0.1505\n",
      "Epoch 6/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.1511 - val_loss: 0.1400\n",
      "Epoch 7/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.1416 - val_loss: 0.1305\n",
      "Epoch 8/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1356 - val_loss: 0.1227\n",
      "Epoch 9/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1247 - val_loss: 0.1160\n",
      "Epoch 10/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1163 - val_loss: 0.1108\n",
      "Epoch 11/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1119 - val_loss: 0.1070\n",
      "Epoch 12/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.1103 - val_loss: 0.1041\n",
      "Epoch 13/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.1105 - val_loss: 0.1025\n",
      "Epoch 14/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1129 - val_loss: 0.1017\n",
      "Epoch 15/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.1090 - val_loss: 0.1013\n",
      "Epoch 16/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.1054 - val_loss: 0.1010\n",
      "Epoch 17/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1064 - val_loss: 0.1007\n",
      "Epoch 18/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1079 - val_loss: 0.1002\n",
      "Epoch 19/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1076 - val_loss: 0.1000\n",
      "Epoch 20/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1087 - val_loss: 0.0995\n",
      "Epoch 21/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.1096 - val_loss: 0.0990\n",
      "Epoch 22/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.1057 - val_loss: 0.0986\n",
      "Epoch 23/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1065 - val_loss: 0.0980\n",
      "Epoch 24/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1062 - val_loss: 0.0975\n",
      "Epoch 25/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1036 - val_loss: 0.0968\n",
      "Epoch 26/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1070 - val_loss: 0.0966\n",
      "Epoch 27/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.1021 - val_loss: 0.0958\n",
      "Epoch 28/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.1039 - val_loss: 0.0951\n",
      "Epoch 29/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.1008 - val_loss: 0.0944\n",
      "Epoch 30/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 0.1046 - val_loss: 0.0938\n",
      "Epoch 31/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.1019 - val_loss: 0.0935\n",
      "Epoch 32/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 0.1000 - val_loss: 0.0944\n",
      "Epoch 33/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.1013 - val_loss: 0.0925\n",
      "Epoch 34/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.1023 - val_loss: 0.0922\n",
      "Epoch 35/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1027 - val_loss: 0.0920\n",
      "Epoch 36/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.1015 - val_loss: 0.0924\n",
      "Epoch 37/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.1019 - val_loss: 0.0913\n",
      "Epoch 38/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1030 - val_loss: 0.0911\n",
      "Epoch 39/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1017 - val_loss: 0.0903\n",
      "Epoch 40/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0988 - val_loss: 0.0903\n",
      "Epoch 41/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0984 - val_loss: 0.0895\n",
      "Epoch 42/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0985 - val_loss: 0.0898\n",
      "Epoch 43/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1008 - val_loss: 0.0897\n",
      "Epoch 44/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0990 - val_loss: 0.0890\n",
      "Epoch 45/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0964 - val_loss: 0.0887\n",
      "Epoch 46/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0989 - val_loss: 0.0890\n",
      "Epoch 47/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0980 - val_loss: 0.0885\n",
      "Epoch 48/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.0958 - val_loss: 0.0879\n",
      "Epoch 49/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0980 - val_loss: 0.0871\n",
      "Epoch 50/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1016 - val_loss: 0.0891\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step\n"
     ]
    }
   ],
   "source": [
    "# Define Layer 1 of the Adaptive NIDS\n",
    "class AdaptiveNIDSLayer1:\n",
    "    def __init__(self, input_dim, latent_dim=16):\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.model = self._build_autoencoder()\n",
    "\n",
    "    def _build_autoencoder(self):\n",
    "        inputs = layers.Input(shape=(self.input_dim,))\n",
    "        x = layers.BatchNormalization()(inputs)\n",
    "        x = layers.Reshape((-1, 1))(x)\n",
    "\n",
    "        # Feature extraction via Residual CNN\n",
    "        x = layers.Conv1D(16, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.Conv1D(32, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.GlobalAveragePooling1D(name=\"gap_layer\")(x)  # Added explicit name\n",
    "\n",
    "        # Latent Representation\n",
    "        x = layers.Dense(64, activation='mish', kernel_regularizer=regularizers.l1(0.0005))(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        encoded = layers.Dense(self.latent_dim, activation='linear')(x)\n",
    "\n",
    "        # Decoder\n",
    "        x = layers.RepeatVector(self.input_dim)(encoded)\n",
    "        x = layers.LSTM(self.latent_dim * 2, return_sequences=True, recurrent_dropout=0.25)(x)\n",
    "        decoded = layers.TimeDistributed(layers.Dense(1, activation='linear'))(x)\n",
    "        decoded = layers.Flatten()(decoded)\n",
    "\n",
    "        autoencoder = keras.Model(inputs=inputs, outputs=decoded)\n",
    "        autoencoder.compile(optimizer=keras.optimizers.Adam(1e-4), loss='mse')\n",
    "        return autoencoder\n",
    "\n",
    "    def train(self, X_train, X_val, epochs=50):\n",
    "        self.model.fit(X_train, X_train, epochs=epochs, batch_size=64, validation_data=(X_val, X_val))\n",
    "\n",
    "    def detect_anomalies(self, X_data, threshold=0.02):\n",
    "        reconstructed = self.model.predict(X_data)\n",
    "        errors = np.mean(np.square(X_data - reconstructed), axis=1)\n",
    "        return X_data[errors > threshold], np.where(errors > threshold)[0]\n",
    "        \n",
    "    def extract_features(self, X_anomalies):\n",
    "        # Create a feature extractor model using the named gap_layer\n",
    "        feature_extractor = keras.Model(\n",
    "            inputs=self.model.input, \n",
    "            outputs=self.model.get_layer(\"gap_layer\").output  # Use the named layer\n",
    "        )\n",
    "        return feature_extractor.predict(X_anomalies)\n",
    "\n",
    "# Train Layer 1\n",
    "layer1 = AdaptiveNIDSLayer1(input_dim=X_train.shape[1])\n",
    "layer1.train(X_train, X_val)\n",
    "\n",
    "# Detect anomalies\n",
    "anomalies, anomaly_indices = layer1.detect_anomalies(X_val)\n",
    "\n",
    "# Example usage of the new extract_features method\n",
    "extracted_features = layer1.extract_features(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 0.2402 - val_loss: 0.2264\n",
      "Epoch 2/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.2306 - val_loss: 0.2157\n",
      "Epoch 3/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.2177 - val_loss: 0.2054\n",
      "Epoch 4/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.2091 - val_loss: 0.1950\n",
      "Epoch 5/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1992 - val_loss: 0.1866\n",
      "Epoch 6/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1953 - val_loss: 0.1785\n",
      "Epoch 7/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1836 - val_loss: 0.1709\n",
      "Epoch 8/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.1778 - val_loss: 0.1636\n",
      "Epoch 9/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1654 - val_loss: 0.1569\n",
      "Epoch 10/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.1611 - val_loss: 0.1504\n",
      "Epoch 11/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1539 - val_loss: 0.1443\n",
      "Epoch 12/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.1496 - val_loss: 0.1389\n",
      "Epoch 13/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.1471 - val_loss: 0.1336\n",
      "Epoch 14/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.1434 - val_loss: 0.1290\n",
      "Epoch 15/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1323 - val_loss: 0.1244\n",
      "Epoch 16/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1309 - val_loss: 0.1205\n",
      "Epoch 17/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1282 - val_loss: 0.1171\n",
      "Epoch 18/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1260 - val_loss: 0.1139\n",
      "Epoch 19/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1202 - val_loss: 0.1112\n",
      "Epoch 20/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1176 - val_loss: 0.1087\n",
      "Epoch 21/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1150 - val_loss: 0.1065\n",
      "Epoch 22/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1145 - val_loss: 0.1045\n",
      "Epoch 23/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.1090 - val_loss: 0.1030\n",
      "Epoch 24/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.1084 - val_loss: 0.1018\n",
      "Epoch 25/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.1060 - val_loss: 0.1007\n",
      "Epoch 26/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.1072 - val_loss: 0.1002\n",
      "Epoch 27/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1047 - val_loss: 0.0996\n",
      "Epoch 28/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1069 - val_loss: 0.0993\n",
      "Epoch 29/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1071 - val_loss: 0.0990\n",
      "Epoch 30/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1048 - val_loss: 0.0984\n",
      "Epoch 31/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1082 - val_loss: 0.0980\n",
      "Epoch 32/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.1008 - val_loss: 0.0975\n",
      "Epoch 33/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.1042 - val_loss: 0.0973\n",
      "Epoch 34/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.1029 - val_loss: 0.0977\n",
      "Epoch 35/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1016 - val_loss: 0.0962\n",
      "Epoch 36/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1072 - val_loss: 0.0958\n",
      "Epoch 37/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.1013 - val_loss: 0.0956\n",
      "Epoch 38/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1021 - val_loss: 0.0950\n",
      "Epoch 39/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1037 - val_loss: 0.0947\n",
      "Epoch 40/40\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1015 - val_loss: 0.0940\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Define Layer 1 of the Adaptive NIDS\n",
    "class AdaptiveNIDSLayer1:\n",
    "    def __init__(self, input_dim, latent_dim=16):\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.model = self._build_autoencoder()\n",
    "\n",
    "    def _build_autoencoder(self):\n",
    "        inputs = layers.Input(shape=(self.input_dim,))\n",
    "        x = layers.BatchNormalization()(inputs)\n",
    "        x = layers.Reshape((-1, 1))(x)\n",
    "\n",
    "        # Feature extraction via Residual CNN\n",
    "        x = layers.Conv1D(16, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.Conv1D(32, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.GlobalAveragePooling1D(name=\"gap_layer\")(x)  # Added explicit name\n",
    "\n",
    "        # Latent Representation\n",
    "        x = layers.Dense(64, activation='mish', kernel_regularizer=regularizers.l1(0.0005))(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        encoded = layers.Dense(self.latent_dim, activation='linear')(x)\n",
    "\n",
    "        # Decoder\n",
    "        x = layers.RepeatVector(self.input_dim)(encoded)\n",
    "        x = layers.LSTM(self.latent_dim * 2, return_sequences=True, recurrent_dropout=0.25)(x)\n",
    "        decoded = layers.TimeDistributed(layers.Dense(1, activation='linear'))(x)\n",
    "        decoded = layers.Flatten()(decoded)\n",
    "\n",
    "        autoencoder = keras.Model(inputs=inputs, outputs=decoded)\n",
    "        autoencoder.compile(optimizer=keras.optimizers.Adam(1e-4), loss='mse')\n",
    "        return autoencoder\n",
    "\n",
    "    def train(self, X_train, X_val, epochs=40):\n",
    "        self.model.fit(X_train, X_train, epochs=epochs, batch_size=128, validation_data=(X_val, X_val))\n",
    "\n",
    "    def detect_anomalies(self, X_data, threshold=0.02):\n",
    "        reconstructed = self.model.predict(X_data)\n",
    "        errors = np.mean(np.square(X_data - reconstructed), axis=1)\n",
    "        return X_data[errors > threshold], np.where(errors > threshold)[0]\n",
    "        \n",
    "    def extract_features(self, X_anomalies):\n",
    "        # Create a feature extractor model using the named gap_layer\n",
    "        feature_extractor = keras.Model(\n",
    "            inputs=self.model.input, \n",
    "            outputs=self.model.get_layer(\"gap_layer\").output  # Use the named layer\n",
    "        )\n",
    "        return feature_extractor.predict(X_anomalies)\n",
    "\n",
    "# Train Layer 1\n",
    "layer1 = AdaptiveNIDSLayer1(input_dim=X_train.shape[1])\n",
    "layer1.train(X_train, X_val)\n",
    "\n",
    "# Detect anomalies\n",
    "anomalies, anomaly_indices = layer1.detect_anomalies(X_val)\n",
    "\n",
    "# Example usage of the new extract_features method\n",
    "extracted_features_epoch_40_BS_128 = layer1.extract_features(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 0.2342 - val_loss: 0.2222\n",
      "Epoch 2/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.2260 - val_loss: 0.2118\n",
      "Epoch 3/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.2164 - val_loss: 0.2028\n",
      "Epoch 4/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.2075 - val_loss: 0.1935\n",
      "Epoch 5/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1955 - val_loss: 0.1837\n",
      "Epoch 6/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1875 - val_loss: 0.1762\n",
      "Epoch 7/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1777 - val_loss: 0.1689\n",
      "Epoch 8/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1718 - val_loss: 0.1621\n",
      "Epoch 9/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.1672 - val_loss: 0.1556\n",
      "Epoch 10/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.1621 - val_loss: 0.1496\n",
      "Epoch 11/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.1551 - val_loss: 0.1437\n",
      "Epoch 12/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1492 - val_loss: 0.1383\n",
      "Epoch 13/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.1463 - val_loss: 0.1335\n",
      "Epoch 14/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.1400 - val_loss: 0.1290\n",
      "Epoch 15/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.1324 - val_loss: 0.1245\n",
      "Epoch 16/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1301 - val_loss: 0.1206\n",
      "Epoch 17/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.1300 - val_loss: 0.1171\n",
      "Epoch 18/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1245 - val_loss: 0.1139\n",
      "Epoch 19/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.1174 - val_loss: 0.1113\n",
      "Epoch 20/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1143 - val_loss: 0.1087\n",
      "Epoch 21/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1154 - val_loss: 0.1064\n",
      "Epoch 22/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1119 - val_loss: 0.1046\n",
      "Epoch 23/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1121 - val_loss: 0.1031\n",
      "Epoch 24/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.1086 - val_loss: 0.1018\n",
      "Epoch 25/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1100 - val_loss: 0.1008\n",
      "Epoch 26/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1101 - val_loss: 0.0999\n",
      "Epoch 27/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1071 - val_loss: 0.0993\n",
      "Epoch 28/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1064 - val_loss: 0.0990\n",
      "Epoch 29/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1040 - val_loss: 0.0981\n",
      "Epoch 30/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.1013 - val_loss: 0.0979\n",
      "Epoch 31/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1042 - val_loss: 0.0977\n",
      "Epoch 32/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.1036 - val_loss: 0.0970\n",
      "Epoch 33/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - loss: 0.1054 - val_loss: 0.0962\n",
      "Epoch 34/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1074 - val_loss: 0.0959\n",
      "Epoch 35/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1007 - val_loss: 0.0953\n",
      "Epoch 36/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1050 - val_loss: 0.0946\n",
      "Epoch 37/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1051 - val_loss: 0.0946\n",
      "Epoch 38/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1029 - val_loss: 0.0941\n",
      "Epoch 39/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1030 - val_loss: 0.0933\n",
      "Epoch 40/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.1022 - val_loss: 0.0929\n",
      "Epoch 41/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1011 - val_loss: 0.0925\n",
      "Epoch 42/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1035 - val_loss: 0.0926\n",
      "Epoch 43/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1010 - val_loss: 0.0927\n",
      "Epoch 44/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0996 - val_loss: 0.0926\n",
      "Epoch 45/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0983 - val_loss: 0.0909\n",
      "Epoch 46/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0983 - val_loss: 0.0905\n",
      "Epoch 47/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.1004 - val_loss: 0.0912\n",
      "Epoch 48/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0996 - val_loss: 0.0899\n",
      "Epoch 49/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1003 - val_loss: 0.0918\n",
      "Epoch 50/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0983 - val_loss: 0.0896\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step\n"
     ]
    }
   ],
   "source": [
    "# Define Layer 1 of the Adaptive NIDS\n",
    "class AdaptiveNIDSLayer1:\n",
    "    def __init__(self, input_dim, latent_dim=16):\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.model = self._build_autoencoder()\n",
    "\n",
    "    def _build_autoencoder(self):\n",
    "        inputs = layers.Input(shape=(self.input_dim,))\n",
    "        x = layers.BatchNormalization()(inputs)\n",
    "        x = layers.Reshape((-1, 1))(x)\n",
    "\n",
    "        # Feature extraction via Residual CNN\n",
    "        x = layers.Conv1D(16, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.Conv1D(32, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.GlobalAveragePooling1D(name=\"gap_layer\")(x)  # Added explicit name\n",
    "\n",
    "        # Latent Representation\n",
    "        x = layers.Dense(64, activation='mish', kernel_regularizer=regularizers.l1(0.0005))(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        encoded = layers.Dense(self.latent_dim, activation='linear')(x)\n",
    "\n",
    "        # Decoder\n",
    "        x = layers.RepeatVector(self.input_dim)(encoded)\n",
    "        x = layers.LSTM(self.latent_dim * 2, return_sequences=True, recurrent_dropout=0.25)(x)\n",
    "        decoded = layers.TimeDistributed(layers.Dense(1, activation='linear'))(x)\n",
    "        decoded = layers.Flatten()(decoded)\n",
    "\n",
    "        autoencoder = keras.Model(inputs=inputs, outputs=decoded)\n",
    "        autoencoder.compile(optimizer=keras.optimizers.Adam(1e-4), loss='mse')\n",
    "        return autoencoder\n",
    "\n",
    "    def train(self, X_train, X_val, epochs=50):\n",
    "        self.model.fit(X_train, X_train, epochs=epochs, batch_size=128, validation_data=(X_val, X_val))\n",
    "\n",
    "    def detect_anomalies(self, X_data, threshold=0.02):\n",
    "        reconstructed = self.model.predict(X_data)\n",
    "        errors = np.mean(np.square(X_data - reconstructed), axis=1)\n",
    "        return X_data[errors > threshold], np.where(errors > threshold)[0]\n",
    "        \n",
    "    def extract_features(self, X_anomalies):\n",
    "        # Create a feature extractor model using the named gap_layer\n",
    "        feature_extractor = keras.Model(\n",
    "            inputs=self.model.input, \n",
    "            outputs=self.model.get_layer(\"gap_layer\").output  # Use the named layer\n",
    "        )\n",
    "        return feature_extractor.predict(X_anomalies)\n",
    "\n",
    "# Train Layer 1\n",
    "layer1 = AdaptiveNIDSLayer1(input_dim=X_train.shape[1])\n",
    "layer1.train(X_train, X_val)\n",
    "\n",
    "# Detect anomalies\n",
    "anomalies, anomaly_indices = layer1.detect_anomalies(X_val)\n",
    "\n",
    "# Example usage of the new extract_features method\n",
    "extracted_features_epoch_50_BS_128 = layer1.extract_features(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.2297 - val_loss: 0.1953\n",
      "Epoch 2/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1912 - val_loss: 0.1648\n",
      "Epoch 3/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1650 - val_loss: 0.1415\n",
      "Epoch 4/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - loss: 0.1433 - val_loss: 0.1239\n",
      "Epoch 5/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - loss: 0.1268 - val_loss: 0.1115\n",
      "Epoch 6/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1136 - val_loss: 0.1043\n",
      "Epoch 7/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1132 - val_loss: 0.1017\n",
      "Epoch 8/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1059 - val_loss: 0.1012\n",
      "Epoch 9/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1114 - val_loss: 0.1003\n",
      "Epoch 10/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1035 - val_loss: 0.0993\n",
      "Epoch 11/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1085 - val_loss: 0.0988\n",
      "Epoch 12/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1081 - val_loss: 0.0977\n",
      "Epoch 13/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1080 - val_loss: 0.0961\n",
      "Epoch 14/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1051 - val_loss: 0.0955\n",
      "Epoch 15/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1007 - val_loss: 0.0943\n",
      "Epoch 16/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - loss: 0.1027 - val_loss: 0.0934\n",
      "Epoch 17/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0987 - val_loss: 0.0924\n",
      "Epoch 18/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1016 - val_loss: 0.0928\n",
      "Epoch 19/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1005 - val_loss: 0.0923\n",
      "Epoch 20/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.1003 - val_loss: 0.0931\n",
      "Epoch 21/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - loss: 0.1052 - val_loss: 0.0907\n",
      "Epoch 22/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1006 - val_loss: 0.0898\n",
      "Epoch 23/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0997 - val_loss: 0.0891\n",
      "Epoch 24/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1019 - val_loss: 0.0889\n",
      "Epoch 25/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0983 - val_loss: 0.0886\n",
      "Epoch 26/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0978 - val_loss: 0.0884\n",
      "Epoch 27/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1030 - val_loss: 0.0871\n",
      "Epoch 28/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0991 - val_loss: 0.0883\n",
      "Epoch 29/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0989 - val_loss: 0.0872\n",
      "Epoch 30/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0976 - val_loss: 0.0866\n",
      "Epoch 31/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0993 - val_loss: 0.0866\n",
      "Epoch 32/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0981 - val_loss: 0.0865\n",
      "Epoch 33/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0989 - val_loss: 0.0857\n",
      "Epoch 34/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0934 - val_loss: 0.0846\n",
      "Epoch 35/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0969 - val_loss: 0.0848\n",
      "Epoch 36/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0942 - val_loss: 0.0849\n",
      "Epoch 37/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0976 - val_loss: 0.0837\n",
      "Epoch 38/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0969 - val_loss: 0.0839\n",
      "Epoch 39/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0995 - val_loss: 0.0835\n",
      "Epoch 40/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0952 - val_loss: 0.0827\n",
      "Epoch 41/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0983 - val_loss: 0.0838\n",
      "Epoch 42/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0960 - val_loss: 0.0823\n",
      "Epoch 43/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0945 - val_loss: 0.0812\n",
      "Epoch 44/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0966 - val_loss: 0.0817\n",
      "Epoch 45/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0988 - val_loss: 0.0818\n",
      "Epoch 46/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0967 - val_loss: 0.0826\n",
      "Epoch 47/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0936 - val_loss: 0.0815\n",
      "Epoch 48/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0936 - val_loss: 0.0803\n",
      "Epoch 49/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0959 - val_loss: 0.0834\n",
      "Epoch 50/50\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0943 - val_loss: 0.0802\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# Define Layer 1 of the Adaptive NIDS\n",
    "class AdaptiveNIDSLayer1:\n",
    "    def __init__(self, input_dim, latent_dim=16):\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.model = self._build_autoencoder()\n",
    "\n",
    "    def _build_autoencoder(self):\n",
    "        inputs = layers.Input(shape=(self.input_dim,))\n",
    "        x = layers.BatchNormalization()(inputs)\n",
    "        x = layers.Reshape((-1, 1))(x)\n",
    "\n",
    "        # Feature extraction via Residual CNN\n",
    "        x = layers.Conv1D(16, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.Conv1D(32, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.GlobalAveragePooling1D(name=\"gap_layer\")(x)  # Added explicit name\n",
    "\n",
    "        # Latent Representation\n",
    "        x = layers.Dense(64, activation='mish', kernel_regularizer=regularizers.l1(0.0005))(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        encoded = layers.Dense(self.latent_dim, activation='linear')(x)\n",
    "\n",
    "        # Decoder\n",
    "        x = layers.RepeatVector(self.input_dim)(encoded)\n",
    "        x = layers.LSTM(self.latent_dim * 2, return_sequences=True, recurrent_dropout=0.25)(x)\n",
    "        decoded = layers.TimeDistributed(layers.Dense(1, activation='linear'))(x)\n",
    "        decoded = layers.Flatten()(decoded)\n",
    "\n",
    "        autoencoder = keras.Model(inputs=inputs, outputs=decoded)\n",
    "        autoencoder.compile(optimizer=keras.optimizers.Adam(1e-4), loss='mse')\n",
    "        return autoencoder\n",
    "\n",
    "    def train(self, X_train, X_val, epochs=50):\n",
    "        self.model.fit(X_train, X_train, epochs=epochs, batch_size=32, validation_data=(X_val, X_val))\n",
    "\n",
    "    def detect_anomalies(self, X_data, threshold=0.02):\n",
    "        reconstructed = self.model.predict(X_data)\n",
    "        errors = np.mean(np.square(X_data - reconstructed), axis=1)\n",
    "        return X_data[errors > threshold], np.where(errors > threshold)[0]\n",
    "        \n",
    "    def extract_features(self, X_anomalies):\n",
    "        # Create a feature extractor model using the named gap_layer\n",
    "        feature_extractor = keras.Model(\n",
    "            inputs=self.model.input, \n",
    "            outputs=self.model.get_layer(\"gap_layer\").output  # Use the named layer\n",
    "        )\n",
    "        return feature_extractor.predict(X_anomalies)\n",
    "\n",
    "# Train Layer 1\n",
    "layer1 = AdaptiveNIDSLayer1(input_dim=X_train.shape[1])\n",
    "layer1.train(X_train, X_val)\n",
    "\n",
    "# Detect anomalies\n",
    "anomalies, anomaly_indices = layer1.detect_anomalies(X_val)\n",
    "\n",
    "# Example usage of the new extract_features method\n",
    "extracted_features_epoch_50_BS_32 = layer1.extract_features(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - loss: 0.2420 - val_loss: 0.2174\n",
      "Epoch 2/25\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 0.2194 - val_loss: 0.1970\n",
      "Epoch 3/25\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.2006 - val_loss: 0.1804\n",
      "Epoch 4/25\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.1844 - val_loss: 0.1661\n",
      "Epoch 5/25\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1667 - val_loss: 0.1533\n",
      "Epoch 6/25\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1572 - val_loss: 0.1421\n",
      "Epoch 7/25\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1482 - val_loss: 0.1322\n",
      "Epoch 8/25\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1355 - val_loss: 0.1237\n",
      "Epoch 9/25\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1262 - val_loss: 0.1166\n",
      "Epoch 10/25\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1210 - val_loss: 0.1109\n",
      "Epoch 11/25\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1151 - val_loss: 0.1066\n",
      "Epoch 12/25\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.1139 - val_loss: 0.1036\n",
      "Epoch 13/25\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.1093 - val_loss: 0.1021\n",
      "Epoch 14/25\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1065 - val_loss: 0.1014\n",
      "Epoch 15/25\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1085 - val_loss: 0.1013\n",
      "Epoch 16/25\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1074 - val_loss: 0.1007\n",
      "Epoch 17/25\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1090 - val_loss: 0.1004\n",
      "Epoch 18/25\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1074 - val_loss: 0.1001\n",
      "Epoch 19/25\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 0.1059 - val_loss: 0.0997\n",
      "Epoch 20/25\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.1069 - val_loss: 0.0992\n",
      "Epoch 21/25\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 0.1046 - val_loss: 0.0986\n",
      "Epoch 22/25\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.1026 - val_loss: 0.0986\n",
      "Epoch 23/25\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.1041 - val_loss: 0.0977\n",
      "Epoch 24/25\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 0.1025 - val_loss: 0.0971\n",
      "Epoch 25/25\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 0.1064 - val_loss: 0.0971\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# Define Layer 1 of the Adaptive NIDS\n",
    "class AdaptiveNIDSLayer1:\n",
    "    def __init__(self, input_dim, latent_dim=16):\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.model = self._build_autoencoder()\n",
    "\n",
    "    def _build_autoencoder(self):\n",
    "        inputs = layers.Input(shape=(self.input_dim,))\n",
    "        x = layers.BatchNormalization()(inputs)\n",
    "        x = layers.Reshape((-1, 1))(x)\n",
    "\n",
    "        # Feature extraction via Residual CNN\n",
    "        x = layers.Conv1D(16, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.Conv1D(32, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.GlobalAveragePooling1D(name=\"gap_layer\")(x)  # Added explicit name\n",
    "\n",
    "        # Latent Representation\n",
    "        x = layers.Dense(64, activation='mish', kernel_regularizer=regularizers.l1(0.0005))(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        encoded = layers.Dense(self.latent_dim, activation='linear')(x)\n",
    "\n",
    "        # Decoder\n",
    "        x = layers.RepeatVector(self.input_dim)(encoded)\n",
    "        x = layers.LSTM(self.latent_dim * 2, return_sequences=True, recurrent_dropout=0.25)(x)\n",
    "        decoded = layers.TimeDistributed(layers.Dense(1, activation='linear'))(x)\n",
    "        decoded = layers.Flatten()(decoded)\n",
    "\n",
    "        autoencoder = keras.Model(inputs=inputs, outputs=decoded)\n",
    "        autoencoder.compile(optimizer=keras.optimizers.Adam(1e-4), loss='mse')\n",
    "        return autoencoder\n",
    "\n",
    "    def train(self, X_train, X_val, epochs=25):\n",
    "        self.model.fit(X_train, X_train, epochs=epochs, batch_size=64, validation_data=(X_val, X_val))\n",
    "\n",
    "    def detect_anomalies(self, X_data, threshold=0.02):\n",
    "        reconstructed = self.model.predict(X_data)\n",
    "        errors = np.mean(np.square(X_data - reconstructed), axis=1)\n",
    "        return X_data[errors > threshold], np.where(errors > threshold)[0]\n",
    "        \n",
    "    def extract_features(self, X_anomalies):\n",
    "        # Create a feature extractor model using the named gap_layer\n",
    "        feature_extractor = keras.Model(\n",
    "            inputs=self.model.input, \n",
    "            outputs=self.model.get_layer(\"gap_layer\").output  # Use the named layer\n",
    "        )\n",
    "        return feature_extractor.predict(X_anomalies)\n",
    "\n",
    "# Train Layer 1\n",
    "layer1 = AdaptiveNIDSLayer1(input_dim=X_train.shape[1])\n",
    "layer1.train(X_train, X_val)\n",
    "\n",
    "# Detect anomalies\n",
    "anomalies, anomaly_indices = layer1.detect_anomalies(X_val)\n",
    "\n",
    "# Example usage of the new extract_features method\n",
    "extracted_features_epoch_25_BS_64 = layer1.extract_features(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.2324 - val_loss: 0.1961\n",
      "Epoch 2/25\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1940 - val_loss: 0.1642\n",
      "Epoch 3/25\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1629 - val_loss: 0.1407\n",
      "Epoch 4/25\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1409 - val_loss: 0.1229\n",
      "Epoch 5/25\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1255 - val_loss: 0.1110\n",
      "Epoch 6/25\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1170 - val_loss: 0.1042\n",
      "Epoch 7/25\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1102 - val_loss: 0.1022\n",
      "Epoch 8/25\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - loss: 0.1059 - val_loss: 0.1015\n",
      "Epoch 9/25\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1108 - val_loss: 0.1011\n",
      "Epoch 10/25\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1042 - val_loss: 0.1008\n",
      "Epoch 11/25\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1074 - val_loss: 0.1002\n",
      "Epoch 12/25\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1094 - val_loss: 0.0997\n",
      "Epoch 13/25\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1052 - val_loss: 0.0995\n",
      "Epoch 14/25\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1097 - val_loss: 0.0986\n",
      "Epoch 15/25\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1053 - val_loss: 0.0982\n",
      "Epoch 16/25\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1072 - val_loss: 0.0975\n",
      "Epoch 17/25\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1049 - val_loss: 0.0970\n",
      "Epoch 18/25\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1044 - val_loss: 0.0962\n",
      "Epoch 19/25\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1028 - val_loss: 0.0953\n",
      "Epoch 20/25\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1072 - val_loss: 0.0949\n",
      "Epoch 21/25\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.0972 - val_loss: 0.0934\n",
      "Epoch 22/25\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1051 - val_loss: 0.0936\n",
      "Epoch 23/25\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1046 - val_loss: 0.0926\n",
      "Epoch 24/25\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1029 - val_loss: 0.0920\n",
      "Epoch 25/25\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1002 - val_loss: 0.0915\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# Define Layer 1 of the Adaptive NIDS\n",
    "class AdaptiveNIDSLayer1:\n",
    "    def __init__(self, input_dim, latent_dim=16):\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.model = self._build_autoencoder()\n",
    "\n",
    "    def _build_autoencoder(self):\n",
    "        inputs = layers.Input(shape=(self.input_dim,))\n",
    "        x = layers.BatchNormalization()(inputs)\n",
    "        x = layers.Reshape((-1, 1))(x)\n",
    "\n",
    "        # Feature extraction via Residual CNN\n",
    "        x = layers.Conv1D(16, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.Conv1D(32, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.GlobalAveragePooling1D(name=\"gap_layer\")(x)  # Added explicit name\n",
    "\n",
    "        # Latent Representation\n",
    "        x = layers.Dense(64, activation='mish', kernel_regularizer=regularizers.l1(0.0005))(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        encoded = layers.Dense(self.latent_dim, activation='linear')(x)\n",
    "\n",
    "        # Decoder\n",
    "        x = layers.RepeatVector(self.input_dim)(encoded)\n",
    "        x = layers.LSTM(self.latent_dim * 2, return_sequences=True, recurrent_dropout=0.25)(x)\n",
    "        decoded = layers.TimeDistributed(layers.Dense(1, activation='linear'))(x)\n",
    "        decoded = layers.Flatten()(decoded)\n",
    "\n",
    "        autoencoder = keras.Model(inputs=inputs, outputs=decoded)\n",
    "        autoencoder.compile(optimizer=keras.optimizers.Adam(1e-4), loss='mse')\n",
    "        return autoencoder\n",
    "\n",
    "    def train(self, X_train, X_val, epochs=25):\n",
    "        self.model.fit(X_train, X_train, epochs=epochs, batch_size=32, validation_data=(X_val, X_val))\n",
    "\n",
    "    def detect_anomalies(self, X_data, threshold=0.02):\n",
    "        reconstructed = self.model.predict(X_data)\n",
    "        errors = np.mean(np.square(X_data - reconstructed), axis=1)\n",
    "        return X_data[errors > threshold], np.where(errors > threshold)[0]\n",
    "        \n",
    "    def extract_features(self, X_anomalies):\n",
    "        # Create a feature extractor model using the named gap_layer\n",
    "        feature_extractor = keras.Model(\n",
    "            inputs=self.model.input, \n",
    "            outputs=self.model.get_layer(\"gap_layer\").output  # Use the named layer\n",
    "        )\n",
    "        return feature_extractor.predict(X_anomalies)\n",
    "\n",
    "# Train Layer 1\n",
    "layer1 = AdaptiveNIDSLayer1(input_dim=X_train.shape[1])\n",
    "layer1.train(X_train, X_val)\n",
    "\n",
    "# Detect anomalies\n",
    "anomalies, anomaly_indices = layer1.detect_anomalies(X_val)\n",
    "\n",
    "# Example usage of the new extract_features method\n",
    "extracted_features_epoch_25_BS_32 = layer1.extract_features(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 0.2412 - val_loss: 0.2260\n",
      "Epoch 2/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.2299 - val_loss: 0.2158\n",
      "Epoch 3/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.2210 - val_loss: 0.2058\n",
      "Epoch 4/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.2074 - val_loss: 0.1958\n",
      "Epoch 5/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.1988 - val_loss: 0.1868\n",
      "Epoch 6/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.1916 - val_loss: 0.1790\n",
      "Epoch 7/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1825 - val_loss: 0.1714\n",
      "Epoch 8/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.1774 - val_loss: 0.1643\n",
      "Epoch 9/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1706 - val_loss: 0.1577\n",
      "Epoch 10/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1632 - val_loss: 0.1513\n",
      "Epoch 11/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.1577 - val_loss: 0.1453\n",
      "Epoch 12/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1480 - val_loss: 0.1399\n",
      "Epoch 13/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1461 - val_loss: 0.1347\n",
      "Epoch 14/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.1424 - val_loss: 0.1297\n",
      "Epoch 15/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1352 - val_loss: 0.1252\n",
      "Epoch 16/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1260 - val_loss: 0.1213\n",
      "Epoch 17/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1257 - val_loss: 0.1173\n",
      "Epoch 18/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.1209 - val_loss: 0.1137\n",
      "Epoch 19/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.1183 - val_loss: 0.1106\n",
      "Epoch 20/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1162 - val_loss: 0.1080\n",
      "Epoch 21/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.1150 - val_loss: 0.1052\n",
      "Epoch 22/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1140 - val_loss: 0.1036\n",
      "Epoch 23/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.1105 - val_loss: 0.1014\n",
      "Epoch 24/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1067 - val_loss: 0.0999\n",
      "Epoch 25/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.1069 - val_loss: 0.0988\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# Define Layer 1 of the Adaptive NIDS\n",
    "class AdaptiveNIDSLayer1:\n",
    "    def __init__(self, input_dim, latent_dim=16):\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.model = self._build_autoencoder()\n",
    "\n",
    "    def _build_autoencoder(self):\n",
    "        inputs = layers.Input(shape=(self.input_dim,))\n",
    "        x = layers.BatchNormalization()(inputs)\n",
    "        x = layers.Reshape((-1, 1))(x)\n",
    "\n",
    "        # Feature extraction via Residual CNN\n",
    "        x = layers.Conv1D(16, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.Conv1D(32, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.GlobalAveragePooling1D(name=\"gap_layer\")(x)  # Added explicit name\n",
    "\n",
    "        # Latent Representation\n",
    "        x = layers.Dense(64, activation='mish', kernel_regularizer=regularizers.l1(0.0005))(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        encoded = layers.Dense(self.latent_dim, activation='linear')(x)\n",
    "\n",
    "        # Decoder\n",
    "        x = layers.RepeatVector(self.input_dim)(encoded)\n",
    "        x = layers.LSTM(self.latent_dim * 2, return_sequences=True, recurrent_dropout=0.25)(x)\n",
    "        decoded = layers.TimeDistributed(layers.Dense(1, activation='linear'))(x)\n",
    "        decoded = layers.Flatten()(decoded)\n",
    "\n",
    "        autoencoder = keras.Model(inputs=inputs, outputs=decoded)\n",
    "        autoencoder.compile(optimizer=keras.optimizers.Adam(1e-4), loss='mse')\n",
    "        return autoencoder\n",
    "\n",
    "    def train(self, X_train, X_val, epochs=25):\n",
    "        self.model.fit(X_train, X_train, epochs=epochs, batch_size=128, validation_data=(X_val, X_val))\n",
    "\n",
    "    def detect_anomalies(self, X_data, threshold=0.02):\n",
    "        reconstructed = self.model.predict(X_data)\n",
    "        errors = np.mean(np.square(X_data - reconstructed), axis=1)\n",
    "        return X_data[errors > threshold], np.where(errors > threshold)[0]\n",
    "        \n",
    "    def extract_features(self, X_anomalies):\n",
    "        # Create a feature extractor model using the named gap_layer\n",
    "        feature_extractor = keras.Model(\n",
    "            inputs=self.model.input, \n",
    "            outputs=self.model.get_layer(\"gap_layer\").output  # Use the named layer\n",
    "        )\n",
    "        return feature_extractor.predict(X_anomalies)\n",
    "\n",
    "# Train Layer 1\n",
    "layer1 = AdaptiveNIDSLayer1(input_dim=X_train.shape[1])\n",
    "layer1.train(X_train, X_val)\n",
    "\n",
    "# Detect anomalies\n",
    "anomalies, anomaly_indices = layer1.detect_anomalies(X_val)\n",
    "\n",
    "# Example usage of the new extract_features method\n",
    "extracted_features_epoch_25_BS_32 = layer1.extract_features(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.2309 - val_loss: 0.1966\n",
      "Epoch 2/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1919 - val_loss: 0.1663\n",
      "Epoch 3/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1658 - val_loss: 0.1424\n",
      "Epoch 4/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1432 - val_loss: 0.1242\n",
      "Epoch 5/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1308 - val_loss: 0.1112\n",
      "Epoch 6/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1177 - val_loss: 0.1041\n",
      "Epoch 7/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1077 - val_loss: 0.1020\n",
      "Epoch 8/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1108 - val_loss: 0.1011\n",
      "Epoch 9/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1088 - val_loss: 0.1004\n",
      "Epoch 10/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1071 - val_loss: 0.0998\n",
      "Epoch 11/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1070 - val_loss: 0.0995\n",
      "Epoch 12/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1050 - val_loss: 0.0980\n",
      "Epoch 13/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1108 - val_loss: 0.0967\n",
      "Epoch 14/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1055 - val_loss: 0.0970\n",
      "Epoch 15/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1039 - val_loss: 0.0948\n",
      "Epoch 16/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1022 - val_loss: 0.0936\n",
      "Epoch 17/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1066 - val_loss: 0.0933\n",
      "Epoch 18/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1028 - val_loss: 0.0940\n",
      "Epoch 19/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1045 - val_loss: 0.0916\n",
      "Epoch 20/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1017 - val_loss: 0.0912\n",
      "Epoch 21/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1020 - val_loss: 0.0907\n",
      "Epoch 22/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1019 - val_loss: 0.0904\n",
      "Epoch 23/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0999 - val_loss: 0.0904\n",
      "Epoch 24/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0976 - val_loss: 0.0892\n",
      "Epoch 25/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1003 - val_loss: 0.0889\n",
      "Epoch 26/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0977 - val_loss: 0.0897\n",
      "Epoch 27/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1023 - val_loss: 0.0882\n",
      "Epoch 28/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1017 - val_loss: 0.0883\n",
      "Epoch 29/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0968 - val_loss: 0.0879\n",
      "Epoch 30/30\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1007 - val_loss: 0.0876\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# Define Layer 1 of the Adaptive NIDS\n",
    "class AdaptiveNIDSLayer1:\n",
    "    def __init__(self, input_dim, latent_dim=16):\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.model = self._build_autoencoder()\n",
    "\n",
    "    def _build_autoencoder(self):\n",
    "        inputs = layers.Input(shape=(self.input_dim,))\n",
    "        x = layers.BatchNormalization()(inputs)\n",
    "        x = layers.Reshape((-1, 1))(x)\n",
    "\n",
    "        # Feature extraction via Residual CNN\n",
    "        x = layers.Conv1D(16, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.Conv1D(32, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.GlobalAveragePooling1D(name=\"gap_layer\")(x)  # Added explicit name\n",
    "\n",
    "        # Latent Representation\n",
    "        x = layers.Dense(64, activation='mish', kernel_regularizer=regularizers.l1(0.0005))(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        encoded = layers.Dense(self.latent_dim, activation='linear')(x)\n",
    "\n",
    "        # Decoder\n",
    "        x = layers.RepeatVector(self.input_dim)(encoded)\n",
    "        x = layers.LSTM(self.latent_dim * 2, return_sequences=True, recurrent_dropout=0.25)(x)\n",
    "        decoded = layers.TimeDistributed(layers.Dense(1, activation='linear'))(x)\n",
    "        decoded = layers.Flatten()(decoded)\n",
    "\n",
    "        autoencoder = keras.Model(inputs=inputs, outputs=decoded)\n",
    "        autoencoder.compile(optimizer=keras.optimizers.Adam(1e-4), loss='mse')\n",
    "        return autoencoder\n",
    "\n",
    "    def train(self, X_train, X_val, epochs=30):\n",
    "        self.model.fit(X_train, X_train, epochs=epochs, batch_size=32, validation_data=(X_val, X_val))\n",
    "\n",
    "    def detect_anomalies(self, X_data, threshold=0.02):\n",
    "        reconstructed = self.model.predict(X_data)\n",
    "        errors = np.mean(np.square(X_data - reconstructed), axis=1)\n",
    "        return X_data[errors > threshold], np.where(errors > threshold)[0]\n",
    "        \n",
    "    def extract_features(self, X_anomalies):\n",
    "        # Create a feature extractor model using the named gap_layer\n",
    "        feature_extractor = keras.Model(\n",
    "            inputs=self.model.input, \n",
    "            outputs=self.model.get_layer(\"gap_layer\").output  # Use the named layer\n",
    "        )\n",
    "        return feature_extractor.predict(X_anomalies)\n",
    "\n",
    "# Train Layer 1\n",
    "layer1 = AdaptiveNIDSLayer1(input_dim=X_train.shape[1])\n",
    "layer1.train(X_train, X_val)\n",
    "\n",
    "# Detect anomalies\n",
    "anomalies, anomaly_indices = layer1.detect_anomalies(X_val)\n",
    "\n",
    "# Example usage of the new extract_features method\n",
    "extracted_features_epoch_30_BS_32 = layer1.extract_features(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.2334 - val_loss: 0.2129\n",
      "Epoch 2/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.2114 - val_loss: 0.1940\n",
      "Epoch 3/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1925 - val_loss: 0.1767\n",
      "Epoch 4/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1790 - val_loss: 0.1623\n",
      "Epoch 5/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1627 - val_loss: 0.1496\n",
      "Epoch 6/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.1568 - val_loss: 0.1388\n",
      "Epoch 7/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.1372 - val_loss: 0.1294\n",
      "Epoch 8/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.1318 - val_loss: 0.1215\n",
      "Epoch 9/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1263 - val_loss: 0.1149\n",
      "Epoch 10/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1219 - val_loss: 0.1098\n",
      "Epoch 11/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1178 - val_loss: 0.1060\n",
      "Epoch 12/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.1122 - val_loss: 0.1036\n",
      "Epoch 13/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1098 - val_loss: 0.1023\n",
      "Epoch 14/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1098 - val_loss: 0.1016\n",
      "Epoch 15/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1116 - val_loss: 0.1011\n",
      "Epoch 16/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 0.1065 - val_loss: 0.1012\n",
      "Epoch 17/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 0.1076 - val_loss: 0.1007\n",
      "Epoch 18/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 0.1074 - val_loss: 0.1002\n",
      "Epoch 19/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1063 - val_loss: 0.0999\n",
      "Epoch 20/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.1050 - val_loss: 0.0994\n",
      "Epoch 21/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1051 - val_loss: 0.0990\n",
      "Epoch 22/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1018 - val_loss: 0.0986\n",
      "Epoch 23/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1023 - val_loss: 0.0988\n",
      "Epoch 24/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.1044 - val_loss: 0.0976\n",
      "Epoch 25/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.1063 - val_loss: 0.0976\n",
      "Epoch 26/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.1047 - val_loss: 0.0973\n",
      "Epoch 27/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.1044 - val_loss: 0.0970\n",
      "Epoch 28/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.1030 - val_loss: 0.0963\n",
      "Epoch 29/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1035 - val_loss: 0.0962\n",
      "Epoch 30/30\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.1034 - val_loss: 0.0961\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# Define Layer 1 of the Adaptive NIDS\n",
    "class AdaptiveNIDSLayer1:\n",
    "    def __init__(self, input_dim, latent_dim=16):\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.model = self._build_autoencoder()\n",
    "\n",
    "    def _build_autoencoder(self):\n",
    "        inputs = layers.Input(shape=(self.input_dim,))\n",
    "        x = layers.BatchNormalization()(inputs)\n",
    "        x = layers.Reshape((-1, 1))(x)\n",
    "\n",
    "        # Feature extraction via Residual CNN\n",
    "        x = layers.Conv1D(16, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.Conv1D(32, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.GlobalAveragePooling1D(name=\"gap_layer\")(x)  # Added explicit name\n",
    "\n",
    "        # Latent Representation\n",
    "        x = layers.Dense(64, activation='mish', kernel_regularizer=regularizers.l1(0.0005))(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        encoded = layers.Dense(self.latent_dim, activation='linear')(x)\n",
    "\n",
    "        # Decoder\n",
    "        x = layers.RepeatVector(self.input_dim)(encoded)\n",
    "        x = layers.LSTM(self.latent_dim * 2, return_sequences=True, recurrent_dropout=0.25)(x)\n",
    "        decoded = layers.TimeDistributed(layers.Dense(1, activation='linear'))(x)\n",
    "        decoded = layers.Flatten()(decoded)\n",
    "\n",
    "        autoencoder = keras.Model(inputs=inputs, outputs=decoded)\n",
    "        autoencoder.compile(optimizer=keras.optimizers.Adam(1e-4), loss='mse')\n",
    "        return autoencoder\n",
    "\n",
    "    def train(self, X_train, X_val, epochs=30):\n",
    "        self.model.fit(X_train, X_train, epochs=epochs, batch_size=64, validation_data=(X_val, X_val))\n",
    "\n",
    "    def detect_anomalies(self, X_data, threshold=0.02):\n",
    "        reconstructed = self.model.predict(X_data)\n",
    "        errors = np.mean(np.square(X_data - reconstructed), axis=1)\n",
    "        return X_data[errors > threshold], np.where(errors > threshold)[0]\n",
    "        \n",
    "    def extract_features(self, X_anomalies):\n",
    "        # Create a feature extractor model using the named gap_layer\n",
    "        feature_extractor = keras.Model(\n",
    "            inputs=self.model.input, \n",
    "            outputs=self.model.get_layer(\"gap_layer\").output  # Use the named layer\n",
    "        )\n",
    "        return feature_extractor.predict(X_anomalies)\n",
    "\n",
    "# Train Layer 1\n",
    "layer1 = AdaptiveNIDSLayer1(input_dim=X_train.shape[1])\n",
    "layer1.train(X_train, X_val)\n",
    "\n",
    "# Detect anomalies\n",
    "anomalies, anomaly_indices = layer1.detect_anomalies(X_val)\n",
    "\n",
    "# Example usage of the new extract_features method\n",
    "extracted_features_epoch_30_BS_64 = layer1.extract_features(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 0.2367 - val_loss: 0.2254\n",
      "Epoch 2/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.2306 - val_loss: 0.2146\n",
      "Epoch 3/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.2184 - val_loss: 0.2050\n",
      "Epoch 4/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.2059 - val_loss: 0.1948\n",
      "Epoch 5/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1973 - val_loss: 0.1858\n",
      "Epoch 6/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.1947 - val_loss: 0.1782\n",
      "Epoch 7/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1817 - val_loss: 0.1707\n",
      "Epoch 8/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1767 - val_loss: 0.1637\n",
      "Epoch 9/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1697 - val_loss: 0.1571\n",
      "Epoch 10/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.1630 - val_loss: 0.1508\n",
      "Epoch 11/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.1571 - val_loss: 0.1449\n",
      "Epoch 12/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1504 - val_loss: 0.1393\n",
      "Epoch 13/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1489 - val_loss: 0.1341\n",
      "Epoch 14/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.1365 - val_loss: 0.1295\n",
      "Epoch 15/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1326 - val_loss: 0.1250\n",
      "Epoch 16/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1306 - val_loss: 0.1211\n",
      "Epoch 17/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1273 - val_loss: 0.1174\n",
      "Epoch 18/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1236 - val_loss: 0.1140\n",
      "Epoch 19/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1218 - val_loss: 0.1112\n",
      "Epoch 20/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.1200 - val_loss: 0.1088\n",
      "Epoch 21/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.1140 - val_loss: 0.1064\n",
      "Epoch 22/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1141 - val_loss: 0.1048\n",
      "Epoch 23/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1107 - val_loss: 0.1032\n",
      "Epoch 24/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.1105 - val_loss: 0.1020\n",
      "Epoch 25/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1041 - val_loss: 0.1009\n",
      "Epoch 26/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1094 - val_loss: 0.1003\n",
      "Epoch 27/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1057 - val_loss: 0.0996\n",
      "Epoch 28/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1095 - val_loss: 0.0989\n",
      "Epoch 29/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1054 - val_loss: 0.0980\n",
      "Epoch 30/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1039 - val_loss: 0.0976\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# Define Layer 1 of the Adaptive NIDS\n",
    "class AdaptiveNIDSLayer1:\n",
    "    def __init__(self, input_dim, latent_dim=16):\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.model = self._build_autoencoder()\n",
    "\n",
    "    def _build_autoencoder(self):\n",
    "        inputs = layers.Input(shape=(self.input_dim,))\n",
    "        x = layers.BatchNormalization()(inputs)\n",
    "        x = layers.Reshape((-1, 1))(x)\n",
    "\n",
    "        # Feature extraction via Residual CNN\n",
    "        x = layers.Conv1D(16, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.Conv1D(32, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.GlobalAveragePooling1D(name=\"gap_layer\")(x)  # Added explicit name\n",
    "\n",
    "        # Latent Representation\n",
    "        x = layers.Dense(64, activation='mish', kernel_regularizer=regularizers.l1(0.0005))(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        encoded = layers.Dense(self.latent_dim, activation='linear')(x)\n",
    "\n",
    "        # Decoder\n",
    "        x = layers.RepeatVector(self.input_dim)(encoded)\n",
    "        x = layers.LSTM(self.latent_dim * 2, return_sequences=True, recurrent_dropout=0.25)(x)\n",
    "        decoded = layers.TimeDistributed(layers.Dense(1, activation='linear'))(x)\n",
    "        decoded = layers.Flatten()(decoded)\n",
    "\n",
    "        autoencoder = keras.Model(inputs=inputs, outputs=decoded)\n",
    "        autoencoder.compile(optimizer=keras.optimizers.Adam(1e-4), loss='mse')\n",
    "        return autoencoder\n",
    "\n",
    "    def train(self, X_train, X_val, epochs=30):\n",
    "        self.model.fit(X_train, X_train, epochs=epochs, batch_size=128, validation_data=(X_val, X_val))\n",
    "\n",
    "    def detect_anomalies(self, X_data, threshold=0.02):\n",
    "        reconstructed = self.model.predict(X_data)\n",
    "        errors = np.mean(np.square(X_data - reconstructed), axis=1)\n",
    "        return X_data[errors > threshold], np.where(errors > threshold)[0]\n",
    "        \n",
    "    def extract_features(self, X_anomalies):\n",
    "        # Create a feature extractor model using the named gap_layer\n",
    "        feature_extractor = keras.Model(\n",
    "            inputs=self.model.input, \n",
    "            outputs=self.model.get_layer(\"gap_layer\").output  # Use the named layer\n",
    "        )\n",
    "        return feature_extractor.predict(X_anomalies)\n",
    "\n",
    "# Train Layer 1\n",
    "layer1 = AdaptiveNIDSLayer1(input_dim=X_train.shape[1])\n",
    "layer1.train(X_train, X_val)\n",
    "\n",
    "# Detect anomalies\n",
    "anomalies, anomaly_indices = layer1.detect_anomalies(X_val)\n",
    "\n",
    "# Example usage of the new extract_features method\n",
    "extracted_features_epoch_30_BS_128 = layer1.extract_features(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing dataset for Layer 2\n",
    "def attach_attack_labels(original_df, anomaly_indices):\n",
    "    labeled_anomalies = original_df.iloc[anomaly_indices]\n",
    "    return labeled_anomalies.drop(columns=['Attack_label']), labeled_anomalies['Attack_label']\n",
    "\n",
    "# Load original dataset for labels\n",
    "original_df = pd.read_csv(\"/Users/siddhantgond/Desktop/6THSEM/Project_Elective/Adaptive-Network-Intrusion-Detection-System/Implementaiton/training_dataset.csv\")\n",
    "X_layer2, y_layer2 = attach_attack_labels(original_df, anomaly_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.6626 - loss: 0.9693 - val_accuracy: 0.8563 - val_loss: 0.2665\n",
      "Epoch 2/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9461 - loss: 0.1434 - val_accuracy: 0.9235 - val_loss: 0.2001\n",
      "Epoch 3/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9795 - loss: 0.0575 - val_accuracy: 0.9384 - val_loss: 0.1957\n",
      "Epoch 4/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9889 - loss: 0.0384 - val_accuracy: 0.9384 - val_loss: 0.2310\n",
      "Epoch 5/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9790 - loss: 0.0490 - val_accuracy: 0.9515 - val_loss: 0.1724\n",
      "Epoch 6/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9860 - loss: 0.0361 - val_accuracy: 0.9757 - val_loss: 0.0587\n",
      "Epoch 7/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9894 - loss: 0.0267 - val_accuracy: 0.9851 - val_loss: 0.0248\n",
      "Epoch 8/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9858 - loss: 0.0328 - val_accuracy: 0.9832 - val_loss: 0.0329\n",
      "Epoch 9/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9934 - loss: 0.0209 - val_accuracy: 0.9925 - val_loss: 0.0186\n",
      "Epoch 10/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9920 - loss: 0.0220 - val_accuracy: 0.9925 - val_loss: 0.0198\n",
      "Epoch 11/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9931 - loss: 0.0185 - val_accuracy: 0.9795 - val_loss: 0.0361\n",
      "Epoch 12/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9947 - loss: 0.0155 - val_accuracy: 0.9795 - val_loss: 0.0333\n",
      "Epoch 13/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9825 - loss: 0.0491 - val_accuracy: 0.9907 - val_loss: 0.0259\n",
      "Epoch 14/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9945 - loss: 0.0177 - val_accuracy: 0.9888 - val_loss: 0.0189\n",
      "Epoch 15/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9922 - loss: 0.0172 - val_accuracy: 0.9869 - val_loss: 0.0269\n",
      "Epoch 16/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9971 - loss: 0.0093 - val_accuracy: 0.9813 - val_loss: 0.0314\n",
      "Epoch 17/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9894 - loss: 0.0264 - val_accuracy: 0.9888 - val_loss: 0.0275\n",
      "Epoch 18/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9932 - loss: 0.0155 - val_accuracy: 0.9813 - val_loss: 0.0435\n",
      "Epoch 19/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9918 - loss: 0.0164 - val_accuracy: 0.9888 - val_loss: 0.0255\n",
      "Epoch 20/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9986 - loss: 0.0058 - val_accuracy: 0.9869 - val_loss: 0.0338\n",
      "Epoch 21/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9909 - loss: 0.0190 - val_accuracy: 0.9869 - val_loss: 0.0301\n",
      "Epoch 22/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9991 - loss: 0.0056 - val_accuracy: 0.9832 - val_loss: 0.0388\n",
      "Epoch 23/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9976 - loss: 0.0069 - val_accuracy: 0.9925 - val_loss: 0.0366\n",
      "Epoch 24/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9964 - loss: 0.0127 - val_accuracy: 0.9925 - val_loss: 0.0271\n",
      "Epoch 25/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9992 - loss: 0.0041 - val_accuracy: 0.9907 - val_loss: 0.0297\n",
      "Epoch 26/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9995 - loss: 0.0046 - val_accuracy: 0.9832 - val_loss: 0.0508\n",
      "Epoch 27/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9907 - val_loss: 0.0329\n",
      "Epoch 28/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9975 - loss: 0.0060 - val_accuracy: 0.9907 - val_loss: 0.0320\n",
      "Epoch 29/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0042 - val_accuracy: 0.9832 - val_loss: 0.0617\n",
      "Epoch 30/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9958 - loss: 0.0129 - val_accuracy: 0.9907 - val_loss: 0.0376\n",
      "Epoch 31/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9999 - loss: 0.0027 - val_accuracy: 0.9888 - val_loss: 0.0298\n",
      "Epoch 32/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9888 - val_loss: 0.0341\n",
      "Epoch 33/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 0.9888 - val_loss: 0.0374\n",
      "Epoch 34/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9961 - loss: 0.0092 - val_accuracy: 0.9888 - val_loss: 0.0411\n",
      "Epoch 35/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9964 - loss: 0.0070 - val_accuracy: 0.9851 - val_loss: 0.0395\n",
      "Epoch 36/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9999 - loss: 0.0029 - val_accuracy: 0.9888 - val_loss: 0.0345\n",
      "Epoch 37/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 0.9869 - val_loss: 0.0407\n",
      "Epoch 38/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9999 - loss: 0.0016 - val_accuracy: 0.9907 - val_loss: 0.0374\n",
      "Epoch 39/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9990 - loss: 0.0034 - val_accuracy: 0.9869 - val_loss: 0.0405\n",
      "Epoch 40/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9813 - val_loss: 0.0418\n",
      "Epoch 41/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9998 - loss: 0.0016 - val_accuracy: 0.9888 - val_loss: 0.0393\n",
      "Epoch 42/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9832 - val_loss: 0.0627\n",
      "Epoch 43/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9888 - val_loss: 0.0494\n",
      "Epoch 44/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.9869 - val_loss: 0.0585\n",
      "Epoch 45/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9832 - val_loss: 0.0686\n",
      "Epoch 46/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.8274e-04 - val_accuracy: 0.9851 - val_loss: 0.0607\n",
      "Epoch 47/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 4.1418e-04 - val_accuracy: 0.9832 - val_loss: 0.0592\n",
      "Epoch 48/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 9.4575e-04 - val_accuracy: 0.9851 - val_loss: 0.0761\n",
      "Epoch 49/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9969 - loss: 0.0040 - val_accuracy: 0.9851 - val_loss: 0.0701\n",
      "Epoch 50/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9979 - loss: 0.0049 - val_accuracy: 0.9776 - val_loss: 0.0915\n"
     ]
    }
   ],
   "source": [
    "# Define Layer 2 of the Adaptive NIDS\n",
    "class AdaptiveNIDSLayer2:\n",
    "    def __init__(self, input_dim, num_classes, seq_length=10):\n",
    "        \"\"\"\n",
    "        Initializes Layer 2 for attack classification using CNN-BiLSTM.\n",
    "        \n",
    "        Args:\n",
    "            input_dim (int): Number of input features per time step.\n",
    "            num_classes (int): Number of attack classes.\n",
    "            seq_length (int): Number of time steps in sequence.\n",
    "        \"\"\"\n",
    "        self.input_dim = input_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.seq_length = seq_length\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        \"\"\"\n",
    "        Builds the CNN-BiLSTM classification model.\n",
    "        \"\"\"\n",
    "        inputs = layers.Input(shape=(self.seq_length, self.input_dim))\n",
    "        \n",
    "        # CNN Feature Extraction\n",
    "        x = layers.Conv1D(64, kernel_size=3, activation='relu', padding='same')(inputs)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        # BiLSTM for Temporal Sequence Learning\n",
    "        x = layers.Bidirectional(layers.GRU(48, return_sequences=False))(x)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        x = layers.Dense(64, activation='relu')(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        \n",
    "        # Output Layer (Softmax for Classification)\n",
    "        outputs = layers.Dense(self.num_classes, activation='softmax')(x)\n",
    "\n",
    "        # Compile Model\n",
    "        model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        model.compile(optimizer=keras.optimizers.Adam(1e-3), \n",
    "                      loss='sparse_categorical_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def train(self, X_train, y_train, epochs=50, batch_size=64):\n",
    "        \"\"\"\n",
    "        Trains the Layer 2 model.\n",
    "        \n",
    "        Args:\n",
    "            X_train (np.array): Input sequences.\n",
    "            y_train (np.array): Attack labels.\n",
    "            epochs (int): Number of training epochs.\n",
    "            batch_size (int): Batch size.\n",
    "        \"\"\"\n",
    "        self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
    "\n",
    "\n",
    "def create_sequences(data, labels, seq_length=10):\n",
    "    \"\"\"\n",
    "    Converts feature data into time-series sequences for Layer 2.\n",
    "    \n",
    "    Args:\n",
    "        data (np.array): 2D feature matrix.\n",
    "        labels (pd.Series or np.array): Corresponding labels.\n",
    "        seq_length (int): Number of time steps per sequence.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (sequential data, adjusted labels)\n",
    "    \"\"\"\n",
    "    sequences, seq_labels = [], []\n",
    "    \n",
    "    # Convert labels to NumPy array to avoid indexing issues\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    for i in range(len(data) - seq_length):\n",
    "        sequences.append(data[i:i + seq_length])\n",
    "        seq_labels.append(labels[i + seq_length - 1])  # ✅ Now works correctly\n",
    "\n",
    "    return np.array(sequences), np.array(seq_labels)\n",
    "\n",
    "# Generate sequences for Layer 2\n",
    "seq_length = 10\n",
    "X_layer2_reshaped, y_layer2_adjusted = create_sequences(X_layer2, y_layer2, seq_length=seq_length)\n",
    "\n",
    "# Train Layer 2\n",
    "layer2 = AdaptiveNIDSLayer2(input_dim=X_layer2_reshaped.shape[2], num_classes=5, seq_length=seq_length)\n",
    "layer2.train(X_layer2_reshaped, y_layer2_adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "def knowledge_distillation(teacher_model, student_model, X_train, y_train, temperature=3.0, alpha=0.5, epochs=50):\n",
    "    \"\"\"\n",
    "    Implements knowledge distillation by training the student model with soft targets from the teacher.\n",
    "\n",
    "    Args:\n",
    "        teacher_model: Pre-trained teacher model.\n",
    "        student_model: Student model to be trained.\n",
    "        X_train (np.array): Training features.\n",
    "        y_train (np.array): Training labels (should be a NumPy array).\n",
    "        temperature (float): Softmax temperature for distillation.\n",
    "        alpha (float): Weight balance between hard loss and soft loss.\n",
    "        epochs (int): Number of training epochs.\n",
    "    \"\"\"\n",
    "    # ✅ Ensure y_train is a NumPy array\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    # ✅ Ensure labels are integers (for sparse categorical crossentropy)\n",
    "    if len(y_train.shape) > 1 and y_train.shape[1] > 1:\n",
    "        y_train = np.argmax(y_train, axis=1)  # Convert one-hot to integer labels\n",
    "\n",
    "    # Get number of classes for one-hot encoding\n",
    "    num_classes = student_model.output_shape[-1]\n",
    "    if isinstance(num_classes, tf.TensorShape):\n",
    "        num_classes = num_classes.as_list()[-1]  # Fix for unknown TensorShape\n",
    "    \n",
    "    # Step 1: Get teacher predictions first\n",
    "    print(\"Getting teacher predictions...\")\n",
    "    teacher_logits = teacher_model.predict(X_train)\n",
    "    teacher_probs = tf.nn.softmax(teacher_logits / temperature).numpy()\n",
    "    \n",
    "    # Step 2: Define custom loss function for distillation\n",
    "    def distillation_loss(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Computes the knowledge distillation loss:\n",
    "        - Hard loss: Student's predictions vs. true labels (Sparse Categorical Crossentropy)\n",
    "        - Soft loss: Student's predictions vs. Teacher's soft probabilities (KL Divergence)\n",
    "        \"\"\"\n",
    "        # Get index of the batch in the dataset\n",
    "        batch_indices = tf.range(tf.shape(y_true)[0])\n",
    "        \n",
    "        # Convert y_true to one-hot format (needed for loss calculation)\n",
    "        y_true_one_hot = tf.one_hot(tf.cast(tf.squeeze(y_true), tf.int32), depth=num_classes)\n",
    "        \n",
    "        # Get teacher soft targets for this batch\n",
    "        # We use a more robust approach that doesn't depend on keeping the teacher predictions in memory\n",
    "        batch_teacher_probs = tf.nn.softmax(teacher_model(tf.cast(tf.gather(X_train, batch_indices), tf.float32), training=False) / temperature)\n",
    "        \n",
    "        # Get student soft predictions\n",
    "        student_logits = y_pred\n",
    "        student_soft_probs = tf.nn.softmax(student_logits / temperature)\n",
    "        \n",
    "        # Compute losses\n",
    "        hard_loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, student_logits)\n",
    "        soft_loss = tf.keras.losses.KLDivergence()(batch_teacher_probs, student_soft_probs)\n",
    "        \n",
    "        # Weighted combination of hard and soft loss\n",
    "        return (1 - alpha) * hard_loss + alpha * soft_loss * (temperature ** 2)\n",
    "\n",
    "    # Step 3: Compile the student model with distillation loss\n",
    "    student_model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                          loss=distillation_loss,\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "    # Step 4: Train the student model using distillation\n",
    "    print(\"Training the student model with knowledge distillation...\")\n",
    "    student_model.fit(X_train, y_train, epochs=epochs, batch_size=64, verbose=1)\n",
    "\n",
    "    return student_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
